In fact, for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.We then add to the representation of the edge: Mi as head features, Mj as dependent features, and also each conjunction of a feature from both sets.That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.The major contribution was in helping to distinguish subjects, objects and other dependents of main verbs, which is the most common labeling error.For score functions, we use simple dot products between high dimensional feature representations and a weight vector Assuming we have an appropriate feature representation, we can find the highest scoring label sequence with Viterbiâ€™s algorithm.