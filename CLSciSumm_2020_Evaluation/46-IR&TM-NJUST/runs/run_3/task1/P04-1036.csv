Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","'63','86','103','111'","<S sid=""63"" ssid=""19"">We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.</S><S sid=""86"" ssid=""15"">The random baseline for ( ) is 24%.</S><S sid=""103"" ssid=""1"">In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken, we use the SENSEVAL-2 all-words data (Palmer et al., 2001).</S><S sid=""111"" ssid=""9"">We give the results for this WSD task in table 2.</S>",'Method_Citation'
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","'35','52','131','132'","<S sid=""35"" ssid=""28"">The neighbours are words ordered in terms of the “distributional similarity” that they have with the target.</S><S sid=""52"" ssid=""8"">For each sense of ( ) we obtain a ranking score by summing over the of each neighbour ( ) multiplied by a weight.</S><S sid=""131"" ssid=""8"">The SPORTS corpus consists of 35317 documents (about 9.1 million words).</S><S sid=""132"" ssid=""9"">The FINANCE corpus consists of 117734 documents (about 32.5 million words).</S>",'Method_Citation'
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","'41','155','178','190'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""155"" ssid=""3"">A major benefit of our work, rather than reliance on hand-tagged training data such as SemCor, is that this method permits us to produce predominant senses for the domain and text type required.</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid=""190"" ssid=""13"">Whilst we have used WordNet as our sense inventory, it would be possible to use this method with another inventory given a measure of semantic relatedness between the neighbours and the senses.</S>",'Method_Citation'
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"'5','10','83','93'","<S sid=""5"" ssid=""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S><S sid=""10"" ssid=""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al., 1993).</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S>",'Method_Citation'
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","'93','95','110','112'","<S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""95"" ssid=""24"">Since SemCor is derived from the Brown corpus, which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6, the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid=""110"" ssid=""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid=""112"" ssid=""10"">We compare results using the first sense listed in SemCor, and the first sense according to the SENSEVAL-2 English all-words test data itself.</S>",'Method_Citation'
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","'93','100','131','132'","<S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""100"" ssid=""29"">In the English all-words SENSEVAL-2, 25% of the noun data was monosemous.</S><S sid=""131"" ssid=""8"">The SPORTS corpus consists of 35317 documents (about 9.1 million words).</S><S sid=""132"" ssid=""9"">The FINANCE corpus consists of 117734 documents (about 32.5 million words).</S>","'Method_Citation','Result_Citation'"
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","'9','22','93','141'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""22"" ssid=""15"">More importantly, when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.</S><S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""141"" ssid=""18"">We contrast the distribution of domain labels for these words in the 2 domain specific corpora.</S>",'Method_Citation'
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","'93','110','142','167'","<S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""110"" ssid=""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid=""142"" ssid=""19"">The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.</S><S sid=""167"" ssid=""15"">In this work the lists of neighbours are themselves clustered to bring out the various senses of the word.</S>",'Method_Citation'
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","'10','71','150','178'","<S sid=""10"" ssid=""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al., 1993).</S><S sid=""71"" ssid=""27"">This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal:</S><S sid=""150"" ssid=""27"">Figure 2 displays the results of the second experiment with the domain specific corpora.</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S>",'Method_Citation'
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","'9','83','93','169'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""169"" ssid=""17"">This method obtains precision of 61% and recall 51%.</S>","'Method_Citation','Result_Citation'"
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","'4','45','83','165'","<S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""165"" ssid=""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S>",'Method_Citation'
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","'32','41','155','178'","<S sid=""32"" ssid=""25"">We describe some related work in section 6 and conclude in section 7. are therefore investigating a method of automatically ranking WordNet senses from raw text.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""155"" ssid=""3"">A major benefit of our work, rather than reliance on hand-tagged training data such as SemCor, is that this method permits us to produce predominant senses for the domain and text type required.</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S>",'Method_Citation'
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","'93','103','110','167'","<S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""103"" ssid=""1"">In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken, we use the SENSEVAL-2 all-words data (Palmer et al., 2001).</S><S sid=""110"" ssid=""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid=""167"" ssid=""15"">In this work the lists of neighbours are themselves clustered to bring out the various senses of the word.</S>",'Method_Citation'
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","'9','95','134','151'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""95"" ssid=""24"">Since SemCor is derived from the Brown corpus, which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6, the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid=""134"" ssid=""11"">There is no existing sense-tagged data for these domains that we could use for evaluation.</S><S sid=""151"" ssid=""28"">This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.</S>",'Method_Citation'
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","'68','83','95','99'","<S sid=""68"" ssid=""24"">We are of course able to apply the method to other versions of WordNet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""95"" ssid=""24"">Since SemCor is derived from the Brown corpus, which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6, the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid=""99"" ssid=""28"">Even given the difference in text type between SemCor and the BNC the results are encouraging, especially given that our results are for polysemous nouns.</S>",'Method_Citation'
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","'8','86','111'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""86"" ssid=""15"">The random baseline for ( ) is 24%.</S><S sid=""111"" ssid=""9"">We give the results for this WSD task in table 2.</S>",'Result_Citation'
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","'63','97','101','111'","<S sid=""63"" ssid=""19"">We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.</S><S sid=""97"" ssid=""26"">The first ranked sense according to SemCor is the filth, stain: state of being unclean sense whereas the automatic ranking lists dirt, ground, earth as the first sense, which is the second ranked sense according to SemCor.</S><S sid=""101"" ssid=""30"">Thus, if we used the sense ranking as a heuristic for an “all nouns” task we would expect to get precision in the region of 60%.</S><S sid=""111"" ssid=""9"">We give the results for this WSD task in table 2.</S>","'Method_Citation','Result_Citation'"
