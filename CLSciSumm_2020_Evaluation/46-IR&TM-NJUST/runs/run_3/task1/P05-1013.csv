Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P05-1013,W05-1505,0,"Nivre and Nilsson, 2005",0,"Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","'35','36','40','59'","<S sid=""35"" ssid=""6"">The dependency graph in Figure 1 satisfies all the defining conditions above, but it fails to satisfy the condition ofprojectivity (Kahane et al., 1998): The arc connecting the head jedna (one) to the dependent Z (out-of) spans the token je (is), which is not dominated by jedna.</S><S sid=""36"" ssid=""7"">As observed by Kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid=""40"" ssid=""11"">Even this may be nondeterministic, in case the graph contains several non-projective arcs whose lifts interact, but we use the following algorithm to construct a minimal projective transformation D0 = (W, A0) of a (nonprojective) dependency graph D = (W, A): The function SMALLEST-NONP-ARC returns the non-projective arc with the shortest distance from head to dependent (breaking ties from left to right).</S><S sid=""59"" ssid=""30"">The details of the transformation procedure are slightly different depending on the encoding schemes: d↑h let the linear head be the syntactic head). target arc must have the form wl −→ wm; if no target arc is found, Head is used as backoff. must have the form wl −→ wm and no outgoing arcs of the form wm p'↓ −→ wo; no backoff.</S>",'Method_Citation'
2,P05-1013,P08-1006,0,"Nivre and Nilsson, 2005",0,"1http: //sourceforge.net/projects/mstparser Figure 1: CoNLL-X dependency tree Figure 2: Penn Treebank-style phrase structure tree KSDEP Sagae and Tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","'35','46','63','65'","<S sid=""35"" ssid=""6"">The dependency graph in Figure 1 satisfies all the defining conditions above, but it fails to satisfy the condition ofprojectivity (Kahane et al., 1998): The arc connecting the head jedna (one) to the dependent Z (out-of) spans the token je (is), which is not dominated by jedna.</S><S sid=""46"" ssid=""17"">In principle, it would be possible to encode the exact position of the syntactic head in the label of the arc from the linear head, but this would give a potentially infinite set of arc labels and would make the training of the parser very hard.</S><S sid=""63"" ssid=""2"">The parser builds dependency graphs by traversing the input from left to right, using a stack to store tokens that are not yet complete with respect to their dependents.</S><S sid=""65"" ssid=""4"">More details on the parsing algorithm can be found in Nivre (2003).</S>",'Method_Citation'
3,P05-1013,W10-1401,0,"Nivre and Nilsson, 2005",0,"Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","'10','18','29','60'","<S sid=""10"" ssid=""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""29"" ssid=""25"">In section 5, we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.</S><S sid=""60"" ssid=""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks, and in section 5 they are applied to parser output.</S>",'Method_Citation'
4,P05-1013,P12-3029,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","'12','18','106'","<S sid=""12"" ssid=""8"">Prague Dependency Treebank (Hajiˇc et al., 2001b), Danish Dependency Treebank (Kromann, 2003), and the METU Treebank of Turkish (Oflazer et al., 2003), which generally allow annotations with nonprojective dependency structures.</S><S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""106"" ssid=""17"">However, the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech, with a best performance of 73% UAS (Holan, 2004).</S>",'Method_Citation'
5,P05-1013,W10-1403,0,"Nivre and Nilsson, 2005",0,"It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","'23','28','40','44'","<S sid=""23"" ssid=""19"">By applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid=""28"" ssid=""24"">First, in section 4, we evaluate the graph transformation techniques in themselves, with data from the Prague Dependency Treebank and the Danish Dependency Treebank.</S><S sid=""40"" ssid=""11"">Even this may be nondeterministic, in case the graph contains several non-projective arcs whose lifts interact, but we use the following algorithm to construct a minimal projective transformation D0 = (W, A0) of a (nonprojective) dependency graph D = (W, A): The function SMALLEST-NONP-ARC returns the non-projective arc with the shortest distance from head to dependent (breaking ties from left to right).</S><S sid=""44"" ssid=""15"">Instead, we want to apply an inverse transformation to recover the underlying (nonprojective) dependency graph.</S>",'Method_Citation'
6,P05-1013,D08-1008,0,"Nivre and Nilsson, 2005",0,"To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","'23','62','93','95'","<S sid=""23"" ssid=""19"">By applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S><S sid=""93"" ssid=""4"">In the labeled version of these metrics (L) both heads and arc labels must be correct, while the unlabeled version (U) only considers heads.</S><S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>",'Method_Citation'
7,P05-1013,D07-1013,0,2005,0,",wn in O (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines","Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing","'23','36','38','40'","<S sid=""23"" ssid=""19"">By applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid=""36"" ssid=""7"">As observed by Kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid=""38"" ssid=""9"">Projectivizing a dependency graph by lifting nonprojective arcs is a nondeterministic operation in the general case.</S><S sid=""40"" ssid=""11"">Even this may be nondeterministic, in case the graph contains several non-projective arcs whose lifts interact, but we use the following algorithm to construct a minimal projective transformation D0 = (W, A0) of a (nonprojective) dependency graph D = (W, A): The function SMALLEST-NONP-ARC returns the non-projective arc with the shortest distance from head to dependent (breaking ties from left to right).</S>",'Method_Citation'
8,P05-1013,D07-1119,0,2005,0,"For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","'10','52','81','105'","<S sid=""10"" ssid=""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid=""52"" ssid=""23"">Thus, the arc from je to jedna will be labeled 5b↓ (to indicate that there is a syntactic head below it).</S><S sid=""81"" ssid=""8"">However, the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.</S><S sid=""105"" ssid=""16"">Although the best published results for the Collins parser is 80% UAS (Collins, 1999), this parser reaches 82% when trained on the entire training data set, and an adapted version of Charniak’s parser (Charniak, 2000) performs at 84% (Jan Hajiˇc, pers. comm.).</S>",'Method_Citation'
9,P05-1013,N07-1050,0,"Nivre and Nilsson, 2005",0,"Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","'9','18','36','61'","<S sid=""9"" ssid=""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004).</S><S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""36"" ssid=""7"">As observed by Kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid=""61"" ssid=""32"">Before we turn to the evaluation, however, we need to introduce the data-driven dependency parser used in the latter experiments.</S>",'Method_Citation'
10,P05-1013,W09-1207,0,"Nivre and Nilsson, 2005",0,"troduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","'0','62','95','104'","<S sid=""0"" ssid=""1"">Pseudo-Projective Dependency Parsing</S><S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S><S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid=""104"" ssid=""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>",'Method_Citation'
11,P05-1013,E09-1034,0,"Nivre and Nilsson, 2005",0,"non projective (Nivre and Nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested","However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested","'6','8','12','62'","<S sid=""6"" ssid=""2"">However, this argument is only plausible if the formal framework allows non-projective dependency structures, i.e. structures where a head and its dependents may correspond to a discontinuous constituent.</S><S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S><S sid=""12"" ssid=""8"">Prague Dependency Treebank (Hajiˇc et al., 2001b), Danish Dependency Treebank (Kromann, 2003), and the METU Treebank of Turkish (Oflazer et al., 2003), which generally allow annotations with nonprojective dependency structures.</S><S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S>",'Method_Citation'
12,P05-1013,W09-1218,0,"Nivre and Nilsson, 2005",0,"In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","'23','39','62','90'","<S sid=""23"" ssid=""19"">By applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid=""39"" ssid=""10"">However, since we want to preserve as much of the original structure as possible, we are interested in finding a transformation that involves a minimal number of lifts.</S><S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S><S sid=""90"" ssid=""1"">The second experiment is limited to data from PDT.5 The training part of the treebank was projectivized under different encoding schemes and used to train memory-based dependency parsers, which were run on the test part of the treebank, consisting of 7,507 sentences and 125,713 tokens.6 The inverse transformation was applied to the output of the parsers and the result compared to the gold standard test set.</S>",'Method_Citation'
13,P05-1013,C08-1081,0,"Nivre and Nilsson, 2005",0,"Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","'18','29','53','106'","<S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""29"" ssid=""25"">In section 5, we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.</S><S sid=""53"" ssid=""24"">In the third and final scheme, denoted Path, we keep the extra infor2Note that this is a baseline for the parsing experiment only (Experiment 2).</S><S sid=""106"" ssid=""17"">However, the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech, with a best performance of 73% UAS (Holan, 2004).</S>",'Method_Citation'
14,P05-1013,C08-1081,0,2005,0,"Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","'10','31','70','105'","<S sid=""10"" ssid=""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid=""31"" ssid=""2"">Formally, we define dependency graphs as follows: 3.</S><S sid=""70"" ssid=""9"">Except for the left3The graphs satisfy all the well-formedness conditions given in section 2 except (possibly) connectedness.</S><S sid=""105"" ssid=""16"">Although the best published results for the Collins parser is 80% UAS (Collins, 1999), this parser reaches 82% when trained on the entire training data set, and an adapted version of Charniak’s parser (Charniak, 2000) performs at 84% (Jan Hajiˇc, pers. comm.).</S>",'Method_Citation'
15,P05-1013,C08-1081,0,2005,0,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,"'0','8','29','61'","<S sid=""0"" ssid=""1"">Pseudo-Projective Dependency Parsing</S><S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S><S sid=""29"" ssid=""25"">In section 5, we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.</S><S sid=""61"" ssid=""32"">Before we turn to the evaluation, however, we need to introduce the data-driven dependency parser used in the latter experiments.</S>",'Method_Citation'
16,P05-1013,C08-1081,0,2005,0,"Weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","'9','10','51','52'","<S sid=""9"" ssid=""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004).</S><S sid=""10"" ssid=""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid=""51"" ssid=""22"">In the second scheme, Head+Path, we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid=""52"" ssid=""23"">Thus, the arc from je to jedna will be labeled 5b↓ (to indicate that there is a syntactic head below it).</S>",'Method_Citation'
17,P05-1013,D11-1006,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","'12','18','106'","<S sid=""12"" ssid=""8"">Prague Dependency Treebank (Hajiˇc et al., 2001b), Danish Dependency Treebank (Kromann, 2003), and the METU Treebank of Turkish (Oflazer et al., 2003), which generally allow annotations with nonprojective dependency structures.</S><S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""106"" ssid=""17"">However, the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech, with a best performance of 73% UAS (Holan, 2004).</S>",'Method_Citation'
18,P05-1013,P11-2121,0,"Nivre and Nilsson, 2005",0,"Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","'18','29','53','110'","<S sid=""18"" ssid=""14"">In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003).</S><S sid=""29"" ssid=""25"">In section 5, we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.</S><S sid=""53"" ssid=""24"">In the third and final scheme, denoted Path, we keep the extra infor2Note that this is a baseline for the parsing experiment only (Experiment 2).</S><S sid=""110"" ssid=""2"">The main result is that the combined system can recover non-projective dependencies with a precision sufficient to give a significant improvement in overall parsing accuracy, especially with respect to the exact match criterion, leading to the best reported performance for robust non-projective parsing of Czech.</S>",'Method_Citation'
19,P05-1013,E06-1010,0,"Nivre and Nilsson, 2005",0,"Itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (Nivre and Nilsson, 2005)","It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)","'14','19','99'","<S sid=""14"" ssid=""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%, the total proportion of non-projective arcs is normally only 1–2%.</S><S sid=""19"" ssid=""15"">Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004).</S><S sid=""99"" ssid=""10"">This may seem surprising, given the experiments reported in section 4, but the explanation is probably that the non-projective dependencies that can be recovered at all are of the simple kind that only requires a single lift, where the encoding of path information is often redundant.</S>",'Method_Citation'
20,P05-1013,D07-1111,0,"Nivre and Nilsson, 2005",0,"The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (Nivre and Nilsson, 2005)","The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)","'0','24','60','95'","<S sid=""0"" ssid=""1"">Pseudo-Projective Dependency Parsing</S><S sid=""24"" ssid=""20"">We call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al., 1998).</S><S sid=""60"" ssid=""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks, and in section 5 they are applied to parser output.</S><S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>",'Method_Citation'
