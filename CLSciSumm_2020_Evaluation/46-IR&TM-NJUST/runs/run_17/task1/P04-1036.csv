Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","'8','21','107','163'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""107"" ssid=""5"">To disambiguate senses a system should take context into account.</S><S sid=""163"" ssid=""11"">Lapata and Brew (2004) have recently also highlighted the importance of a good prior in WSD.</S>",'Method_Citation'
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","'10','31','151','152'","<S sid=""10"" ssid=""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al., 1993).</S><S sid=""31"" ssid=""24"">In section 5 we present results of the method on two domain specific sections of the Reuters corpus for a sample of words.</S><S sid=""151"" ssid=""28"">This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.</S><S sid=""152"" ssid=""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels, but as we would expect, the other peaks correspond to the economy label for the FINANCE corpus, and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S>",'Method_Citation'
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","'115','157','178','190'","<S sid=""115"" ssid=""13"">Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor, which is very encouraging given that our method only uses raw text, with no manual labelling.</S><S sid=""157"" ssid=""5"">Buitelaar and Sacaleanu have evaluated their method on identifying domain specific concepts using human judgements on 100 items.</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid=""190"" ssid=""13"">Whilst we have used WordNet as our sense inventory, it would be possible to use this method with another inventory given a measure of semantic relatedness between the neighbours and the senses.</S>",'Method_Citation'
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"'10','34','153','167'","<S sid=""10"" ssid=""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al., 1993).</S><S sid=""34"" ssid=""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S><S sid=""153"" ssid=""1"">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S><S sid=""167"" ssid=""15"">In this work the lists of neighbours are themselves clustered to bring out the various senses of the word.</S>",'Method_Citation'
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","'9','21','97','152'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""97"" ssid=""26"">The first ranked sense according to SemCor is the filth, stain: state of being unclean sense whereas the automatic ranking lists dirt, ground, earth as the first sense, which is the second ranked sense according to SemCor.</S><S sid=""152"" ssid=""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels, but as we would expect, the other peaks correspond to the economy label for the FINANCE corpus, and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S>",'Method_Citation'
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","'34','92','101','152'","<S sid=""34"" ssid=""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S><S sid=""92"" ssid=""21"">For example, in WordNet the first listed sense ofpipe is tobacco pipe, and this is ranked joint first according to the Brown files in SemCor with the second sense tube made of metal or plastic used to carry water, oil or gas etc....</S><S sid=""101"" ssid=""30"">Thus, if we used the sense ranking as a heuristic for an “all nouns” task we would expect to get precision in the region of 60%.</S><S sid=""152"" ssid=""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels, but as we would expect, the other peaks correspond to the economy label for the FINANCE corpus, and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S>",'Method_Citation'
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","'127','130','141','150'","<S sid=""127"" ssid=""4"">We chose the domains of SPORTS and FINANCE since there is sufficient material for these domains in this publically available corpus.</S><S sid=""130"" ssid=""7"">We selected documents from the SPORTS domain (topic code: GSPO) and a limited number of documents from the FINANCE domain (topic codes: ECAT and MCAT).</S><S sid=""141"" ssid=""18"">We contrast the distribution of domain labels for these words in the 2 domain specific corpora.</S><S sid=""150"" ssid=""27"">Figure 2 displays the results of the second experiment with the domain specific corpora.</S>",'Method_Citation'
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","'92','95','97','151'","<S sid=""92"" ssid=""21"">For example, in WordNet the first listed sense ofpipe is tobacco pipe, and this is ranked joint first according to the Brown files in SemCor with the second sense tube made of metal or plastic used to carry water, oil or gas etc....</S><S sid=""95"" ssid=""24"">Since SemCor is derived from the Brown corpus, which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6, the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid=""97"" ssid=""26"">The first ranked sense according to SemCor is the filth, stain: state of being unclean sense whereas the automatic ranking lists dirt, ground, earth as the first sense, which is the second ranked sense according to SemCor.</S><S sid=""151"" ssid=""28"">This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.</S>",'Method_Citation'
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","'61','71','142','191'","<S sid=""61"" ssid=""17"">We use the WordNet Similarity Package 0.05 and WordNet version 1.6.</S><S sid=""71"" ssid=""27"">This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal:</S><S sid=""142"" ssid=""19"">The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.</S><S sid=""191"" ssid=""14"">The lesk measure for example, can be used with definitions in any standard machine readable dictionary.</S>",'Method_Citation'
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","'9','21','38','89'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""38"" ssid=""31"">For example, the neighbours of star in a dependency-based thesaurus provided by Lin 1 has the ordered list of neighbours: superstar, player, teammate, actor early in the list, but one can also see words that are related to another sense of star e.g. galaxy, sun, world and planet further down the list.</S><S sid=""89"" ssid=""18"">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the IC files.</S>",'Method_Citation'
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","'38','49','83','182'","<S sid=""38"" ssid=""31"">For example, the neighbours of star in a dependency-based thesaurus provided by Lin 1 has the ordered list of neighbours: superstar, player, teammate, actor early in the list, but one can also see words that are related to another sense of star e.g. galaxy, sun, world and planet further down the list.</S><S sid=""49"" ssid=""5"">Let be the ordered set of the top scoring neighbours of from the thesaurus with associated distributional similarity scores The thesaurus was acquired using the method described by Lin (1998).</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""182"" ssid=""5"">In many cases the sense ranking provided in SemCor differs to that obtained automatically because we used the BNC to produce our thesaurus.</S>",'Method_Citation'
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","'115','137','159','190'","<S sid=""115"" ssid=""13"">Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor, which is very encouraging given that our method only uses raw text, with no manual labelling.</S><S sid=""137"" ssid=""14"">Additionally, we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a, 2000) which annotates WordNet synsets with domain labels.</S><S sid=""159"" ssid=""7"">Magnini and Cavagli`a (2000) have identified WordNet word senses with particular domains, and this has proven useful for high precision WSD (Magnini et al., 2001); indeed in section 5 we used these domain labels for evaluation.</S><S sid=""190"" ssid=""13"">Whilst we have used WordNet as our sense inventory, it would be possible to use this method with another inventory given a measure of semantic relatedness between the neighbours and the senses.</S>",'Method_Citation'
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","'8','9','21','89'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""89"" ssid=""18"">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the IC files.</S>",'Method_Citation'
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","'9','21','93','182'","<S sid=""9"" ssid=""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""93"" ssid=""22"">The automatic ranking from the BNC data lists the latter tube sense first.</S><S sid=""182"" ssid=""5"">In many cases the sense ranking provided in SemCor differs to that obtained automatically because we used the BNC to produce our thesaurus.</S>",'Method_Citation'
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","'13','66','82','153'","<S sid=""13"" ssid=""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid=""66"" ssid=""22"">It uses the glosses of semantically related (according to WordNet) senses too. jcn (Jiang and Conrath, 1997) This score uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts.</S><S sid=""82"" ssid=""11"">We also calculate the WSD accuracy that would be obtained on SemCor, when using our first sense in all contexts ( ).</S><S sid=""153"" ssid=""1"">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S>",'Method_Citation'
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","'25','106','159','172'","<S sid=""25"" ssid=""18"">However, the most accurate WSD systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (Yarowsky and Florian, 2002) available.</S><S sid=""106"" ssid=""4"">We do not assume that the predominant sense is a method of WSD in itself.</S><S sid=""159"" ssid=""7"">Magnini and Cavagli`a (2000) have identified WordNet word senses with particular domains, and this has proven useful for high precision WSD (Magnini et al., 2001); indeed in section 5 we used these domain labels for evaluation.</S><S sid=""172"" ssid=""20"">We believe automatic ranking techniques such as ours will be useful for systems that rely on WordNet, for example those that use it for lexical acquisition or WSD.</S>",'Method_Citation'
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","'8','13','21','84'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""13"" ssid=""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid=""21"" ssid=""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.</S><S sid=""84"" ssid=""13"">The random baseline for choosing the predominant sense over all these words ( ) is 32%.</S>",'Method_Citation'
