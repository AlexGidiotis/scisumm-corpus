Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.As in Clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.5 Discussion Piantadosi et al. (2008) induces first-order formuA major focus of this work is on our semantic rep- lae using CCG in a small domain assuming observed resentation, DCS, which offers a new perspective lexical semantics.This bootstrapping behavior occurs naturally: The “easy” examples are processed first, where easy is defined by the ability of the current model to generate the correct answer using any tree. with scope variation.In each dataset, each sentence x is annotated with a Prolog logical form, which we use only to evaluate and get an answer y.On two stansemantic parsing benchmarks our system obtains the highest published accuracies, despite requiring no annotated logical forms.We first present a basic version (Section 2.1) of dependency-based compositional semantics (DCS), which captures the core idea of using trees to represent formal semantics.Eisenciations due to data sparsity, and having an insuffi- stein et al. (2009) induces conjunctive formulae and ciently large K. uses them as features in another learning problem.Results We first compare our system with Clarke et al. (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs.