Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P08-1043,C10-1045,0,2008,0,"Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew",'190',"<S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
2,P08-1043,P11-1141,0,2008,0,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,"'49','53','167','171'","<S sid=""49"" ssid=""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""167"" ssid=""5"">When using the segmentation pruning (using HSPELL) for unseen tokens, performance improves for all tasks as well.</S><S sid=""171"" ssid=""9"">Secondly, for all our models we provide better fine- and coarse-grained POS-tagging accuracy, and all pruned models outperform the Oracle results reported by them.12 In terms of syntactic disambiguation, even the simplest grammar pruned with HSPELL outperforms their non-Oracle results.</S>","'Method_Citation','Result_Citation'"
3,P08-1043,P10-1074,0,2008,0,"Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing","Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing","'46','49','159','190'","<S sid=""46"" ssid=""4"">The development of the very first Hebrew Treebank (Sima’an et al., 2001) called for the exploration of general statistical parsing methods, but the application was at first limited.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
4,P08-1043,P11-1089,0,2008,0,Goldberg and Tsarfaty (2008) pro pose a generative joint model,Goldberg and Tsarfaty (2008) propose a generative joint model,"'53','158','159','190'","<S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
5,P08-1043,W10-1404,0,2008,0,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,"'53','155','163','190'","<S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""155"" ssid=""33"">Evaluation We use 8 different measures to evaluate the performance of our system on the joint disambiguation task.</S><S sid=""163"" ssid=""1"">The accuracy results for segmentation, tagging and parsing using our different models and our standard data split are summarized in Table 1.</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
6,P08-1043,P11-2124,0,2008,0,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text,"'150','159','188','190'","<S sid=""150"" ssid=""28"">We thank Felix Hageloh (Hageloh, 2006) for providing us with this version. proposed in (Tsarfaty, 2006).</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S><S sid=""188"" ssid=""2"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
7,P08-1043,P11-2124,0,"Goldberg and Tsarfaty, 2008",0,"Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","'70','75','86','112'","<S sid=""70"" ssid=""2"">Each lattice arc corresponds to a segment and its corresponding PoS tag, and a path through the lattice corresponds to a specific morphological segmentation of the utterance.</S><S sid=""75"" ssid=""7"">Every token is independent of the others, and the sentence lattice is in fact a concatenation of smaller lattices, one for each token.</S><S sid=""86"" ssid=""18"">A morphological analyzer M : W—* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).</S><S sid=""112"" ssid=""44"">We first make use of our morphological analyzer to find all segmentation possibilities by chopping off all prefix sequence possibilities (including the empty prefix) and construct a lattice off of them.</S>",'Method_Citation'
8,P08-1043,P12-2002,0,2008,0,2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),"'47','69','133','158'","<S sid=""47"" ssid=""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid=""69"" ssid=""1"">We represent all morphological analyses of a given utterance using a lattice structure.</S><S sid=""133"" ssid=""11"">Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S>",'Method_Citation'
9,P08-1043,D12-1046,0,"Goldberg and Tsarfaty, 2008",0,"A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","'53','140','158','159'","<S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""140"" ssid=""18"">For these models we limit the options provided for OOV words by not considering the entire token as a valid segmentation in case at least some prefix segmentation exists.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S>",'Method_Citation'
10,P08-1043,D12-1133,0,2008,0,"Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","'49','53','158','190'","<S sid=""49"" ssid=""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
11,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec","Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)","'0','19','49','190'","<S sid=""0"" ssid=""1"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S sid=""19"" ssid=""15"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""190"" ssid=""4"">We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",'Method_Citation'
12,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","'50','102','150'","<S sid=""50"" ssid=""8"">The joint morphological and syntactic hypothesis was first discussed in (Tsarfaty, 2006; Tsarfaty and Sima’an, 2004) and empirically explored in (Tsarfaty, 2006).</S><S sid=""102"" ssid=""34"">In order to pass these constraints onto the parser, the lexical rules in the grammar are of the form pi —* (si, pi) Parameter Estimation The grammar probabilities are estimated from the corpus using simple relative frequency estimates.</S><S sid=""150"" ssid=""28"">We thank Felix Hageloh (Hageloh, 2006) for providing us with this version. proposed in (Tsarfaty, 2006).</S>",'Method_Citation'
14,P08-1043,E09-1038,0,2008,0,"Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","'52','53','96','158'","<S sid=""52"" ssid=""10"">Cohen and Smith (2007) later on based a system for joint inference on factored, independent, morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid=""53"" ssid=""11"">Both (Tsarfaty, 2006; Cohen and Smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.</S><S sid=""96"" ssid=""28"">This is a unique object for which we are able to define a proper probability model.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S>",'Method_Citation'
15,P08-1043,E09-1038,0,2008,0,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,"'47','127','134','193'","<S sid=""47"" ssid=""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid=""127"" ssid=""5"">Data We use the Hebrew Treebank, (Sima’an et al., 2001), provided by the knowledge center for processing Hebrew, in which sentences from the daily newspaper “Ha’aretz” are morphologically segmented and syntactically annotated.</S><S sid=""134"" ssid=""12"">Such resources exist for Hebrew (Itai et al., 2006), but unfortunately use a tagging scheme which is incompatible with the one of the Hebrew Treebank.s For this reason, we use a data-driven morphological analyzer derived from the training data similar to (Cohen and Smith, 2007).</S><S sid=""193"" ssid=""7"">(Levinger et al., 1995; Goldberg et al., ; Adler et al., 2008)) will make the parser more robust and suitable for use in more realistic scenarios.</S>",'Method_Citation'
16,P08-1043,E09-1038,0,2008,0,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,"'25','75','112','149'","<S sid=""25"" ssid=""4"">While the linear precedence of segmental morphemes within a token is subject to constraints, the dominance relations among their mother and sister constituents is rather free.</S><S sid=""75"" ssid=""7"">Every token is independent of the others, and the sentence lattice is in fact a concatenation of smaller lattices, one for each token.</S><S sid=""112"" ssid=""44"">We first make use of our morphological analyzer to find all segmentation possibilities by chopping off all prefix sequence possibilities (including the empty prefix) and construct a lattice off of them.</S><S sid=""149"" ssid=""27"">We use a patched version of BitPar allowing for direct input of probabilities instead of counts.</S>",'Method_Citation'
17,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units","Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units","'84','107','156','157'","<S sid=""84"" ssid=""16"">The entries in such a lexicon may be thought of as meaningful surface segments paired up with their PoS tags li = (si, pi), but note that a surface segment s need not be a space-delimited token.</S><S sid=""107"" ssid=""39"">Firstly, Hebrew unknown tokens are doubly unknown: each unknown token may correspond to several segmentation possibilities, and each segment in such sequences may be able to admit multiple PoS tags.</S><S sid=""156"" ssid=""34"">To evaluate the performance on the segmentation task, we report SEG, the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid=""157"" ssid=""35"">SEGTok(noH) is the segmentation accuracy ignoring mistakes involving the implicit definite article h.11 To evaluate our performance on the tagging task we report CPOS and FPOS corresponding to coarse- and fine-grained PoS tagging results (F1) measure.</S>",'Method_Citation'
