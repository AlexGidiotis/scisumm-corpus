When dropping the top and bottom 2.5% the remaining BLEU scores define the range of the confidence interval.For instance: if 10 systems participate, and one system does better than 3 others, worse then 2, and is not significant different from the remaining 4, its rank is in the interval 3â€“7.For statistics on this test set, refer to Figure 1.This is demonstrated by average scores over all systems, in terms of BLEU, fluency and adequacy, as displayed in Figure 5.Again, we can compute average scores for all systems for the different language pairs (Figure 6).While we had up to 11 submissions for a translation direction, we did decide against presenting all 11 system outputs to the human judge.This is less than the 694 judgements 2004 DARPA/NIST evaluation, or the 532 judgements in the 2005 DARPA/NIST evaluation.We divide up each test set into blocks of 20 sentences (100 blocks for the in-domain test set, 53 blocks for the out-of-domain test set), check for each block, if one system has a higher BLEU score than the other, and then use the sign test.We can check, what the consequences of less manual annotation of results would have been: With half the number of manual judgements, we can distinguish about 40% of the systems, 10% less.The test set included 2000 sentences from the Europarl corpus, but also 1064 sentences out-ofdomain test data.