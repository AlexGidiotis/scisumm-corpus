The average fluency judgement per judge ranged from 2.33 to 3.67, the average adequacy judgement ranged from 2.56 to 4.13.For statistics on this test set, refer to Figure 1.The BLEU score has been shown to correlate well with human judgement, when statistical machine translation systems are compared (Doddington, 2002; Przybocki, 2004; Li, 2005).The test set included 2000 sentences from the Europarl corpus, but also 1064 sentences out-ofdomain test data.The test data was again drawn from a segment of the Europarl corpus from the fourth quarter of 2000, which is excluded from the training data.We confirm the finding by Callison-Burch et al. (2006) that the rule-based system of Systran is not adequately appreciated by BLEU.This is can not be the only explanation, since the discrepancy still holds, for instance, for out-of-domain French-English, where Systran receives among the best adequacy and fluency scores, but a worse BLEU score than all but one statistical system.One annotator suggested that this was the case for as much as 10% of our test sentences.Systran submitted their commercial rule-based system that was not tuned to the Europarl corpus.However, a recent study (Callison-Burch et al., 2006), pointed out that this correlation may not always be strong.Systems that generally do better than others will receive a positive average normalizedjudgement per sentence.