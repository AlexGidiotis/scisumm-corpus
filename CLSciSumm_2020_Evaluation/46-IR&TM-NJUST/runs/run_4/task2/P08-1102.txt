On the Penn Chinese Treebank 5.0, we obtain an error reduction of segmentation and joint segmentation and part-of-speech tagging over the perceptron-only baseline.We trained a character-based perceptron for Chinese Joint S&T, and found that the perceptron itself could achieve considerably high accuracy on segmentation and Joint S&T.Besides the usual character-based features, additional features dependent on POSâ€™s or words can also be employed to improve the performance.Figure 2 shows the growing tendency of feature space with the introduction of these features as well as the character-based ones.Here the core perceptron was just the POS+ model in experiments above.We find that the cascaded model achieves a F-measure increment of about 0.5 points on segmentation and about 0.9 points on Joint S&T, over the perceptron-only model POS+.Additional features most widely used are related to word or POS ngrams.Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved Fmeasure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation.The feature templates we adopted are selected from those of Ng and Low (2004).Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target.By maintaining a stack of size N at each position i of the sequence, we can preserve the top N best candidate labelled results of subsequence C1:i during decoding.As predications generated from such templates depend on the current character, we name these templates lexical-target.