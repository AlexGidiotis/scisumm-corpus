We have presented a lexicalized Markov grammar parsing model that achieves (using the now standard training/testing/development sections of the Penn treebank) an average precision/recall of 91.1% on sentences of length < 40 and 89.5% on sentences of length < 100.The results of [13] achieved by combining the aforementioned three-best parsers also suggest that the limit on tree-bank trained parsers is much higher than previously thought.The results for the new parser as well as for the previous top-three individual parsers on this corpus are given in Figure 1.Between the Old model and the Best model, Figure 2 gives precision/recall measurements for several different versions of our parser.One of the first and without doubt the most significant change we made in the current parser is to move from two stages of probabilistic decisions at each node to three.In the more interesting version, Equation 7, this is not true in general, but one would not expect it to differ much from one, and we assume that as long as we are not publishing the raw probabilities (as we would be doing, for example, in publishing perplexity results) the difference from one should be unimportant.First, it uses a clustering scheme on words to give the system a "soft" clustering of heads and sub-heads.As already noted, Char97 first guesses the lexical head of a constituent and then, given the head, guesses the PCFG rule used to expand the constituent in question.