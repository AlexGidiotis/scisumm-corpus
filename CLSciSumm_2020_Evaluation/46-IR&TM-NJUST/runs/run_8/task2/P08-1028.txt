Specifically, we present both additive and multiplicative models of vector combination and assess their performance on a sentence similarity rating experiment.To overcome this problem, other techniques have been proposed in which the binding of two vectors results in a vector which has the same dimensionality as its components.We define a general class of models for this process of composition as: The expression above allows us to derive models for which p is constructed in a distinct space from u and v, as is the case for tensor products.As a result of the assumption of symmetry, both these models are ‘bag of words’ models and word order insensitive.First, the additive model in (7) weighs differentially the contribution of the two constituents.The projection is defined in terms of circular convolution a mathematical function that compresses the tensor product of two vectors.Here, we are interested in relative differences, since the two types of ratings correspond to different scales.One particularly useful constraint is to hold R fixed by focusing on a single well defined linguistic structure, for example the verb-subject relation.Another simplification concerns K which can be ignored so as to explore what can be achieved in the absence of additional knowledge.Specifically, they belonged to different synsets and were maximally dissimilar as measured by the Jiang and Conrath (1997) measure.3 Our initial set of candidate materials consisted of 20 verbs, each paired with 10 nouns, and 2 landmarks (400 pairs of sentences in total).