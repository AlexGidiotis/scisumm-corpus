As to the processing time, the PCFG reduction parses each sentence 100 words) in 3.6 seconds average, while the parser in Bod (2001, 2003), which uses over 5 million subtrees, is reported to take about 220 seconds per sentence.This suggests that a model which combines these two notions of best parse may boost the accuracy.We will refer to these models as Likelihood-DOP models, but in this paper we will specifically mean by "Likelihood-DOP" the PCFG-reduction of Bod (2001) given in Section 2.2.Table 2 shows the results for sentences 100 words for various values of n. Note that there is an increase in accuracy for both SL-DOP and LS-DOP if the value of n increases from 1 to 12.Yet, his grammar contains more than 5 million subtrees and processing times of over 200 seconds per WSJ sentence are reported (Bod 2003).For the node in figure 1, the following eight PCFG rules are generated, where the number in parentheses following a rule is its probability.That is, all subtrees of each root label are assigned a rank according to their frequency in the treebank: the most frequent subtree (or subtrees) of each root label gets rank 1, the second most frequent subtree gets rank 2, etc.A new nonterminal is created for each node in the training data.The only thing that needs to be changed for Simplicity-DOP is that all subtrees should be assigned equal probabilities.