As in Clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.5 Discussion Piantadosi et al. (2008) induces first-order formuA major focus of this work is on our semantic rep- lae using CCG in a small domain assuming observed resentation, DCS, which offers a new perspective lexical semantics.The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).However, we still model the logical form (now as a latent variable) to capture the complexities of language.We first present a basic version (Section 2.1) of dependency-based compositional semantics (DCS), which captures the core idea of using trees to represent formal semantics.Results We first compare our system with Clarke et al. (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs.Our learning algorithm alternates between (i) using the current parameters θ to generate the K-best set ˜ZL,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.Figure 1 shows our probabilistic model: with respect to a world w (database of facts), producing an answer y.In some sense, this is the technical core of DCS.