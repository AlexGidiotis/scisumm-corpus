The constituent voting and na√Øve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.The entries in this table can be compared with those of Table 3 to see how the performance of the combining techniques degrades in the presence of an inferior parser.Furthermore, we know one of the original parses will be the hypothesized parse, so the direct method of determining which one is best is to compute the probability of each of the candidate parses using the probabilistic model we developed in Section 2.1.If we were working with more than three parsers we could investigate minority constituents, those constituents that are suggested by at least one parser, but which the majority of the parsers do not suggest.We do not show the numbers for the Bayes models in Table 2 because the parameters involved were established using this set.It is chosen such that the decisions it made in including or excluding constituents are most probable under the models for all of the parsers.The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank, leaving only sections 22 and 23 completely untouched during the development of any of the parsers.From this we see that a finer-grained model for parser combination, at least for the features we have examined, will not give us any additional power.