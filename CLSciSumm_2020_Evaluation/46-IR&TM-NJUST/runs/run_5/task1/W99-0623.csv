Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Reference Citation
1,W99-0623,A00-2005,0,1999,0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,"'40','71','116','146'","<S sid=""40"" ssid=""26"">Lemma: If the number of votes required by constituent voting is greater than half of the parsers under consideration the resulting structure has no crossing constituents.</S><S sid=""71"" ssid=""57"">It is chosen such that the decisions it made in including or excluding constituents are most probable under the models for all of the parsers.</S><S sid=""116"" ssid=""45"">The maximum precision row is the upper bound on accuracy if we could pick exactly the correct constituents from among the constituents suggested by the three parsers.</S><S sid=""146"" ssid=""1"">We would like to thank Eugene Charniak, Michael Collins, and Adwait Ratnaparkhi for enabling all of this research by providing us with their parsers and helpful comments.</S>",'Method_Citation'
2,W99-0623,A00-2005,0,1999,0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)","'38','57','89','94'","<S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid=""57"" ssid=""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S><S sid=""89"" ssid=""18"">None of the models we have presented utilize features associated with a particular constituent (i.e. the label, span, parent label, etc.) to influence parser preference.</S><S sid=""94"" ssid=""23"">This is the only important case, because otherwise the simple majority combining technique would pick the correct constituent.</S>",'Method_Citation'
4,W99-0623,N10-1091,0,"Henderson and Brill, 1999",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","'22','46','71','101'","<S sid=""22"" ssid=""8"">If enough parsers suggest that a particular constituent belongs in the parse, we include it.</S><S sid=""46"" ssid=""32"">None of the parsers produce parses with crossing brackets, so none of them votes for both of the assumed constituents.</S><S sid=""71"" ssid=""57"">It is chosen such that the decisions it made in including or excluding constituents are most probable under the models for all of the parsers.</S><S sid=""101"" ssid=""30"">We show the results of three of the experiments we conducted to measure isolated constituent precision under various partitioning schemes.</S>",'Method_Citation'
5,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","'38','41','48'","<S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid=""41"" ssid=""27"">IL+-1Proof: Assume a pair of crossing constituents appears in the output of the constituent voting technique using k parsers.</S><S sid=""48"" ssid=""34"">• Similarly, when the naïve Bayes classifier is configured such that the constituents require estimated probabilities strictly larger than 0.5 to be accepted, there is not enough probability mass remaining on crossing brackets for them to be included in the hypothesis.</S>",'Method_Citation'
6,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization","'32','48','119','124'","<S sid=""32"" ssid=""18"">In Equations 1 through 3 we develop the model for constructing our parse using naïve Bayes classification.</S><S sid=""48"" ssid=""34"">• Similarly, when the naïve Bayes classifier is configured such that the constituents require estimated probabilities strictly larger than 0.5 to be accepted, there is not enough probability mass remaining on crossing brackets for them to be included in the hypothesis.</S><S sid=""119"" ssid=""48"">We do not show the numbers for the Bayes models in Table 2 because the parameters involved were established using this set.</S><S sid=""124"" ssid=""53"">This is the first set that gives us a fair evaluation of the Bayes models, and the Bayes switching model performs significantly better than its non-parametric counterpart.</S>",'Method_Citation'
7,W99-0623,W05-1518,0,1999,0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,'135',"<S sid=""135"" ssid=""64"">The average individual parser accuracy was reduced by more than 5% when we added this new parser, but the precision of the constituent voting technique was the only result that decreased significantly.</S>",'Result_Citation'
8,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","'1','19','120','130'","<S sid=""1"" ssid=""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy.</S><S sid=""19"" ssid=""5"">The precision and recall measures (described in more detail in Section 3) used in evaluating Treebank parsing treat each constituent as a separate entity, a minimal unit of correctness.</S><S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid=""130"" ssid=""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S>",'Method_Citation'
10,W99-0623,P01-1005,0,"Henderson and Brill, 1999",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","'9','38','126'","<S sid=""9"" ssid=""5"">Recently, combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al., 1998; Brill and Wu, 1998).</S><S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid=""126"" ssid=""55"">Table 4 shows how much the Bayes switching technique uses each of the parsers on the test set.</S>",'Method_Citation'
11,W99-0623,D09-1161,0,1999,0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","'55','100','127','133'","<S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid=""100"" ssid=""29"">When this metric is less than 0.5, we expect to incur more errors' than we will remove by adding those constituents to the parse.</S><S sid=""127"" ssid=""56"">Parser 3, the most accurate parser, was chosen 71% of the time, and Parser 1, the least accurate parser was chosen 16% of the time.</S><S sid=""133"" ssid=""62"">The entries in this table can be compared with those of Table 3 to see how the performance of the combining techniques degrades in the presence of an inferior parser.</S>",'Method_Citation'
12,W99-0623,D09-1161,0,1999,0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","'40','46','57','146'","<S sid=""40"" ssid=""26"">Lemma: If the number of votes required by constituent voting is greater than half of the parsers under consideration the resulting structure has no crossing constituents.</S><S sid=""46"" ssid=""32"">None of the parsers produce parses with crossing brackets, so none of them votes for both of the assumed constituents.</S><S sid=""57"" ssid=""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S><S sid=""146"" ssid=""1"">We would like to thank Eugene Charniak, Michael Collins, and Adwait Ratnaparkhi for enabling all of this research by providing us with their parsers and helpful comments.</S>",'Method_Citation'
13,W99-0623,D09-1161,0,"Henderson and Brill, 1999",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","'36','102'","<S sid=""36"" ssid=""22"">The estimation of the probabilities in the model is carried out as shown in Equation 4.</S><S sid=""102"" ssid=""31"">In Table 1 we see with very few exceptions that the isolated constituent precision is less than 0.5 when we use the constituent label as a feature.</S>",'Method_Citation'
14,W99-0623,N06-2033,0,"Henderson and Brill, 1999",0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","'24','55','84','146'","<S sid=""24"" ssid=""10"">We include a constituent in our hypothesized parse if it appears in the output of a majority of the parsers.</S><S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid=""84"" ssid=""13"">The first shows how constituent features and context do not help in deciding which parser to trust.</S><S sid=""146"" ssid=""1"">We would like to thank Eugene Charniak, Michael Collins, and Adwait Ratnaparkhi for enabling all of this research by providing us with their parsers and helpful comments.</S>",'Method_Citation'
15,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","'55','95','104','107'","<S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid=""95"" ssid=""24"">One side of the decision making process is when we choose to believe a constituent should be in the parse, even though only one parser suggests it.</S><S sid=""104"" ssid=""33"">In the cases where isolated constituent precision is larger than 0.5 the affected portion of the hypotheses is negligible.</S><S sid=""107"" ssid=""36"">Again we notice that the isolated constituent precision is larger than 0.5 only in those partitions that contain very few samples.</S>",'Method_Citation'
16,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","'67','71','98','99'","<S sid=""67"" ssid=""53"">The set of candidate constituents comes from the union of all the constituents suggested by the member parsers.</S><S sid=""71"" ssid=""57"">It is chosen such that the decisions it made in including or excluding constituents are most probable under the models for all of the parsers.</S><S sid=""98"" ssid=""27"">Adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.</S><S sid=""99"" ssid=""28"">Consider for a set of constituents the isolated constituent precision parser metric, the portion of isolated constituents that are correctly hypothesized.</S>",'Method_Citation'
17,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","'19','31','61','102'","<S sid=""19"" ssid=""5"">The precision and recall measures (described in more detail in Section 3) used in evaluating Treebank parsing treat each constituent as a separate entity, a minimal unit of correctness.</S><S sid=""31"" ssid=""17"">For this reason, naïve Bayes classifiers are well-matched to this problem.</S><S sid=""61"" ssid=""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid=""102"" ssid=""31"">In Table 1 we see with very few exceptions that the isolated constituent precision is less than 0.5 when we use the constituent label as a feature.</S>",'Method_Citation'
18,W99-0623,P09-1065,0,"Henderson and Brill, 1999",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))",'20',"<S sid=""20"" ssid=""6"">Since our goal is to perform well under these measures we will similarly treat constituents as the minimal substructures for combination.</S>",'Method_Citation'
20,W99-0623,C10-1151,0,1999,0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,"'55','95','104','107'","<S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid=""95"" ssid=""24"">One side of the decision making process is when we choose to believe a constituent should be in the parse, even though only one parser suggests it.</S><S sid=""104"" ssid=""33"">In the cases where isolated constituent precision is larger than 0.5 the affected portion of the hypotheses is negligible.</S><S sid=""107"" ssid=""36"">Again we notice that the isolated constituent precision is larger than 0.5 only in those partitions that contain very few samples.</S>",'Method_Citation'
