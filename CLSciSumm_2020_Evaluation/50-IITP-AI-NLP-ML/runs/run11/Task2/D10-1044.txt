this is a standard adaptation problem for smt.
we obtained positive results using a very simple phrase-based system in two different adaptation settings: using english/french europarl to improve a performance on a small, specialized medical domain; and using non-news portions of the nist09 training material to improve performance on the news-related corpora.
it is also worth pointing out a connection with daum´e’s (2007) work that splits each feature into domain-specific and general copies.
the paper is structured as follows.
the linear lm (lin lm), tm (lin tm) and map tm (map tm) used with non-adapted counterparts perform in all cases slightly worse than the log-linear combination, which adapts both lm and tm components.
finally, we make some improvements to baseline approaches.
the 4th block contains instance-weighting models trained on all features, used within a map tm combination, and with a linear lm mixture.
finally, we note that jiang’s instance-weighting framework is broader than we have presented above, encompassing among other possibilities the use of unlabelled in data, which is applicable to smt settings where source-only in corpora are available.
experiments are presented in section 4.
this suggests a direct parallel to (1): where ˜p(s, t) is a joint empirical distribution extracted from the in dev set using the standard procedure.2 an alternative form of linear combination is a maximum a posteriori (map) combination (bacchiani et al., 2004).
we extend the matsoukas et al approach in several ways.
matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities.
we will also directly compare with a baseline similar to the matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.
