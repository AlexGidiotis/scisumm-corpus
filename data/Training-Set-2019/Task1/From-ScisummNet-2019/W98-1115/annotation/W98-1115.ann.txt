Citance Number: 1 | Reference Article:  W98-1115.txt | Citing Article:  P99-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al, 1993), and additional parsed text was obtained by parsing the Wall Street Journal text using the parser described in Charniak et al (1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (Marcus et al., 1993), with section 22 reserved for testing.</S><S sid = NA ssid = NA>Our figures were obtained using ri = 1.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W98-1115.txt | Citing Article:  E12-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Using this information, the model described in (Charniak et al 1998) is P (s|h, t, l).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We applied the binarization technique described above to the grammar.</S><S sid = NA ssid = NA>Our figures were obtained using ri = 1.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W98-1115.txt | Citing Article:  H05-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Charniak et al (1998) and Caraballo and Charniak (1998) showed that, when seeking the best parse (using min= or max=), best-first parsing can be extremely effective.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Probably the most extensive comparison of possible metrics for best-first PCFG parsing is that of Caraballo and Charniak (henceforth C&C) (Forthcoming).</S><S sid = NA ssid = NA>Edge-Based Best-First Chart Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W98-1115.txt | Citing Article:  D08-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Therein, the idea of coarse-to-fine parsing (Charniak et al, 1998) is extended to handle the repeated parsing of the same sentences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Once this has been done there is no need for incomplete edges at all in bottomup parsing, and parsing can be performed using the CKY algorithm, suitably extended to handle unary productions.</S><S sid = NA ssid = NA>One well-known 0(n3) parsing method (Kay, 1980) is chart parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W98-1115.txt | Citing Article:  W04-3203.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>One paper that focuses on efficiency of statistical parsing is Charniak et al (1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We make the same assumption in this paper.</S><S sid = NA ssid = NA>As noted, our paper takes off from that of C&C and uses the same FOM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W98-1115.txt | Citing Article:  P04-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Charniak et al (1998) introduce overparsing as a technique to improve parse accuracy by continuing parsing after the first complete parse tree is found.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Note that regardless of 7/ the accuracy of the parse increases given extra time, but that all of the increase is achieved with only 1.5 to 2 times as many edges as needed for the first parse.</S><S sid = NA ssid = NA>As such we strongly recommend this technique to others interested in PCFG parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W98-1115.txt | Citing Article:  P06-2089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This binarization process is similar to the one described in (Charniak et al, 1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We applied the binarization technique described above to the grammar.</S><S sid = NA ssid = NA>Goodman uses an FOM that is similar to that of C&C but one that should, in general, be somewhat more accurate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W98-1115.txt | Citing Article:  P10-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Here, we observe an effect seen in previous work (Charniak et al (1998), Petrov and Klein (2007), Petrov et al (2008)), that a certain amount of pruning helps accuracy, perhaps by promoting agreement between the coarse and full grammars (model intersection).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As can be seen, our parser requires about one twentieth the number of edges required by C&C.</S><S sid = NA ssid = NA>This has the effect of multiplying the inside probability /3(N.4) by rik-J.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W98-1115.txt | Citing Article:  D08-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Two grammars are equivalent if they define the same probability distribution over strings (Charniak et al, 1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have empirically measured the normalization factor and found that the bi-tag distribution produces probabilities that are approximately 1.3 times those produced by the PCFG distribution, on a per-word basis.</S><S sid = NA ssid = NA>One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs (Charniak, 1997), or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components (Magerman, 1995; Collins, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W98-1115.txt | Citing Article:  D08-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As shown in Charniak et al (1998), we can binarize explicitly and use intermediate symbols to replace dotted rules in chart parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The average number of popped edges to first parse as a function of q is shown in Figure 1, and the average precision and recall are shown in Figure 2.</S><S sid = NA ssid = NA>Edge-Based Best-First Chart Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W98-1115.txt | Citing Article:  N03-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Chitrao and Grishman (1990), Caraballo and Charniak (1998), Charniak et al (1998), and Collins (1999) describe best-first parsing, which is intended for a tabular item-based framework.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Bobrow (1990) and Chitrao and Grishman (1990) introduced best-first PCFG parsing, the approach taken here.</S><S sid = NA ssid = NA>Edge-Based Best-First Chart Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W98-1115.txt | Citing Article:  N03-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>I-TRIE is a non-deterministic left branching trie with weights on rule entry as in Charniak et al (1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The key observation is that the 'new' non-terminals `01,i' in a CKY parse using a left-factored grammar correspond to the set of non-empty incomplete edges A -4 01,z.</S><S sid = NA ssid = NA>Specifically, the fundamental rule of chart parsing (Kay, 1980), which combines an incomplete edge A --* a • BO with a complete edge B 7- to yield the edge A -+ a B • 0, corresponds to the left-factored productions `aB' --+ a B if /3 is non-empty or A 'a' B if i3 is empty.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W98-1115.txt | Citing Article:  N03-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following (Charniak et al, 1998), we parsed unseen sentences of length 18-26 from the Penn Treebank, using the grammar induced from the remainder of the treebank.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Figure 4 we reproduce C&C's results on the percentage of sentences (length 18-26) parsed as a function of number of edges used.</S><S sid = NA ssid = NA>In our work we have found that exhaustively parsing maximum-40-word sentences from the Penn II treebank requires an average of about 1.2 million edges per sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W98-1115.txt | Citing Article:  N03-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>On the other hand, the more complex, tuned FOM in (Charniak et al, 1998) is able to parse all of these sentences using around 2K edges, while BF requires 7K edges.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As can be seen, our parser requires about one twentieth the number of edges required by C&C.</S><S sid = NA ssid = NA>In our work we have found that exhaustively parsing maximum-40-word sentences from the Penn II treebank requires an average of about 1.2 million edges per sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W98-1115.txt | Citing Article:  N03-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The complex FOMs in (Charniak et al, 1998) require somewhat more online computation to assemble.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Goodman uses an FOM that is similar to that of C&C but one that should, in general, be somewhat more accurate.</S><S sid = NA ssid = NA>Subsequent work has suggested different FOMs built from PCFG probabilities (Miller and Fox.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W98-1115.txt | Citing Article:  N07-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As such we strongly recommend this technique to others interested in PCFG parsing.</S><S sid = NA ssid = NA>Here NJ, is a constituent of type i (e.g., NP, VP, etc.) that spans the constituents from j up to but not including k, and tom are the n parts-of-speech (tags) of the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W98-1115.txt | Citing Article:  P11-2126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the training phase, each target-style parse tree in the training data is transformed into a binary tree (Charniak et al, 1998) and then decomposed into a (golden) action-state sequence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (Marcus et al., 1993), with section 22 reserved for testing.</S><S sid = NA ssid = NA>Of the five terms in Equation 4, two can be directly estimated from training data: the &quot;boundary statistics&quot; p(N.:,k I tj) (the probability of a constituent of type NIAstarting just after the tag tj) and p(tk I NIA) (the probability of tk appearing just after the end of a constituent of type N.4).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W98-1115.txt | Citing Article:  N09-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This measure is used by Charniak et al (1998) and Klein and Manning (2003b).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (Marcus et al., 1993), with section 22 reserved for testing.</S><S sid = NA ssid = NA>We chose to measure the amount of work done by the parser in terms of the average number of edges popped off the agenda before finding a parse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W98-1115.txt | Citing Article:  C00-1078.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>With respect to chart parsing, (Charniak et al, 1998) report that their parser can achieve good results while producing about three times tile mininmm number of edges required to produce the final parse.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since the average number of edges required to construct just the (left-factored) test corpus trees is 47.5, our parsing system considers as few as 3 times as many edges as are required to actually produce the output tree.</S><S sid = NA ssid = NA>As can be seen, our parser requires about one twentieth the number of edges required by C&C.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W98-1115.txt | Citing Article:  N06-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Related approaches are used in Hall (2004) and Charniak and Johnson (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have two (possibly related) theories of these phenomona.</S><S sid = NA ssid = NA>In Figure 4 we reproduce C&C's results on the percentage of sentences (length 18-26) parsed as a function of number of edges used.</S> | Discourse Facet:  NA | Annotator: Automatic


