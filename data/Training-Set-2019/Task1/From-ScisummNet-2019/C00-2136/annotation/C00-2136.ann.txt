Citance Number: 1 | Reference Article:  C00-2136.txt | Citing Article:  W01-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>On the one hand machine learning is used to automate as much as possible the tasks an IE expert would perform in application development (Cardie 1997) (Yangarber et al 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S><S sid = NA ssid = NA>These dit\[iculties have stimulate.d resear('h on 1)attel . 'n a ( : ( lu i s i t ion . So lne o f th i s work has en l - i)hasized il\]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot:' the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al, 1992; Fisher et al, 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>learned, otherwise go to step 4 Previous algorithms which use this approach include those described by Yangarber et al (2000) and Stevenson and Greenwood (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S><S sid = NA ssid = NA>I/,epeat the procedure (from step 1) until some iteration limit is reached, or no more patterns can be added.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The extraction patterns used by both Yangarber et al (2000) and Stevenson and Greenwood (2005) were based on SVO tuples extracted from dependency trees.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S><S sid = NA ssid = NA>These dit\[iculties have stimulate.d resear('h on 1)attel . 'n a ( : ( lu i s i t ion . So lne o f th i s work has en l - i)hasized il\]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot:' the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al, 1992; Fisher et al, 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yangarber et al (2000) suggested a method where patterns were compared based on their distribution across documents in a corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, the review and augmenta- tion process took little time, as compared to the manual corpus analysis and development of the pattern base.</S><S sid = NA ssid = NA>split of the corpus into relevant and non- relevant documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yangarber et al (2000) proposed an algorithm for learning extraction patterns for a small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Automatic Acquisition Of Domain Knowledge For Information Extraction</S><S sid = NA ssid = NA>These dit\[iculties have stimulate.d resear('h on 1)attel . 'n a ( : ( lu i s i t ion . So lne o f th i s work has en l - i)hasized il\]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot:' the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al, 1992; Fisher et al, 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yangarber et al (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>tins U into a set of relewmt documents, R (which contain at; least one instance of one of the patterns), and a set of non-relevant documents R = U - R. 2.</S><S sid = NA ssid = NA>split of the corpus into relevant and non- relevant documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This approach has been shown to successfully acquire useful extraction patterns which, when added to an IE system, improved its performance (Yangarber et al, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, Proteus performance depends on many fimtors besides the event patterns, such as the quality of name re, cognition, syntactic mmlysis, anaphora reso~ lution, inferencing, etc. Several of these were improved since the MUC formal evaluation, so some of the gain over the MUC formal evalua- tion score is attritmtable to these factors.</S><S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C00-2136.txt | Citing Article:  P07-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Architecture This architecture has been inspired by several existing seed-oriented minimally supervised ma chine learning systems, in particular by Snowball (Agichtein and Gravano, 2000) and ExDisco (Yangarber et al, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>ExDIscO attains values within the range of the MUC participald;S, all of which were either heavily-supervised or m~mually coded systems.</S><S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C00-2136.txt | Citing Article:  W03-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>ExDisco (Yangarber et al,2000) uses a bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Search tbr new candidate patterns:.</S><S sid = NA ssid = NA>Use the new pattern set; to induce a new.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C00-2136.txt | Citing Article:  W06-0202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, the AutoSlog system (Riloff, 1993) uses pat terns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while Yangarber et al (2000) use subject-verb object tuples derived from a dependency parse.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>ExDIsco was seeded with lninimal pattern sets, namely: Subject Verb Direct Object C-Company C-At)point C-Person C-Person C-Resign ibr the Mmmgement task, and Subject Verb Direct Object * C-Buy C-Conlt)any C-Company merge * for Acquisitions.</S><S sid = NA ssid = NA>Because tuples may not repeat with sufficient frequency to obtain reliable statistics, each tu- ple is reduced to a set of pints: e.g., a verb- object pair, a subject-object pair, etc. Each pair is used as a generalized pattern during the can- didate selection stage.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C00-2136.txt | Citing Article:  N07-2043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized ,e.g. Riloff (1996), Yangarber et al (2000), and Sekine (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S><S sid = NA ssid = NA>Automatic Acquisition Of Domain Knowledge For Information Extraction</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C00-2136.txt | Citing Article:  W09-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Bootstrapping approaches are employed in (Riloff, 1996), (Yangarber et al, 2000), (Yangarber, 2003), and (Stevenson and Greenwood, 2005) in order to find IE patterns for domain-specific event extraction.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Automatic Acquisition Of Domain Knowledge For Information Extraction</S><S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C00-2136.txt | Citing Article:  W06-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, EXDISCO (Yangarber et al., 2000) used Wall Street Journal articles for training.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We used a corlms of 9,224 articles from the Wall Street; Journal.</S><S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C00-2136.txt | Citing Article:  P05-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>meets the density criterion (as defined in (Yangarber et al, 2000)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S><S sid = NA ssid = NA>These dit\[iculties have stimulate.d resear('h on 1)attel . 'n a ( : ( lu i s i t ion . So lne o f th i s work has en l - i)hasized il\]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot:' the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al, 1992; Fisher et al, 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>AutoSlog TS, does not require a pre-annotated corpus, but does require one that has been split into subsets that are relevant vs. non-relevant subsets to the scenario. (Yangarber et al, 2000) attempts to find extraction patterns, without a pre-classified corpus, starting from a set of seed patterns.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>split of the corpus into relevant and non- relevant documents.</S><S sid = NA ssid = NA>However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We first present the basic algorithm for pattern acquisition, similar to that presented in (Yangarber et al., 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Optionally, at this point, we may present he pattern to the user for review.)</S><S sid = NA ssid = NA>Automatic Acquisition Of Domain Knowledge For Information Extraction</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>wouM also like to understand how the topic clusters (of documents and patterns) which are developed by our pro- cedure line up with pre-specified scenarios.</S><S sid = NA ssid = NA>4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For an indirect evaluation of the quality of the learned patterns, we employ the text-filtering evaluation strategy, as in (Yangarber et al, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>rThesc judgements constituted the truth which was used only for evaluation, not visible to ExDISCO</S><S sid = NA ssid = NA>First, Proteus performance depends on many fimtors besides the event patterns, such as the quality of name re, cognition, syntactic mmlysis, anaphora reso~ lution, inferencing, etc. Several of these were improved since the MUC formal evaluation, so some of the gain over the MUC formal evalua- tion score is attritmtable to these factors.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C00-2136.txt | Citing Article:  D09-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Information Extraction (IE) systems typically use extraction patterns (e.g., Soderland et al (1995), Riloff (1996), Yangarber et al (2000), Califf and Mooney (2003)) or classifiers (e.g., Freitag (1998), Freitag and McCallum (2000), Chieu et al (2003), Bunescu and Mooney (2004)) to extract role fillers for events.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These dit\[iculties have stimulate.d resear('h on 1)attel . 'n a ( : ( lu i s i t ion . So lne o f th i s work has en l - i)hasized il\]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot:' the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al, 1992; Fisher et al, 1995; Miller el; al., 1998).</S><S sid = NA ssid = NA>The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C00-2136.txt | Citing Article:  W06-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We have chosen this evaluation strategy because this indirect approach was shown to correlate well with a direct evaluation, where the learned patterns were used to customize an IE system (Yangarberet al, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>rThesc judgements constituted the truth which was used only for evaluation, not visible to ExDISCO</S><S sid = NA ssid = NA>We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


