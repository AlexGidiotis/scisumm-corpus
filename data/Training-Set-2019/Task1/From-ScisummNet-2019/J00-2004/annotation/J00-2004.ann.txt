Citance Number: 1 | Reference Article:  J00-2004.txt | Citing Article:  P04-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Melamed (2000) proposed statistical translation models to improve the techniques of word alignment by taking advantage of preexisting knowledge, which was more effective than a knowledge-free model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs.</S><S sid = NA ssid = NA>This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J00-2004.txt | Citing Article:  P04-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A typical case is the indirect association problem (Melamed, 2000), as shown in Figure 2 in which we want to translate the term s1 (s=s1).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, most words translate to only one other word.</S><S sid = NA ssid = NA>First, most words translate to only one other word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J00-2004.txt | Citing Article:  P04-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To reduce such errors and enhance the reliability of the estimation, a competitive linking algorithm, which is extended from Melamed's work (Melamed, 2000), is developed to determine the most probable translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The competitive linking algorithm can be generalized in various ways.</S><S sid = NA ssid = NA>The competitive linking algorithm creates all the links of a given type independently of each other.'</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J00-2004.txt | Citing Article:  W09-0412.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Melamed (1995), we measured the orthographic similarity using longest common subsequence ratio (LCSR), which is defined as follows: LCSR (s1, s2)= |LCS (s1, s2) |max (|s1|, |s2|) where LCS (s1, s2) is the longest common subsequence of s1 and s2, and |s| is the length of s.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This trade-off was measured at three points, representing cutoffs at the end of each of the three longest plateaus.</S><S sid = NA ssid = NA>The &quot;best&quot; translations are usually the most common.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J00-2004.txt | Citing Article:  H05-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We chose this statistic because it has previously been found to be effective for automatically constructing translation lexicons (e.g., Melamed, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Of course, the size of automatically induced lexicons depends on the size of the training bitext.</S><S sid = NA ssid = NA>Table 5 shows that, given a sufficiently large bitext, the method can automatically construct translation lexicons with as many entries as published bilingual dictionaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J00-2004.txt | Citing Article:  E12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The utility of the constraint for parallel corpora has already been evaluated by Melamed (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data.</S><S sid = NA ssid = NA>Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J00-2004.txt | Citing Article:  E12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Melamed (2000) has already established that most source words in parallel corpora tend to translate to only one target word.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, most words translate to only one other word.</S><S sid = NA ssid = NA>First, most words translate to only one other word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J00-2004.txt | Citing Article:  E12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A direct association, as defined in (Melamed, 2000), is an association between two words (in this setting found by the TI+Cue method) where the two words are indeed mutual translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Nods and hoche are indeed mutual translations, so their tendency to co-occur is called a direct association.</S><S sid = NA ssid = NA>The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J00-2004.txt | Citing Article:  W06-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A translation model is induced between phonemes in two word lists by combining the maximum similarity alignment with the competitive linking algorithm of Melamed (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>I then plotted the of the competitive linking process, because in the first iteration, linking decisions are based only on the initial similarity metric.</S><S sid = NA ssid = NA>The competitive linking algorithm can be generalized in various ways.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J00-2004.txt | Citing Article:  H05-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>One good overview is Melamed (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, Gale and Church (1991, 154) suggest that &quot;02, a x2-like statistic, seems to be a particularly good choice because it makes good use of the off-diagonal cells&quot; in the contingency table.</S><S sid = NA ssid = NA>I have also found it useful to smooth the co-occurrence counts, e.g., using the Simple Good-Turing smoothing method (Gale and Sampson 1995), before computing G2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J00-2004.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Chen et al (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The competitive linking algorithm can be generalized in various ways.</S><S sid = NA ssid = NA>The competitive linking algorithm creates all the links of a given type independently of each other.'</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J00-2004.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>CLA-based: Chen et al (2008) used competitive linking algorithm (CLA) (Melamed, 2000) to build confusion network for hypothesis regeneration.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The competitive linking algorithm can be generalized in various ways.</S><S sid = NA ssid = NA>I then plotted the of the competitive linking process, because in the first iteration, linking decisions are based only on the initial similarity metric.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J00-2004.txt | Citing Article:  H05-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This view of alignment as graph matching is not, in itself, new: Melamed (2000) uses competitive linking to greedily construct matchings where the pair score is a measure of word-to-word association, and Matusov et al (2004) find exact maximum matchings where the pair scores come from the alignment posteriors of generative models.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Each of the models presented below uses a different score formulation.</S><S sid = NA ssid = NA>In this situation, Brown et al. (1993b, 293) recommend &quot;evaluating the expectations using only a single, probable alignment.&quot; The single most probable assignment Amax is the maximum a posteriori (MAP) assignment: If we represent the bitext as a bipartite graph and weight the edges by log trans(u, v), then the right-hand side of Equation 26 is an instance of the weighted maximum matching problem and Amax is its solution.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J00-2004.txt | Citing Article:  H05-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>With just this feature on a pair of word tokens (which depends only on their types), we can already make a stab at word alignment, aligning, say, each English word with the French word (or null) with the highest Dice value (see (Melamed, 2000)), simply as a matching-free heuristic mode.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Most word tokens translate to only one word token.</S><S sid = NA ssid = NA>Since T is constant over all word types, it also represents the probability that an arbitrary co-occurring pair of word tokens are mutual translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J00-2004.txt | Citing Article:  H05-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As observed in Melamed (2000), this use of Dice misses the crucial constraint of competition: a candidate source word with high association to a target word may be unavailable for alignment because some other target has an even better affinity for that source word.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Again, because the total probability assigned to all translations for each source word was one, precision =recall = percent correct on this task.</S><S sid = NA ssid = NA>Most word tokens translate to only one word token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J00-2004.txt | Citing Article:  E09-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In particular, the first alignment model we will present has already been described in (Melamed, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>All the translation models reviewed and introduced in this article can be based on any of the co-occurrence models described by Melamed (1998a).</S><S sid = NA ssid = NA>The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J00-2004.txt | Citing Article:  E09-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As previously mentioned, this model is mostly identical to one already proposed in (Melamed, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A review of some previously published translation models follows an introduction to translation model taxonomy The core of the article is a presentation of the model estimation biases described above.</S><S sid = NA ssid = NA>Of course, performance would degrade on previously unseen data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J00-2004.txt | Citing Article:  E09-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Additionally, as already argued in (Melamed, 2000), there are ways to determine the boundaries of some multi-words phrases (Melamed, 2002), allowing to treat several words as a single token.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>There are many ways to model translational equivalence and many ways to estimate translation models.</S><S sid = NA ssid = NA>For example, the translation models presented in the last two chapters of Melamed (to appear) capture the intuitions that words can have multiple senses and that spaces in text do not necessarily delimit words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J00-2004.txt | Citing Article:  E09-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to compare the efficiency of the BP procedure to a more simple one, we reimplemented the Competitive Link Algorithm (abbreviated as CLA from here on) that is used in (Melamed, 2000) to train an identical model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The competitive linking algorithm can be generalized in various ways.</S><S sid = NA ssid = NA>The competitive linking algorithm creates all the links of a given type independently of each other.'</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J00-2004.txt | Citing Article:  C08-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Many thanks to my former colleagues at UPenn and to the anonymous reviewers for their insightful suggestions for improvement.</S><S sid = NA ssid = NA>A similar strategy was employed by Wu and Xia (1994) and by Fung (1995).</S> | Discourse Facet:  NA | Annotator: Automatic


