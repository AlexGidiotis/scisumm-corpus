Citance Number: 1 | Reference Article:  P01-1067.txt | Citing Article:  W02-1405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To incorporate structural aspects of the language, our channel model accepts a parse tree as an input, i.e., the input sentence is preprocessed by a syntactic parser.</S><S sid = NA ssid = NA>Their models are based on a string-to-string noisy channel model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P01-1067.txt | Citing Article:  P14-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhu et al. (2010) constructed a parallel corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P01-1067.txt | Citing Article:  P14-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We refer the reader to (Yamada and Knight, 2001) for more details.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Mathematical details are fully described in (Brown et al., 1993).</S><S sid = NA ssid = NA>Following (Brown et al., 1993) and the other literature in TM, this paper only focuses the details of TM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P01-1067.txt | Citing Article:  W06-3601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both Yamada and Knight (2001) and Chiang (2005) use SCFGs as the underlying model, so their translation schemata are syntax-directed as in Fig.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P01-1067.txt | Citing Article:  W06-3601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This example also shows that, one-level SCFG rule, even if informed by the Treebank as in (Yamada and Knight, 2001), is not enough to capture a common construction like this which is five levels deep (from VP to by).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We first introduce our translation model with an example.</S><S sid = NA ssid = NA>That is, a function word like ga is just as likely to be inserted in one place as any other.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P01-1067.txt | Citing Article:  W09-1120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In applications such as the syntax based machine translation model of (Yamada and Knight, 2001), a low quality tree might lead to errorenous translation of the sentence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>We have presented a syntax-based translation model that statistically models the translation process from an English parse tree into a foreignlanguage sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P01-1067.txt | Citing Article:  P10-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Additionally, we present novel on-the-fly variants of these algorithms, and compare their performance on a syntax machine translation cascade based on (Yamada and Knight, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present a syntax-based statistical translation model.</S><S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P01-1067.txt | Citing Article:  P10-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We adapt the Japanese-to-English translation model of Yamada and Knight (2001) by transforming it from an English-tree-to-Japanese-string model to an English-tree-to-Japanese-tree model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Therefore, the probability of the Japanese sentence given the English parse tree is the sum of all these probabilities.</S><S sid = NA ssid = NA>To experiment, we trained our model on a small English-Japanese corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P01-1067.txt | Citing Article:  P06-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yamada and Knight (2001) use a parser in the target language to train probabilities on a set of 609 operations that transform a target parse tree into a source string.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node.</S><S sid = NA ssid = NA>Note that the output of our model is a string, not a parse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P01-1067.txt | Citing Article:  P03-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Therefore, we have introduced a variation of the Inside-Outside algorithm as seen in (Yamada and Knight, 2001) for E step computation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.</S><S sid = NA ssid = NA>We define an alpha probability and a beta probability for each major-node, in analogy with the measures used in the inside-outside algorithm for probabilistic context free grammars (Baker, 1979).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P01-1067.txt | Citing Article:  P03-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yamada and Knight (2001) further extended the model to a syntax-to-string translation modeling.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>Their models are based on a string-to-string noisy channel model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P01-1067.txt | Citing Article:  N10-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by DARPA-ITO grant N66001-00-1-9814.</S><S sid = NA ssid = NA>Suppose we obtained the translations shown in the fourth tree of Figure 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Yamada and Knight (2001) present an algorithm for estimating probabilistic parameters for a similar model which represents translation as a sequence of re-ordering operations over children of nodes in a syntactic tree, using automatic parser output for the initial tree structures.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Note that the output of our model is a string, not a parse tree.</S><S sid = NA ssid = NA>Model parameters are estimated in polynomial time using an EM algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We begin by summarizing the model of Yamada and Knight (2001), which can be thought of as representing translation as an Alexander Calder mobile.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A statistical translation model (TM) is a mathematical model in which the process of humanlanguage translation is statistically modeled.</S><S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In part to deal with this problem, Yamada and Knight (2001) flatten the trees in a pre-processing step by collapsing nodes with the same lexical head-word.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.</S><S sid = NA ssid = NA>Second, a subtree was flattened if the node’s head-word was the same as the parent’s headword.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P01-1067.txt | Citing Article:  H05-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Based on an example from (Yamada and Knight, 2001), we provide a sample SCFG fragment translating from English to Japanese, specified by means of the following synchronous productions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The average sentence length was 6.9 for English and 9.7 for Japanese.</S><S sid = NA ssid = NA>We first introduce our translation model with an example.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P01-1067.txt | Citing Article:  H05-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Variant of this definition can be found where the input is a single parse tree for w (Yamada and Knight, 2001), or where the output is a single parse tree, chosen according to some specific criteria (Wu and Wong, 1998).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Note that the output of our model is a string, not a parse tree.</S><S sid = NA ssid = NA>Here, we instead decide the position on the basis of the nodes of the input parse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P01-1067.txt | Citing Article:  P05-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Syntax-based Statistical Translation (Yamada and Knight, 2001): This model extends the above by allowing all possible permutations of the RHS of the English rules.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P01-1067.txt | Citing Article:  W09-2310.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finally, there are three resulting parameter tables analogous to the r-table; as stated in (Yamada and Knight, 2001), consisting of POS and constituent based patterns allowing for reordering and monotone distortion (examples can be found in Table 5).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For simplicity, we split the n-table into two: a table for insert positions and a table for words to be inserted (Table 1).</S><S sid = NA ssid = NA>The probability of reordering it into PRP-VB2-VB1 is 0.723 (the second row in the r-table in Table 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P01-1067.txt | Citing Article:  D12-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or pre ordering (Xia and McCord, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Syntax-Based Statistical Translation Model</S><S sid = NA ssid = NA>We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


