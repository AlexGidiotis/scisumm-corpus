Citance Number: 1 | Reference Article:  P09-1074.txt | Citing Article:  C10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Since we use automatically extracted markables, it is possible that some extracted markables and the gold standard markables are unmatched, or twinless as defined in Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A twinless extracted CE signals that the resolver extracted a spurious CE, while an annotated CE is twinless when the resolver fails to extract it.</S><S sid = NA ssid = NA>To avoid ambiguity, we will use the term coreference element (CE) to refer to the set of linguistic expressions that participate in the coreference relation, as defined for each of the MUC and ACE tasks.1 At times, it will be important to distinguish between the CEs that are included in the gold standard — the annotated CEs — from those that are generated by the coreference resolution system — the extracted CEs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1074.txt | Citing Article:  C10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this paper, we adopt the B3all variation proposed by Stoyanov et al (2009), which retains all twin less markables.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One option, B3all, retains all twinless extracted CEs.</S><S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1074.txt | Citing Article:  P14-2005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2007).</S><S sid = NA ssid = NA>The Berkeley parser (Petrov and Klein, 2007) generates phrase structure parse trees, and the de Marneffe et al. (2006) system produces dependency relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1074.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A04CU: Train/dev/test split of the newswire portion of the ACE 2004 training set7 utilized in Culotta et al (2007), Bengston and Roth (2008) and Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S><S sid = NA ssid = NA>When available, we use the standard test/train split.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1074.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A05ST: Train/test split of the newswire portion of the ACE 2005 training set utilized in Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>When available, we use the standard test/train split.</S><S sid = NA ssid = NA>Otherwise, we randomly split the data into a training and test set following a 70/30 ratio.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1074.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2007).</S><S sid = NA ssid = NA>The Berkeley parser (Petrov and Klein, 2007) generates phrase structure parse trees, and the de Marneffe et al. (2006) system produces dependency relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1074.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We utilized MUC (Vilain et al, 1995), B3All (Stoyanov et al, 2009), B3None (Stoyanov et al, 2009), and Pairwise F1.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S><S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1074.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S><S sid = NA ssid = NA>Coreference or Not: A Twin Model for Coreference Resolution.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1074.txt | Citing Article:  P10-1142.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their co reference algorithm, Stoyanovet al (2009) argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In contrast, the 71.3 F-measure reported by Yang et al. (2003) represents a fully automatic end-to-end resolver.</S><S sid = NA ssid = NA>We expect CE detection to be an important subproblem for an end-to-end coreference system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1074.txt | Citing Article:  P10-1142.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To apply these scorers to automatically extracted NPs ,different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al (2009)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S><S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1074.txt | Citing Article:  W11-1907.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The majority of well studied co reference features (e.g. Stoyanov et al (2009)) are actually positive co reference indicators.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S><S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1074.txt | Citing Article:  P10-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A more detailed study of Reconcile-based co reference resolution systems in different evaluation scenarios can be found in Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use the RECONCILE coreference resolution platform (Stoyanov et al., 2009) to configure a coreference resolver that performs comparably to state-of-the-art systems (when evaluated on the MUC and ACE data sets under comparable assumptions).</S><S sid = NA ssid = NA>Different types of anaphora that have to be handled by coreference resolution systems exhibit different properties.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1074.txt | Citing Article:  W10-2420.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We contrast our work with (Stoyanov et al, 2009), who show that the co-reference resolution problem can be separated into different parts ac cording to the type of the mention.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S><S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our baseline differs most substantially from Stoyanov et al (2009) in using a decision tree classifier rather than an averaged linear perceptron.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S><S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We find the decision tree classifier to work better than the default averaged perceptron (used by Stoyanov et al (2009)), on multiple datasets using multiple metrics (see Section 4.3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 3, box 1 shows the performance of RECONCILEACL09 using a default (0.5) coreference classifier threshold.</S><S sid = NA ssid = NA>On the MUC6 data set, for example, the best published MUC score using extracted CEs is approximately 71 (Yang et al., 2003), while multiple systems have produced MUC scores of approximately 85 when using annotated CEs (e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Note that B3 has two versions which handle twinless (spurious) mentions in different ways (see Stoyanov et al (2009) for details).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We propose two different ways to deal with twinless CEs for B3.</S><S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We start with the Reconcile baseline but employ the decision tree (DT) classifier, because it has significantly better performance than the default averaged perceptron classifier used in Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 3, box 1 shows the performance of RECONCILEACL09 using a default (0.5) coreference classifier threshold.</S><S sid = NA ssid = NA>We use the RECONCILE coreference resolution platform (Stoyanov et al., 2009) to configure a coreference resolver that performs comparably to state-of-the-art systems (when evaluated on the MUC and ACE data sets under comparable assumptions).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2007).</S><S sid = NA ssid = NA>The Berkeley parser (Petrov and Klein, 2007) generates phrase structure parse trees, and the de Marneffe et al. (2006) system produces dependency relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>B3 here is the B3All version of Stoyanov et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Soon et al. (2001) and Yang et al.</S><S sid = NA ssid = NA>We briefly summarize the features here and refer the reader to Stoyanov et al. (2009) for more details.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1074.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The perceptron baseline in this work (Reconcile settings: 15 iterations, threshold= 0.45, SIG for ACE04 and AP for ACE05, ACE05 ALL) has different results from Stoyanov et al (2009) because their current publicly available code is different from that used in their paper (p.c.).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We will refer to the specific configuration of RECONCILE used for this paper as RECONCILEACL09.</S><S sid = NA ssid = NA>Comparison to the BASELINE system (box 2) shows that using gold standard NEs leads to improvements on all data sets with the exception of ACE2 and ACE05, on which performance is virtually unchanged.</S> | Discourse Facet:  NA | Annotator: Automatic


