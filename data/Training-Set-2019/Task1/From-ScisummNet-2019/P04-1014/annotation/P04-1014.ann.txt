Citance Number: 1 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The CCG parser used here (Clark and Curran, 2004b) is highly accurate and efficient, recovering labelled dependencies with an overall F-score of over 84% on WSJ text, and parsing up to 50 sentences per second.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Clark and Curran (2004) shows that this supertagging method results in a highly efficient parser.</S><S sid = NA ssid = NA>Our system demonstrates that accurate and efficient wide-coverage CCG parsing is feasible.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The parser used in this paper is described in Clark and Curran (2004b).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The dependency structures considered in this paper are described in detail in Clark et al. (2002) and Clark and Curran (2003).</S><S sid = NA ssid = NA>The same parser is used to produce the packed charts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In Clark and Curran (2004b) we investigate several log-linear parsing models for CCG.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Clark and Curran (2003) we argued for the use of log-linear parsing models for CCG.</S><S sid = NA ssid = NA>Parsing The WSJ Using CCG And Log-Linear Models</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The parsing results in Clark and Curran (2004b) rely on a super tagger per-word accuracy of at least 97%, and a sentence accuracy of at least 60% (for 1.5 categories per word).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The average number of categories assigned to each word is determined by a parameter in the supertagger.</S><S sid = NA ssid = NA>For the first set of experiments, we used a setting which assigns 1.7 categories on average per word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P04-1014.txt | Citing Article:  W04-3215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, the scores in Clark and Curran (2004b) give an indication of how super tagging accuracy corresponds to overall dependency recovery.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The dependency structures considered in this paper are described in detail in Clark et al. (2002) and Clark and Curran (2003).</S><S sid = NA ssid = NA>Let L, be the number of correct dependencies in 7r with respect to a gold standard dependency structure G; then the dependency structure, 7rmax, which maximises the expected recall rate is: LP LR UP UR cat where S is the sentence for gold standard dependency structure G and i ranges over the dependency structures for S. This expression can be expanded further: The final score for a dependency structure  is a sum of the scores for each dependency  in ; and the score for a dependency  is the sum of the probabilities of those derivations producing .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P04-1014.txt | Citing Article:  P14-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P04-1014.txt | Citing Article:  P07-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to access categorial and structural information, we used the C&C toolkit (Clark and Curran, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(See Clark and Curran (2004) for a description of the Eisner constraints.)</S><S sid = NA ssid = NA>Clark and Curran (2004) shows that this supertagging method results in a highly efficient parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P04-1014.txt | Citing Article:  N09-2047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous discriminative models for CCG (Clark and Curran, 2004b) required cluster computing resources to train.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Clark and Curran (2003) we argued for the use of log-linear parsing models for CCG.</S><S sid = NA ssid = NA>For the dependency model, the highest scoring dependency structure is required.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Clark and Curran (2004b) describes the CCG parser.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Clark and Curran (2003) we argued for the use of log-linear parsing models for CCG.</S><S sid = NA ssid = NA>Our normal-form parser significantly outperforms the parser of Clark et al. (2002) and produces results at least as good as the current state-of-the-art for CCG parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In Clark and Curran (2004b) we use a cluster of 45 machines, together with a parallel implementation of the BFGS training algorithm, to solve this problem.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper describes and evaluates log-linear parsing models for Combinatory Categorial A parallel implementation of algorithm is described, which runs on a Beowulf cluster allowing the complete Penn Treebank to be used for estimation.</S><S sid = NA ssid = NA>We used 45 machines of a 64-node Beowulf cluster to estimate the dependency model, with an average memory usage of approximately 550 MB for each machine.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use the same feature representation (x, y) as in Clark and Curran (2004b), to allow comparison with the log-linear model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Clark and Curran (2003) we argued for the use of log-linear parsing models for CCG.</S><S sid = NA ssid = NA>The packed charts perform a number of roles: they are a compact representation of a very large number of CCG derivations; they allow recovery of the highest scoring parse or dependency structure without enumerating all derivations; and they represent an instance of what Miyao and Tsujii (2002) call a feature forest, which is used to efficiently estimate a log-linear model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We applied the same normal-form restrictions used in Clark and Curran (2004b): categories can only combine if they have been seen to combine in Sections 2-21 of CCGbank, and only if they do not violate the Eisner (1996a) normal-form constraints.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For the normal-form model we were able to reduce the size of the charts considerably by applying two types of restriction to the parser: first, categories can only combine if they appear together in a rule instantiation in sections 2–21 of CCGbank; and second, we apply the normal-form restrictions described in Eisner (1996).</S><S sid = NA ssid = NA>The difference is due largely to the normal-form constraints used by the normal-form parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In Clark and Curran (2004b) we use a cluster of 45 machines, together with a parallel implementation of BFGS, to solve this problem, but need up to 20 GB of RAM.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We used 45 machines of a 64-node Beowulf cluster to estimate the dependency model, with an average memory usage of approximately 550 MB for each machine.</S><S sid = NA ssid = NA>Initially we tried the parallel version of GIS described in Clark and Curran (2003) to perform the estimation, running over the Beowulf cluster.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P04-1014.txt | Citing Article:  W07-1202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Clark and Curran (2004b), accuracy is measured using F-score over the gold standard predicate-argument dependencies in CCG bank.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, using the predicate-argument dependencies in the normal-form model instead of, or in addition to, the local rule dependencies, has not led to an improvement in parsing accuracy.</S><S sid = NA ssid = NA>We had hoped that by modelling the predicate-argument dependencies produced by the parser, rather than local rule dependencies, we would improve performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P04-1014.txt | Citing Article:  W07-2208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.</S><S sid = NA ssid = NA>The components of the gradient vecThe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


