Citance Number: 1 | Reference Article:  W08-0509.txt | Citing Article:  W11-2212.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The experiments led on the alignment methods were evaluated on the development corpus using MGIZA++ (Gao and Vogel, 2008), a multi-thread version of GIZA++ (Och and Ney, 2003) which also allows previously trained IBM alignments models to be applied on the development and test corpora.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, word alignment models are trained on the bilingual parallel training corpora.</S><S sid = NA ssid = NA>While (Och and Ney, 2003) presents algorithm to implement counting over all the alignments for Model 1,2 and HMM, it is prohibitive to do that for Models 3 through 6.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W08-0509.txt | Citing Article:  W10-1709.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We word-aligned the corpus with MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of the standard word alignment tool GIZA++ (Och and Ney, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The most widely used tool to perform this training step is the well-known GIZA++(Och and Ney, 2003).</S><S sid = NA ssid = NA>Parallel Implementations of Word Alignment Tool</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W08-0509.txt | Citing Article:  W12-3150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The parallel corpus was then word-aligned using MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The most widely used tool to perform this training step is the well-known GIZA++(Och and Ney, 2003).</S><S sid = NA ssid = NA>(Och and Ney, 2003) So in this paper we focus on Model 1, HMM, Model 3 and 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W08-0509.txt | Citing Article:  W10-1701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We extend the multi-thread GIZA++ (Gao and Vogel, 2008) to load the alignments from a modified corpus file.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Each thread outputs the alignment into its own output file.</S><S sid = NA ssid = NA>Balancing the load of each child process is another issue.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W08-0509.txt | Citing Article:  W11-2158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The most widely used tool to perform this training step is the well-known GIZA++(Och and Ney, 2003).</S><S sid = NA ssid = NA>The paper describes two parallel implementations of the well-known and widely used word alignment tool GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W08-0509.txt | Citing Article:  W10-1716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The most widely used tool to perform this training step is the well-known GIZA++(Och and Ney, 2003).</S><S sid = NA ssid = NA>The paper describes two parallel implementations of the well-known and widely used word alignment tool GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W08-0509.txt | Citing Article:  P10-2067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>PGIZA++ will not perform as good as MGIZA++ on small-size corpora.</S><S sid = NA ssid = NA>Because the parameters are only updated during the M-step, it will be no difference in the result whether we perform the word alignment in the Estep sequentially or in parallel2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W08-0509.txt | Citing Article:  W11-1217.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>is the translation probability score (as the one given for instance by GIZA++ (Gao and Vogel, 2008)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To also compare the alignment score in the different systems.</S><S sid = NA ssid = NA>In statistical world alignment, the probability of a source sentence given target sentence is written as: in which aJ1 denotes the alignment on the sentence pair.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W08-0509.txt | Citing Article:  W11-1217.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Then, we applied a parallel version of GIZA++ (Gao and Vogel, 2008) that gave us the translation dictionaries of content words only (nouns, verbs, adjective and adverbs) at word form level.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Figure 1 shows a high-level view of the procedure in GIZA++.</S><S sid = NA ssid = NA>Parallel Implementations of Word Alignment Tool</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W08-0509.txt | Citing Article:  C10-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We will continue exploration on these directions. The extended GIZA++ is released to the research community as a branch of MGIZA++ (Gao and Vogel, 2008), which is available online.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The two versions of alignment tools are available online at http://www.cs.cmu.edu/˜qing/giza.</S><S sid = NA ssid = NA>To make more efficient use of available computing resources and thereby speed up the training of our SMT system, we decided to modify GIZA++ so that it can run in parallel on multiple CPUs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W08-0509.txt | Citing Article:  P11-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the t table probabilities of the IBM models and the HMM model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>IBM Model 2 has been shown to be inferior to the HMM alignment model in the sense of providing a good starting point for more complex models.</S><S sid = NA ssid = NA>The best alignment of the sentence pair, GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5 (Brown et al., 1993), HMM (Vogel et al., 1996) and Model 6 (Och and Ney, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W08-0509.txt | Citing Article:  W11-2143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unidirectional word alignments were provided by MGIZA++ (Gao and Vogel, 2008), then symmetrized with the grow-diag-final-and heuristic (Koehn et al, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Among the procedures, more than 2/3 of the time is consumed by word alignment (Koehn et al., 2007).</S><S sid = NA ssid = NA>The word alignment models implemented in GIZA++, the so-called IBM (Brown et al., 1993) and HMM alignment models (Vogel et al., 1996) are typical implementation of the EM algorithm (Dempster et al., 1977).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W08-0509.txt | Citing Article:  W10-1714.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the word alignments, we chose MGIZA (Gaoand Vogel, 2008), using seven threads per MGIZA instance, with the parallel option ,i.e. one MGIZA in stance per pair direction running in parallel.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Parallel Implementations of Word Alignment Tool</S><S sid = NA ssid = NA>PGIZA++, in small amount of data, Because MGIZA++ is more convenient to integrate into other packages, we modified the Moses system to use MGIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W08-0509.txt | Citing Article:  W10-1715.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is largest publicly available parallel corpus, and it does strain computing resources, for instance forcing us to use multi-threaded GIZA++ (Gao and Vogel, 2008). Table 7 shows the gains obtained from using this corpus in both the translation model and the language model opposed to a baseline system trained with otherwise the same settings.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To make more efficient use of available computing resources and thereby speed up the training of our SMT system, we decided to modify GIZA++ so that it can run in parallel on multiple CPUs.</S><S sid = NA ssid = NA>Usually people use the following sequence: Model 1, HMM, Model 3 and finally Model 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W08-0509.txt | Citing Article:  W11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The parallel sentences are aligned using MGIZA++ (Gao and Vogel, 2008) and then the proposed rule extraction algorithm was used in extracting the SRL-aware SCFG rules.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>During the aligning stage, all sentences can be aligned independently of each other, as model parameters are only updated after all sentence pairs have been aligned.</S><S sid = NA ssid = NA>As we can see, if we rule out the time spent in normalization, the speed up is almost linear.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W08-0509.txt | Citing Article:  W12-3147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words. Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The most widely used tool to perform this training step is the well-known GIZA++(Och and Ney, 2003).</S><S sid = NA ssid = NA>The paper describes two parallel implementations of the well-known and widely used word alignment tool GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W08-0509.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Word alignment scores: source-target and target-source MGIZA++ (Gao and Vogel, 2008) force-alignment scores using IBM Model 4 (Och and Ney, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a source string fJ1 = f1, · · · , fj, · · · , fJ and a target string eI1 = e1, · · · , ei, · · · , eI, an alignment A of the two strings is defined as(Och and Ney, 2003): A C {(j,i) : j = 1,···,J;i = 0,···,I} (1) in case that i = 0 in some (j, i) E A, it represents that the source word j aligns to an “empty” target word e0.</S><S sid = NA ssid = NA>E.g. for IBM 1 that alignment is O(J ∗ I), for the HMM alignment it is O(J + I2), with J the number of words in the source sentence and I the number of words in the target sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W08-0509.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The system translates from cased French to cased English; at no point do we lowercase data. The Parallel data is aligned in both directions using the MGIZA++ (Gao and Vogel, 2008) implementation of IBM Model 4 and symmetrized with the grow-diag-final heuristic (Och and Ney, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Och and Ney, 2003) So in this paper we focus on Model 1, HMM, Model 3 and 4.</S><S sid = NA ssid = NA>The best alignment of the sentence pair, GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5 (Brown et al., 1993), HMM (Vogel et al., 1996) and Model 6 (Och and Ney, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W08-0509.txt | Citing Article:  W10-0102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>PGIZA++ will not perform as good as MGIZA++ on small-size corpora.</S><S sid = NA ssid = NA>Because the parameters are only updated during the M-step, it will be no difference in the result whether we perform the word alignment in the Estep sequentially or in parallel2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W08-0509.txt | Citing Article:  W11-2120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For this, we create a parallel corpus consisting of n translation hypotheses and n copies of the corresponding source text, both lowercased and detokenized. We compute the word alignment with MGIZA++ (Gao and Vogel, 2008), based on the word alignment model from the primary corpus that we have previously saved to disk. After training a phrase table from the word aligned corpus with Moses, the lexical weights and translation probabilities are rescored, using the sufficient statistics (i.e. the word, phrase and word/phrase pair counts) of both the primary and the secondary corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The word alignment stage is the most time-consuming part, especially when the size of training corpus is large.</S><S sid = NA ssid = NA>The resulting word alignment is then used to extract phrase pairs and perhaps other information to be used in translation systems, such as block reordering models.</S> | Discourse Facet:  NA | Annotator: Automatic


