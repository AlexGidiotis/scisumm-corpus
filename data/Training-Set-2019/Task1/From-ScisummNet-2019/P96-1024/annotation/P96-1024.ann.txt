Citance Number: 1 | Reference Article:  P96-1024.txt | Citing Article:  W01-0720.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Two measures are used to evaluate the parses: lexical accuracy, which is the percentage of correctly tagged words compared to the extracted gold standard corpus (Watkinson and Manandhar, 2001) and average crossing bracket rate (CBR) (Goodman, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>There are many different ways to evaluate these parses.</S><S sid = NA ssid = NA>It is often called the Crossing Brackets Rate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P96-1024.txt | Citing Article:  P14-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The MST that is found using these edge scores is actually the minimum Bayes risk tree (Goodman, 1996) for an edge accuracy loss function (Smith and Eisner, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Let us define a new function, g(s,t, X).</S><S sid = NA ssid = NA>For this experiment, a very simple grammar was induced by counting, using a portion of the Penn Tree Bank, version 0.5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P96-1024.txt | Citing Article:  P06-2101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The orthogonal technique of minimum Bayes risk decoding has achieved gains on parsing (Goodman, 1996) and machine translation (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Consider writing a parser for a domain such as machine assisted translation.</S><S sid = NA ssid = NA>Using this technique, along with other optimizations, we achieved a 500 times speedup.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P96-1024.txt | Citing Article:  D07-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A probability model permits alternative decoding procedures (Goodman, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have used the technique outlined in this paper in other work (Goodman, 1996) to efficiently parse the DOP model; in that model, the only previously known algorithm which summed over all the possible derivations was a slow Monte Carlo algorithm (Bod, 1993).</S><S sid = NA ssid = NA>The entry maxc [1, n] contains the expected number of correct constituents, given the model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P96-1024.txt | Citing Article:  N10-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>These expectations can be easily computed from the inside/outside scores, similarly as in the maximum bracket recall algorithm of Goodman (1996), or in the variational approximation of Matsuzaki et al (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Similarly, the Bracketed Recall Algorithm improves performance (versus Labelled Tree) on Consistent Brackets and Bracketed Recall criteria.</S><S sid = NA ssid = NA>The Inside probability is defined as e(s,t, X) = P(X Os) and the Outside probability is f(s,t, X) = P(S 3-1 X n W1 wt-1-1)â€¢ Note that while Baker and others have used these probabilites for inducing grammars, here they are used only for parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P96-1024.txt | Citing Article:  P06-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Their algorithm is therefore the labelled recall algorithm of Goodman (1996) but applied to rules.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In particular, the Labelled Recall Algorithm can improve performance versus the Labelled Tree Algorithm on the Consistent Brackets, Labelled Recall, and Bracketed Recall criteria.</S><S sid = NA ssid = NA>Then, in Section 3, we discuss the Labelled Recall Algorithm, a new algorithm that maximizes performance on the Labelled Recall Rate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P96-1024.txt | Citing Article:  P06-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Since this method is not a contribution of this paper, we refer the reader to the fuller presentations in Goodman (1996) and Matsuzaki et al (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper we assume all guessed parse trees are binary branching.</S><S sid = NA ssid = NA>We have used the technique outlined in this paper in other work (Goodman, 1996) to efficiently parse the DOP model; in that model, the only previously known algorithm which summed over all the possible derivations was a slow Monte Carlo algorithm (Bod, 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P96-1024.txt | Citing Article:  P11-2127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The coarse PCFG has an extremely beneficial interaction with the fine all-fragments SDP grammar, wherein the accuracy of the combined grammars is significantly higher than either individually (This is similar to the maximum recall objective for approximate inference (Goodman, 1996b)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The algorithm for Bracketed Recall parsing is extremely similar to that for Labelled Recall parsing.</S><S sid = NA ssid = NA>Similar counting holds for the other three.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P96-1024.txt | Citing Article:  P07-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Goodman (1996) observed that the Viterbi parse is in general not the optimal parse for evaluation metrics such as f-score that are based on the number of correct constituents in a parse.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Remember that B is the number of brackets that are correct, and Nc is the number of constituents in the correct parse.)</S><S sid = NA ssid = NA>The Labelled Recall Algorithm finds that tree TG which has the highest expected value for the Labelled Recall Rate, LINc (where L is the number of correct labelled constituents, and Nc is the number of nodes in the correct parse).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P96-1024.txt | Citing Article:  P05-3031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The performance of web-page structuring algorithms can be evaluated via the nested-list form of tree by bracketed recall and bracketed precision (Goodman, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Similarly, the Bracketed Recall Algorithm improves performance (versus Labelled Tree) on Consistent Brackets and Bracketed Recall criteria.</S><S sid = NA ssid = NA>For the Bracketed Recall Algorithm, we find the parse that maximizes the expected Bracketed Recall Rate, BINc.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P96-1024.txt | Citing Article:  N10-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This algorithm is a natural synchronous generalization of the monolingual Maximum Constituents Parse algorithm of Goodman (1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The Labelled Recall Algorithm maximizes the expected number of correct labelled constituents.</S><S sid = NA ssid = NA>Furthermore, we will show that the two algorithms presented, the Labelled Recall Algorithm and the Bracketed Recall Algorithm, are both special cases of a more general algorithm, the General Recall Algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P96-1024.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We then compute outside scores for bi spans under a max-sum (Goodman, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The only required change is that we sum over the symbols X to calculate max_g, rather than maximize over them.</S><S sid = NA ssid = NA>Unfortunately, this criterion is relatively difficult to maximize, since it is time-consuming to compute the probability that a particular constituent crosses some constituent in the correct parse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P96-1024.txt | Citing Article:  P05-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>I would also like to thank Stanley Chen, Andrew Kehler, Lillian Lee, and Stuart Shieber for helpful discussions, and comments on earlier drafts, and the anonymous reviewers for their comments.</S><S sid = NA ssid = NA>Thus, the expected value of L for any of these trees is 1.75.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P96-1024.txt | Citing Article:  P10-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>I would also like to thank Stanley Chen, Andrew Kehler, Lillian Lee, and Stuart Shieber for helpful discussions, and comments on earlier drafts, and the anonymous reviewers for their comments.</S><S sid = NA ssid = NA>Thus, the expected value of L for any of these trees is 1.75.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P96-1024.txt | Citing Article:  P10-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Goodman (1996b), Petrov and Klein (2007), and Matsuzaki et al (2005) describe the details of constituent, rule-sum and variational objectives respectively.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In both experiments the grammars could not parse some sentences, 0.5% and 9%, respectively.</S><S sid = NA ssid = NA>Unfortunately, this criterion is relatively difficult to maximize, since it is time-consuming to compute the probability that a particular constituent crosses some constituent in the correct parse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P96-1024.txt | Citing Article:  P03-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the field of natural language processing this approach has been applied for example in parsing (Goodman, 1996) and word alignment (Kumar and Byrne, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Let wa denote word a of the sentence under consideration.</S><S sid = NA ssid = NA>The algorithm for Bracketed Recall parsing is extremely similar to that for Labelled Recall parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P96-1024.txt | Citing Article:  P04-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>And finally, we show that the parsing algorithm described in Clark and Curran (2003) is extremely slow in some cases, and suggest an efficient alternative based on Goodman (1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The algorithm for Bracketed Recall parsing is extremely similar to that for Labelled Recall parsing.</S><S sid = NA ssid = NA>Finally, we discuss the relationship of these metrics to parsing algorithms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P96-1024.txt | Citing Article:  P11-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is equivalent to minimum Bayes risk decoding (Goodman, 1996), which is used by Cohen and Smith (2007) and Smith and Eisner (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have used the technique outlined in this paper in other work (Goodman, 1996) to efficiently parse the DOP model; in that model, the only previously known algorithm which summed over all the possible derivations was a slow Monte Carlo algorithm (Bod, 1993).</S><S sid = NA ssid = NA>Next, we define the different metrics used in evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P96-1024.txt | Citing Article:  D07-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A closely related method, applied by Goodman (1996) is called minimum-risk decoding.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This metric is closely related to the Bracketed Tree Rate.</S><S sid = NA ssid = NA>It is often called the Crossing Brackets Rate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P96-1024.txt | Citing Article:  N07-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While the most probable parse problem is NP-complete (Simaan, 1992), several approximate methods exist, including n-best re-ranking by parse likelihood, the labeled bracket alorithm of Goodman (1996), and a variational approximation introduced in Matsuzakiet al (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Many different metrics exist for evaluating parsing results, including Viterbi, Crossing Brackets Rate, Zero Crossing Brackets Rate, and several others.</S><S sid = NA ssid = NA>Various methods can be used for finding these parses.</S> | Discourse Facet:  NA | Annotator: Automatic


