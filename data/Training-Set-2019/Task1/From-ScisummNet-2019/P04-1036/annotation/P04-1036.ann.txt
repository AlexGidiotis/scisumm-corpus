Citance Number: 1 | Reference Article:  P04-1036.txt | Citing Article:  W04-0837.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004).</S> | Reference Offset:  ['8','14'] | Reference Text:  <S sid = 8 ssid = >The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid = 14 ssid = >Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P04-1036.txt | Citing Article:  W04-0837.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available.</S> | Reference Offset:  ['3','15'] | Reference Text:  <S sid = 3 ssid = >Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.</S><S sid = 15 ssid = >Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P04-1036.txt | Citing Article:  W04-0837.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The method is described in (McCarthy et al, 2004), which we summarise here.</S> | Reference Offset:  ['64','175'] | Reference Text:  <S sid = 64 ssid = >We briefly summarise the two measures here; for a more detailed summary see (Patwardhan et al., 2003).</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P04-1036.txt | Citing Article:  P14-2106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','193'] | Reference Text:  <S sid = 48 ssid = >To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid = 193 ssid = >This work was funded by EU-2001-34460 project MEANING: Developing Multilingual Web-scale Language Technologies, UK EPSRC project Robust Accurate Statistical Parsing (RASP) and a UK EPSRC studentship.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P04-1036.txt | Citing Article:  I08-2105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.</S> | Reference Offset:  ['0','165'] | Reference Text:  <S sid = 0 ssid = >Finding Predominant Word Senses In Untagged Text</S><S sid = 165 ssid = >Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P04-1036.txt | Citing Article:  I08-2105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction.</S> | Reference Offset:  ['153','175'] | Reference Text:  <S sid = 153 ssid = >Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P04-1036.txt | Citing Article:  I08-2105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus.</S> | Reference Offset:  ['102','112'] | Reference Text:  <S sid = 102 ssid = >We test this below on the SENSEVAL-2 English all-words data.</S><S sid = 112 ssid = >We compare results using the first sense listed in SemCor, and the first sense according to the SENSEVAL-2 English all-words test data itself.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P04-1036.txt | Citing Article:  P06-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn.</S> | Reference Offset:  ['15','175'] | Reference Text:  <S sid = 15 ssid = >Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P04-1036.txt | Citing Article:  P06-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense.</S> | Reference Offset:  ['48','175'] | Reference Text:  <S sid = 48 ssid = >To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P04-1036.txt | Citing Article:  P06-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','193'] | Reference Text:  <S sid = 48 ssid = >To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid = 193 ssid = >This work was funded by EU-2001-34460 project MEANING: Developing Multilingual Web-scale Language Technologies, UK EPSRC project Robust Accurate Statistical Parsing (RASP) and a UK EPSRC studentship.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P04-1036.txt | Citing Article:  P10-1155.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997).</S> | Reference Offset:  ['66','79'] | Reference Text:  <S sid = 66 ssid = >It uses the glosses of semantically related (according to WordNet) senses too. jcn (Jiang and Conrath, 1997) This score uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts.</S><S sid = 79 ssid = >3 The experimental results reported here are obtained using IC counts from the BNC corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P04-1036.txt | Citing Article:  W12-3401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004).</S> | Reference Offset:  ['63','175'] | Reference Text:  <S sid = 63 ssid = >We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P04-1036.txt | Citing Article:  W12-3401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004).</S> | Reference Offset:  ['29','188'] | Reference Text:  <S sid = 29 ssid = >We discuss our method in the following section.</S><S sid = 188 ssid = >We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al., 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P04-1036.txt | Citing Article:  W12-3401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004).</S> | Reference Offset:  ['29','175'] | Reference Text:  <S sid = 29 ssid = >We discuss our method in the following section.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P04-1036.txt | Citing Article:  W06-1670.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','193'] | Reference Text:  <S sid = 48 ssid = >To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid = 193 ssid = >This work was funded by EU-2001-34460 project MEANING: Developing Multilingual Web-scale Language Technologies, UK EPSRC project Robust Accurate Statistical Parsing (RASP) and a UK EPSRC studentship.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P04-1036.txt | Citing Article:  S12-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004).</S> | Reference Offset:  ['1','161'] | Reference Text:  <S sid = 1 ssid = >word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S><S sid = 161 ssid = >Our approach is complementary to this.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P04-1036.txt | Citing Article:  W10-2803.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009).</S> | Reference Offset:  ['9','175'] | Reference Text:  <S sid = 9 ssid = >This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P04-1036.txt | Citing Article:  W08-2107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004)).</S> | Reference Offset:  ['175','188'] | Reference Text:  <S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S><S sid = 188 ssid = >We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al., 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P04-1036.txt | Citing Article:  D07-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004).</S> | Reference Offset:  ['6','175'] | Reference Text:  <S sid = 6 ssid = >This is a very promising result given that our method does not require any hand-tagged text, such as SemCor.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P04-1036.txt | Citing Article:  W12-2429.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems.</S> | Reference Offset:  ['8','175'] | Reference Text:  <S sid = 8 ssid = >The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid = 175 ssid = >We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


