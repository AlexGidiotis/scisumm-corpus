Citance Number: 1 | Reference Article:  N04-1022.txt | Citing Article:  P13-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Minimum Bayes Risk (MBR) techniques have been successfully applied to a wide range of natural language processing tasks, such as statistical machine translation (Kumar and Byrne, 2004), automatic speech recognition (Goel and Byrne, 2000), parsing (Titov and Henderson, 2006), etc.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S><S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N04-1022.txt | Citing Article:  W10-1756.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This solution is often referred to as the Minimum Bayes Risk (MBR) solution (Kumar and Byrne,2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S><S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N04-1022.txt | Citing Article:  D07-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This list is then rescored using Minimum Bayes-Risk (MBR) decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N04-1022.txt | Citing Article:  P09-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The corresponding minimum Bayes risk (MBR) procedure maximizes the expected similarity score of a system 's translations relative to the model 's distribution over possible translations (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is measured through Bayes-Risk : The expectation is taken under the true distribution that describes translations of human quality.</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Consensus decoding procedures select translations for a single system with a minimum Bayes risk (MBR) (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We therefore use statistical translation models (Och, 2002) to approximate the distribution . tion 3) on the -best List is implemented as and .</S><S sid = NA ssid = NA>Our goal is to find the decoder that has the best performance over all translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For each system, we report the performance of max-derivation decoding (MAX) and 1000-best3 MBR decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We report the performance of the MBR decoders on a Chinese-to-English translation task.</S><S sid = NA ssid = NA>We finally report the performance of MBR decoders optimized for each loss function.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N04-1022.txt | Citing Article:  W10-1710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finally, we used Minimum Bayes Risk decoding (Kumar and Byrne, 2004) based on the BLEU score (Papineni et al, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This rapid progress has been greatly facilitated by the development of automatic translation evaluation metrics such as BLEU score (Papineni et al., 2001), NIST score (Doddington, 2002) and Position Independent Word Error Rate (PER) (Och, 2002).</S><S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N04-1022.txt | Citing Article:  W12-3136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We experimented with two decoding settings: (1) monotone at punctuation reordering (Tillmannand Ney, 2003), and (2) minimum Bayes risk decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N04-1022.txt | Citing Article:  W09-0426.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although during minimum error training we assume a decoder that uses the maximum derivation decision rule, we find benefits to translating using a minimum risk decision rule on a test set (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a loss function and a distribution, it is well known that the decision rule that minimizes the BayesRisk is given by (Bickel and Doksum, 1977; Goel and Byrne, 2000): We shall refer to the decoder given by this equation as the Minimum Bayes-Risk (MBR) decoder.</S><S sid = NA ssid = NA>In contrast, the maximum likelihood techniques that underlie the decision processes of most current MT systems do not take into account these application specific goals.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N04-1022.txt | Citing Article:  W11-2160.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We decoded the test set to produce a 300-best list of unique translations, then chose the best candidate for each sentence using Minimum Bayes Risk reranking (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Each Chinese sentence in this set has four reference translations.</S><S sid = NA ssid = NA>Our goal is to find the decoder that has the best performance over all translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N04-1022.txt | Citing Article:  W10-1757.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Modifying the multitask objective to incorporate application-specific loss/decoding, such as Minimum Bayes Risk (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N04-1022.txt | Citing Article:  W11-2139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This reliably results in a small but consistent improvement in translation quality, but is much more time consuming to compute (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For each sentence, we compute the error rate of the hypothesis translation with respect to the most similar reference translation under the corresponding loss function.</S><S sid = NA ssid = NA>We present results under the Bitree loss function as an example of incorporating linguistic information into a loss function; we have not yet measured its correlation with human assessments of translation quality.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N04-1022.txt | Citing Article:  W09-0416.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N04-1022.txt | Citing Article:  W10-1727.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N04-1022.txt | Citing Article:  P13-2071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Moses Baseline: We trained a Moses system (Koehn et al, 2007) with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated KneserNey smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-felexicalized reordering, sparse lexical and domain features (Hasler et al, 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huangand Chiang, 2007) and the no-reordering-over punctuation heuristic.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N04-1022.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our baseline translation system uses Viterbi decoding while our final system uses segment-level Minimum Bayes-Risk decoding (Kumar and Byrne, 2004) over 500-best lists using 1 BLEU as the loss function.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N04-1022.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>With large training data, moving to a 5-gram language model, increasing the cube pruning pop limit to 1000, and using Minimum Bayes-Risk decoding (Kumar and Byrne, 2004) over 500-best lists collectively show a slight improvement.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The 1000-best lists were then rescored using the different translation loss functions described in Section 2.</S><S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N04-1022.txt | Citing Article:  C10-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Kumar and Byrne (2004) first introduced MBR decoding to SMT field and developed it on the N-best list translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In practice, we will consider the space of translations to be an -best list of translation alternatives generated under a baseline translation model.</S><S sid = NA ssid = NA>We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N04-1022.txt | Citing Article:  W09-0424.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Minimum Bayes Risk Rescoring: In this system, we re-ranked the n-best output of our baseline system using Minimum Bayes Risk (Kumarand Byrne, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = NA ssid = NA>We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


