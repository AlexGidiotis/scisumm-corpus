Citance Number: 1 | Reference Article:  P02-1017.txt | Citing Article:  P04-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A number of studies are related to the work we presented, most specifically work on parallel-text based "information projection" for parsing (Hwa et al., 2002), but also grammar induction work based on constituent/distituent information (Klein and Manning, 2002) and (language-internal) alignment based learning (van Zaanen, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To the extent that such approaches work, they work because good local heuristics have been engineered (Klein and Manning, 2001a; Clark, 2001).</S><S sid = NA ssid = NA>In previous work, we presented a conditional model over trees which gave the best published results for unsupervised parsing of the ATIS corpus (Klein and Manning, 2001b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Empirically, our algorithm performs favorably compared to the constituent context model of Klein and Manning (2002) without the need for careful initialization.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Generative Constituent-Context Model For Improved Grammar Induction</S><S sid = NA ssid = NA>First, random initialization is not always good, or necessary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We primarily compare our method to the constituent-context model (CCM) of Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Generative Constituent-Context Model For Improved Grammar Induction</S><S sid = NA ssid = NA>CCM is our system, as described above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>CCM is used with the initializer proposed in Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>CCM is our system, as described above.</S><S sid = NA ssid = NA>This distribution was not used in the model itself, however.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The EM algorithm with the CCM requires very careful initialization, which is described in Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>CCM is our system, as described above.</S><S sid = NA ssid = NA>First, random initialization is not always good, or necessary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Empirically, our algorithm performs favorably to the CCM of Klein and Manning (2002) without the need for careful initialization.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>CCM is our system, as described above.</S><S sid = NA ssid = NA>First, random initialization is not always good, or necessary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P02-1017.txt | Citing Article:  N06-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finally, there are "unsupervised" strategies where no data is labeled and all annotations (including the grammar itself) must be discovered (Klein and Manning, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>On the right, sequences have been labeled according to whether their occurrences are constituents more or less of the time than a cutoff (of 0.2).</S><S sid = NA ssid = NA>In previous work, we presented a conditional model over trees which gave the best published results for unsupervised parsing of the ATIS corpus (Klein and Manning, 2001b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P02-1017.txt | Citing Article:  P07-1049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>When Klein and Manning induce the parts-of-speech, they do so from a much larger corpus containing the full WSJ tree bank together with additional WSJ newswire (Klein and Manning,2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = NA ssid = NA>We will induce trees by inducing tree-equivalent bracketings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>An excellent recent result is by Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The distituents must necessarily outnumber the constituents, and so such distributional clustering will result in mostly distituent classes.</S><S sid = NA ssid = NA>Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We refer readers to Klein and Manning (2002) or Cover and Thomas (1991, p. 72) for details; computing expected counts for a sentence is a closed form operation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This grammar, which we refer to as DEP-PCFG will be evaluated in more detail in section 4.</S><S sid = NA ssid = NA>The completions (bracketings) cannot be efficiently enumerated, and so a cubic dynamic program similar to the inside-outside algorithm is used to calculate the expected counts of each yield and context, both as constituents and distituents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The third line corresponds to the setup reported by Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A bracketing is binary if it corresponds to a binary tree.</S><S sid = NA ssid = NA>Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We implement the baseline system, which Klein and Manning (2002) use for their grammar induction experiments with induced part-of-speech tags.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We followed this for most experiments, but in section 4.3, we use distributionally induced tags as input.</S><S sid = NA ssid = NA>Figure 8 shows the performance with induced tags compared to correct tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We follow Klein and Manning (2002) in using K means to cluster the d dimensional word vectors into parts-of-speech.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The resulting vectors were clustered into 200 word classes by a weighted k-means algorithm, and then grammar induction operated over these classes.</S><S sid = NA ssid = NA>Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We chose the baseline system primarily to match previous evaluations of grammar induction using induced tags (Klein and Manning, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Nevertheless, using these tags as input still gave induced structure substantially above right-branching.</S><S sid = NA ssid = NA>Figure 8 shows the performance with induced tags compared to correct tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Klein and Manning (2002) present a generative model for inducing constituent boundaries from part-of-speech tagged text.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present a generative distributional model for the unsupervised induction of natural language syntax which explicitly models constituent yields and contexts.</S><S sid = NA ssid = NA>A Generative Constituent-Context Model For Improved Grammar Induction</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We evaluate induced constituency trees against those of the Penn Treebank using the versions of unlabeled precision, recall, and F-score used by Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Evaluation was done by measuring unlabeled precision, recall, and their harmonic mean F1 against the treebank parses.</S><S sid = NA ssid = NA>By the F1 measure used in the experiments in section 4, an induced dependency PCFG scores 48.2, compared to a score of 82.1 for a supervised PCFG read from local trees of the treebank.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P02-1017.txt | Citing Article:  P07-3008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Evaluation of the algorithm is done according to PARSEVAL, except for a few changes that are also proposed by Klein and Manning (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We now essentially have our induction algorithm.</S><S sid = NA ssid = NA>Evaluation was done by measuring unlabeled precision, recall, and their harmonic mean F1 against the treebank parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P02-1017.txt | Citing Article:  P07-3008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Still, Klein and Manning (2002) and Bod (2006) stick to tag-based models.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The induction algorithm combines the benefits of EM-based parameter search and distributional clustering methods.</S><S sid = NA ssid = NA>Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P02-1017.txt | Citing Article:  P06-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary stengths: it identifies brackets but does not label them.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Here, we improve on that model in several ways.</S><S sid = NA ssid = NA>The top row of figure 8 shows the recall of nontrivial brackets, split according the brackets’ labels in the treebank.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P02-1017.txt | Citing Article:  P06-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finally, we intersect the feature-augmented PCFG with the CCM model of Klein and Manning (2002), a high quality bracketing model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Especially since the CCM does not model recursive structure explicitly, one might be concerned that the high overall accuracy is due to a high accuracy on short-span constituents.</S><S sid = NA ssid = NA>The conditional model of Klein and Manning (2001b) had the drawback that the variance of final F1, and qualitative grammars found, was fairly high, depending on small differences in first-round random parses.</S> | Discourse Facet:  NA | Annotator: Automatic


