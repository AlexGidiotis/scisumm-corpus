Citance Number: 1 | Reference Article:  J05-3002.txt | Citing Article:  P14-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To evaluate the grammaticality of our generated summaries, following common practice (Barzilay and McKeown, 2005), we randomly selected 50 sentences from original conversations and system generated abstracts, for each dataset.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The judge also had access to the original theme from which these sentences were generated.</S><S sid = NA ssid = NA>To evaluate our sentence fusion algorithm, we selected 100 themes following the procedure described in the previous section.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J05-3002.txt | Citing Article:  P11-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finally, recent research on analyzing online social media shown a growing interest in mining news stories and headlines because of its broad applications ranging from "meme" tracking and spike detection (Leskovec et al., 2009) to text summarization (Barzilay and McKeown, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentence Fusion For Multidocument News Summarization</S><S sid = NA ssid = NA>MultiGen takes as input a cluster of news stories on the same event and produces a summary which synthesizes common information across input stories.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J05-3002.txt | Citing Article:  W11-1607.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The pioneering work on fusion is Barzilay and McKeown (2005), which introduces the frame work used by subsequent projects: they represent the inputs by dependency trees, align some words to merge the input trees into a lattice, and then extract a single, connected dependency tree as the output.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Two dependency trees and their alignment tree.</S><S sid = NA ssid = NA>This algorithm operates on the dependency trees for pairs of input sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J05-3002.txt | Citing Article:  W09-2808.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Barzilay and McKeown (2005) proposed an idea called sentence fusion that integrates information in overlapping sentences to produce a non-overlapping summary sentence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the subsections that follow, we describe first how this representation is computed, then how dependency subtrees are aligned, and finally how we choose between constituents conveying overlapping information.</S><S sid = NA ssid = NA>Instead, we select a combination already present in the input sentences as a basis and transform it into a fusion sentence by removing extraneous information and augmenting the fusion sentence with information from other sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J05-3002.txt | Citing Article:  W09-2808.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is the other way around compared to the English dependency such as in Barzilay and McKeown (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Two dependency trees and their alignment tree.</S><S sid = NA ssid = NA>In the previous version of the system (Barzilay, McKeown, and Elhadad 1999), we performed linearization of a fusion dependency structure using the language generator FUF/SURGE (Elhadad and Robin 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J05-3002.txt | Citing Article:  P09-3012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Either a sentences from the cluster is selected (Aliguliyev, 2006) or a new sentence is regenerated from all/some sentences in a cluster (Barzilay and McKeown, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>MultiGen takes as input a cluster of news stories on the same event and produces a summary which synthesizes common information across input stories.</S><S sid = NA ssid = NA>Having multiple sentences in the input poses new challenges—such as a need for sentence comparison—but at the same time it opens up new possibilities for generation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J05-3002.txt | Citing Article:  W11-1608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>While earlier approaches for text compression were based on symbolic reduction rules (Grefenstette 1998; Mani, Gates, and Bloedorn 1999), more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced (Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003).</S><S sid = NA ssid = NA>Knight and Marcu (2000) treat reduction as a translation process using a noisychannel model (Brown et al. 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J05-3002.txt | Citing Article:  W11-1608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The work of (Barzilay and McKeown, 2005) on sentence fusion shows an example of re-using the same syntactical structure of a source sentence to create a new one with a slightly different meaning.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(An example of a fusion sentence is shown in Table 1.)</S><S sid = NA ssid = NA>However, removing all such subtrees may result in an ungrammatical or semantically flawed sentence; for example, we might create a sentence without a subject.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J05-3002.txt | Citing Article:  D08-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The work of Barzilay and McKeown (2005) on Sentence Fusion introduced the problem of converting multiple sentences into a single summary sentence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This sentence was created by sentence fusion and clearly, there is a problem.</S><S sid = NA ssid = NA>Here again, the problem is reference.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J05-3002.txt | Citing Article:  C08-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Two dependency trees and their alignment tree.</S><S sid = NA ssid = NA>3.1.2 Alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J05-3002.txt | Citing Article:  P12-2069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009), and a generation based approach that could be called sentence splitting (Genest and Lapalme, 2011).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In addition to sentence fusion, compression algorithms (Chandrasekar, Doran, and Bangalore 1996; Grefenstette 1998; Mani, Gates, and Bloedorn 1999; Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003) and methods for expansion of a multiparallel corpus (Pang, Knight, and Marcu 2003) are other instances of such methods.</S><S sid = NA ssid = NA>While earlier approaches for text compression were based on symbolic reduction rules (Grefenstette 1998; Mani, Gates, and Bloedorn 1999), more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced (Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J05-3002.txt | Citing Article:  P08-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Sentence fusion is a text-to-text generation application, which given two related sentences, outputs a single sentence expressing the information shared by the two input sentences (Barzilay and McKeown 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this article, we have presented sentence fusion, a novel method for text-to-text generation which, given a set of similar sentences, produces a new sentence containing the information common to most sentences.</S><S sid = NA ssid = NA>In contrast, for this task we require text-to-text generation, the ability to produce a new text given a set of related texts as input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J05-3002.txt | Citing Article:  P08-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Barzilay and McKeown (2005) argue convincingly that employing such a fusion strategy in a multidocument summarization system can result in more informative and more coherent summaries.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentence Fusion For Multidocument News Summarization</S><S sid = NA ssid = NA>It has been shown that combining information from several sources is a natural strategy for multidocument summarization.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J05-3002.txt | Citing Article:  N10-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In contrast to these approaches, sentence fusion was introduced to combine fragments of sentences with common information for multi-document summarization (Barzilay and McKeown, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Instead of examining all possible ways to combine these fragments, we select a sentence in the input which contains most of the fragments and transform its parsed tree into the fusion lattice by eliminating nonessential information and augmenting it with information from other input sentences.</S><S sid = NA ssid = NA>The research challenges in developing such an algorithm lie in two areas: identification of the fragments conveying common information and combination of the fragments into a sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


