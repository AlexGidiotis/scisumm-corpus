Citance Number: 1 | Reference Article:  P08-1023.txt | Citing Article:  D08-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, they are promising because the search space of translations is much larger than the typical N-best list (Mi et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The decoder performs two tasks on the translation forest: 1-best search with integrated language model (LM), and k-best search with LM to be used in minimum error rate training.</S><S sid = NA ssid = NA>However, a k-best list, with its limited scope, often has too few variations and too many redundancies; for example, a 50-best list typically encodes a combination of 5 or 6 binary ambiguities (since 25 < 50 < 26), and many subtrees are repeated across different parses (Huang, 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P08-1023.txt | Citing Article:  P14-2024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In addition, Mi et al (2008) have proposed a method for forest-to-string (F2S) translation using packed forests to encode many possible sentence interpretations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following Huang (2008), we modify the parser to output a packed forest for each sentence.</S><S sid = NA ssid = NA>On dev and test sets, we prune the Chinese parse forests by the forest pruning algorithm in Section 3.4 with a threshold of p = 12, and then convert them into translation forests using the algorithm in Section 3.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P08-1023.txt | Citing Article:  W10-1761.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Nor do we try to expand the space where rules can apply by propagating uncertainty from the parser in building input forests, as in (Mi et al, 2008), but we build ambiguity into the translation rule.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We first word-align them by GIZA++ refined by “diagand” from Koehn et al. (2003), and apply the tree-to-string rule extraction algorithm (Galley et al., 2006; Liu et al., 2006), which resulted in 346K translation rules.</S><S sid = NA ssid = NA>translation hyperedge translation rule parse forest, and try to pattern-match each translation rule r against the local sub-forest under node v. For example, in Figure 3(a), at node VP1,6, two rules r3 and r7 both matches the local subforest, and will thus generate two translation hyperedges e3 and e4 (see Figure 3(b-c)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P08-1023.txt | Citing Article:  W10-1761.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Thus, high quality parsers are unavailable for many source languages of interest. Parse forests can be used to mitigate the accuracy problem, allowing the decoder to choose from many alternative parses, (Mi et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This situation becomes worse with resource-poor source languages without enough Treebank data to train a high-accuracy parser.</S><S sid = NA ssid = NA>Note that our rule extraction is still done on 1-best parses, while decoding is on k-best parses or packed forests.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P08-1023.txt | Citing Article:  N10-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In terms of formal similarity, Mi et al (2008) use forests as input to a tree-to-string transducer process, but the forests are used to recover from 1 best parsing errors (as such, all derivations yield the same source string).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A parser first parses the source language input into a 1-best tree T, and the decoder then searches for the best derivation (a sequence of translation steps) d* that converts source tree T into a target-language string among all possible derivations D: We will now proceed with a running example translating from Chinese to English: “Bush held a talk2 with Sharon1” Figure 2 shows how this process works.</S><S sid = NA ssid = NA>Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006), and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string (Lin, 2004; Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P08-1023.txt | Citing Article:  D10-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>An example derivation of tree-to-string translation (much simplified from Mi et al (2008)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006), and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string (Lin, 2004; Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006).</S><S sid = NA ssid = NA>We first word-align them by GIZA++ refined by “diagand” from Koehn et al. (2003), and apply the tree-to-string rule extraction algorithm (Galley et al., 2006; Liu et al., 2006), which resulted in 346K translation rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P08-1023.txt | Citing Article:  D10-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>At decoding time, we again parse the input sentences into trees, and convert them into translation forest by rule pattern matching (Mi et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the decoding step, we first convert the parse forest into a translation forest using the translation rule set, by similar techniques of pattern-matching from tree-based decoding (Section 3.2).</S><S sid = NA ssid = NA>The only extra term in forest-based decoding is P(t  |Hp) denoting the source side parsing probability of the current translation rule r in the parse forest, which is the product of probabilities of each parse hyperedge ep covered in the pattern-match of t against Hp (which can be recorded at conversion time): Our experiments are on Chinese-to-English translation, and we use the Chinese parser of Xiong et al. (2005) to parse the source side of the bitext.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P08-1023.txt | Citing Article:  W11-1825.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Effectively maintaining and leveraging the ambiguity present in the underlying parser has improved task accuracy in some downstream tasks (e.g., Mi et al 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This situation becomes worse with resource-poor source languages without enough Treebank data to train a high-accuracy parser.</S><S sid = NA ssid = NA>Following Huang (2008), we modify the parser to output a packed forest for each sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P08-1023.txt | Citing Article:  D09-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, Quirk et al (2005) use features involving phrases and source side dependency trees and Mi et al (2008) use features from a forest of parses of the source sentence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These phrases are called syntactic phrases which are consistent with syntactic constituents (Chiang, 2005), and have been shown to be helpful in tree-based systems (Galley et al., 2006; Liu et al., 2006).</S><S sid = NA ssid = NA>Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006), and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string (Lin, 2004; Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P08-1023.txt | Citing Article:  P11-1086.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>At decoding time, we again parse the input sentences using the Berkeley parser, and convert them into translation forests using rule pattern matching (Mi et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the decoding step, we first convert the parse forest into a translation forest using the translation rule set, by similar techniques of pattern-matching from tree-based decoding (Section 3.2).</S><S sid = NA ssid = NA>On dev and test sets, we prune the Chinese parse forests by the forest pruning algorithm in Section 3.4 with a threshold of p = 12, and then convert them into translation forests using the algorithm in Section 3.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P08-1023.txt | Citing Article:  P09-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would also like to thank Chris Quirk for inspirations, Yang Liu for help with rule extraction, Mark Johnson for posing the question of virtual ∞-best list, and the anonymous reviewers for suggestions.</S><S sid = NA ssid = NA>Finally, from step (d) we apply rules r4 and r5 which perform phrasal translations for the two remaining subtrees, respectively, and get the Chinese translation in (e).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P08-1023.txt | Citing Article:  D09-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mi et al (2008) applied statistical machine translation to a source language parse forest, rather than to the 1-best parse.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have presented a novel forest-based translation approach which uses a packed forest rather than the 1-best parse tree (or k-best parse trees) to direct the translation.</S><S sid = NA ssid = NA>The only extra term in forest-based decoding is P(t  |Hp) denoting the source side parsing probability of the current translation rule r in the parse forest, which is the product of probabilities of each parse hyperedge ep covered in the pattern-match of t against Hp (which can be recorded at conversion time): Our experiments are on Chinese-to-English translation, and we use the Chinese parser of Xiong et al. (2005) to parse the source side of the bitext.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P08-1023.txt | Citing Article:  P11-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, Mi et al (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al, 2002) by including bilingual syntactic phrases in their forest-based system.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These phrases are called syntactic phrases which are consistent with syntactic constituents (Chiang, 2005), and have been shown to be helpful in tree-based systems (Galley et al., 2006; Liu et al., 2006).</S><S sid = NA ssid = NA>We evaluate the translation quality using the case-sensitive BLEU-4 metric (Papineni et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P08-1023.txt | Citing Article:  P11-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We implemented the forest-to-string decoder described in (Mi et al, 2008) that makes use of forest based translation rules (Mi and Huang, 2008) as the baseline system for translating English HPSG forests into Japanese sentences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Forest-Based Translation</S><S sid = NA ssid = NA>Following Huang (2008), we modify the parser to output a packed forest for each sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P08-1023.txt | Citing Article:  P11-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mi et al (2008) give a detailed description of the two-step decoding process.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the decoding step, we first convert the parse forest into a translation forest using the translation rule set, by similar techniques of pattern-matching from tree-based decoding (Section 3.2).</S><S sid = NA ssid = NA>We first word-align them by GIZA++ refined by “diagand” from Koehn et al. (2003), and apply the tree-to-string rule extraction algorithm (Galley et al., 2006; Liu et al., 2006), which resulted in 346K translation rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P08-1023.txt | Citing Article:  P09-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Given a source parse forest and an STSG grammar G, we first apply the conversion algorithm proposed by Mi et al (2008) to produce a translation forest.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a parse forest and a translation rule set R, we can generate a translation forest which has a similar hypergraph structure.</S><S sid = NA ssid = NA>Informally, a packed parse forest, or forest in short, is a compact representation of all the derivations (i.e., parse trees) for a given sentence under a context-free grammar (Billot and Lang, 1989).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P08-1023.txt | Citing Article:  P09-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, when a pack forest encodes over 1M parses per sentence, the improvements are less significant, which echoes the results in (Mi et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We a that translates a packed forest of exponentially many parses, which encodes many more alternatives standard lists.</S><S sid = NA ssid = NA>We instead propose a new approach, forest-based translation (Section 3), where the decoder translates a packed forest of exponentially many parses,1 which compactly encodes many more alternatives than k-best parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P08-1023.txt | Citing Article:  P09-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The first direct use of packed forest is proposed by Mi et al (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The pruned parse forest will then be used to direct the translation.</S><S sid = NA ssid = NA>We have presented a novel forest-based translation approach which uses a packed forest rather than the 1-best parse tree (or k-best parse trees) to direct the translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P08-1023.txt | Citing Article:  C10-2096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Mi et al (2008), we first convert the lattice-forest into lattice translation forest with the conversion algorithm proposed by Mi et al (2008), and then the decoder finds the best derivation on the lattice translation forest.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Forest-Based Translation</S><S sid = NA ssid = NA>Then the decoder searches for the best derivation on the translation forest and outputs the target string (Section 3.3).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P08-1023.txt | Citing Article:  C10-2096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For more detail, we refer to the algorithms of Mi et al (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Both tasks can be done efficiently by forest-based algorithms based on k-best parsing (Huang and Chiang, 2005).</S><S sid = NA ssid = NA>We first word-align them by GIZA++ refined by “diagand” from Koehn et al. (2003), and apply the tree-to-string rule extraction algorithm (Galley et al., 2006; Liu et al., 2006), which resulted in 346K translation rules.</S> | Discourse Facet:  NA | Annotator: Automatic


