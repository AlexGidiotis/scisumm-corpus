Citance Number: 1 | Reference Article:  P07-1096.txt | Citing Article:  P08-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For our POS tagging experiments, we used the Wall Street Journal in PTB III (Marcus et al, 1994) with the same data split as used in (Shen et al., 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We carry out experiments on the standard data set of the Penn Treebank (PTB) (Marcus et al., 1994).</S><S sid = NA ssid = NA>It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result (Toutanova et al., 2003) on the same data set, while using fewer features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1096.txt | Citing Article:  P08-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In POS tagging, the previous best performance was reported by (Shen et al, 2007) as summarized in Table 7.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Toutanova et al. (2003) reported a POS tagger based on cyclic dependency network.</S><S sid = NA ssid = NA>Compared to previous best result on the same data set, 2.76% by (Toutanova et al., 2003), our best result shows a relative error reduction of 3.3%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1096.txt | Citing Article:  P14-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Feature templates are shown in Table 3, which are based on those of Ratnaparkhi (1996) and Shen et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following (Ratnaparkhi,1996; Collins, 2002; Toutanova et al., 2003; Tsuruoka and Tsujii, 2005), we cut the PTB into the training, development and test sets as shown in Table 1.</S><S sid = NA ssid = NA>With set B, we include a few feature templates which are symmetric to those in Ratnaparkhi’s set, but are only available with bidirectional search.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1096.txt | Citing Article:  P12-2072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the experimental evaluations we use the Bidirectional Tagger with Guided Learning presented in Shen et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Guided Learning for Bidirectional Sequence Classification</S><S sid = NA ssid = NA>In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1096.txt | Citing Article:  S10-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the implementation, we used bpos (Shen et al., 2007) for the POS tagging.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We apply our guided learning algorithm to POS tagging.</S><S sid = NA ssid = NA>We apply this novel algorithm to POS tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1096.txt | Citing Article:  W11-0315.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For comparison, our best model, the PLMRF, achieved a 96.8% in-domain accuracy on sections 22-24 of the Penn Treebank, about 0.5% shy of a state-of-the-art in-domain system (Shen et al, 2007) with more sophisticated supervised learning.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Comparison: Table 4 shows the comparison with the previous works on the PTB test sections.</S><S sid = NA ssid = NA>We carry out experiments on the standard data set of the Penn Treebank (PTB) (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The idea of bidirectional parsing is related to the bidirectional sequential classification method described in (Shen et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Guided Learning for Bidirectional Sequence Classification</S><S sid = NA ssid = NA>We first present an example of POS tagging to show the idea of bidirectional labeling.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similar to bidirectional labelling in (Shen et al, 2007), there are two learning tasking in this model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S><S sid = NA ssid = NA>Guided Learning for Bidirectional Sequence Classification</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The learning algorithm for level-0 dependency is similar to the guided learning algorithm for labelling as described in (Shen et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>2.3 Learning Algorithm In this section, we propose guided learning, a Perceptron like algorithm, to learn the weight vector w, as shown in Algorithm 2.</S><S sid = NA ssid = NA>Then we present the inference algorithm and the learning algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1096.txt | Citing Article:  C10-2052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The only preprocessing step needed is POS tagging of the data, for which we used the system of Shen et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We apply our guided learning algorithm to POS tagging.</S><S sid = NA ssid = NA>We apply this novel algorithm to POS tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1096.txt | Citing Article:  D11-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is due to the fact that the accuracy of POS tagging is very high.</S><S sid = NA ssid = NA>Taskar et al. (2003) improved the CRF method by employing the large margin method to separate the gold standard sequence labeling from incorrect labellings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1096.txt | Citing Article:  N10-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We propose a new category of dependency parsing algorithms, inspired by (Shen et al, 2007): non directional easy-first parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In our recent work (Shen and Joshi, 2007), we have applied a variant of this algorithm to dependency parsing, and showed significant improvement over left-to-right non-aggressive learning strategy.</S><S sid = NA ssid = NA>In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1096.txt | Citing Article:  N10-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Indeed, one major influence on our work is Shen et.al's bi-directional POS-tagging algorithm (Shen et al, 2007), which combines a perceptron learning procedure similar to our own with beam search to produce a state-of-the-art POStagger, which does not rely on left-to-right processing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In our recent work (Shen and Joshi, 2007), we have applied a variant of this algorithm to dependency parsing, and showed significant improvement over left-to-right non-aggressive learning strategy.</S><S sid = NA ssid = NA>In their work, the order of inference is fixed as from left to right.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1096.txt | Citing Article:  N12-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It should be noted that the error rate is close to the inter-annotator discrepancy on PTB, the standard test set for POS tagging, therefore it is very difficult to achieve improvement.</S><S sid = NA ssid = NA>Similarly, we denote the top state for p as Algorithm 1 Inference Algorithm Require: token sequence w1 · · · wn; Require: beam width B; Require: weight vector w; where U is the score of an action.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1096.txt | Citing Article:  N12-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Note that Shen et al (2007) employ contextual features up to 5-gram which go beyond our local trigram window.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>With set C, we add more bi-gram and tri-gram features.</S><S sid = NA ssid = NA>The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1096.txt | Citing Article:  W10-1603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Shen et al, 2007) developed new algorithms based on the easiest-first strategy (Tsuruoka and Tsujii, 2005) and the perceptron algorithm.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S><S sid = NA ssid = NA>Tsuruoka and Tsujii (2005) proposed a bidirectional POS tagger, in which the order of inference is handled with the easiest-first heuristic.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1096.txt | Citing Article:  P09-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Shen et al, (2007) report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result (Toutanova et al., 2003) on the same data set, while using fewer features.</S><S sid = NA ssid = NA>This is due to the fact that the accuracy of POS tagging is very high.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Shen et al (2007) have further shown that better results (97.3 % accuracy) can be obtained using guided learning, a framework for bidirectional sequence classification, which integrates token classification and inference order selection into a single learning task and uses a perceptron-like (Collins and Roark, 2004) passive-aggressive classifier to make the easiest decisions first.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Here, we will propose a novel learning framework, namely guided learning, to integrate classification of individual tokens and inference order selection into a single learning task.</S><S sid = NA ssid = NA>Guided Learning for Bidirectional Sequence Classification</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the feature set defined in (Shen et al 2007), which includes the following: 1.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use feature set E for this set of experiments.</S><S sid = NA ssid = NA>We first use the same feature set used in (Ratnaparkhi, 1996), which includes a set of prefix, suffix and lexical features, as well as some bi-gram and tri-gram context features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It should be noted that the error rate is close to the inter-annotator discrepancy on PTB, the standard test set for POS tagging, therefore it is very difficult to achieve improvement.</S><S sid = NA ssid = NA>Similarly, we denote the top state for p as Algorithm 1 Inference Algorithm Require: token sequence w1 · · · wn; Require: beam width B; Require: weight vector w; where U is the score of an action.</S> | Discourse Facet:  NA | Annotator: Automatic


