Citance Number: 1 | Reference Article:  P06-1091.txt | Citing Article:  N07-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S><S sid = NA ssid = NA>2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1091.txt | Citing Article:  N07-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In (Tillmann and Zhang, 2006) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This block set is used to decode training sentence to obtain block orientation sequences that are used in the discriminative parameter training.</S><S sid = NA ssid = NA>1 used in our model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1091.txt | Citing Article:  P13-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It might be the case that a larger k-best, or revisiting previous strategies for y+ and y− selection, such as bold updating, local updating (Liang et al, 2006b), or maxBLEU updating (Tillmann and Zhang, 2006) might have a greater impact.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S><S sid = NA ssid = NA>The work in this paper substantially differs from previous work in SMT based on the noisy channel approach presented in (Brown et al., 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1091.txt | Citing Article:  P12-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Exceptions where discriminative SMT has been used on large training data are Liang et al. (2006a) who trained 1.5 million features on 67,000 sentences, Blunsom et al. (2008) who trained 7.8 million rules on 100,000 sentences, or Tillmann and Zhang (2006) who used 230,000 sentences for training.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The ’SWAP’ re-ordering uses the same features as the monotone models plus additional orientation-based and distortionBLEU on the training data ( sentences) and the MT03 test data (670 sentences). based features.</S><S sid = NA ssid = NA>The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1091.txt | Citing Article:  W07-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Tillmann and Zhang (2006) use a BLEU oracle decoder for discriminative training of a local reordering model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S><S sid = NA ssid = NA>This step does not require the use of a decoder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1091.txt | Citing Article:  P08-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The translation probability can also be discriminatively trained such as in Tillmann and Zhang (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S><S sid = NA ssid = NA>Such probability features include language model, translation or distortion probabilities, which are commonly used in current SMT approaches 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1091.txt | Citing Article:  D07-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Although the training algorithm can handle realvalued features as used in (Och, 2003; Tillmann and Zhang, 2005) the current paper intentionally excludes them.</S><S sid = NA ssid = NA>The advantage of this approach is that it can easily handle tens of millions of features, e.g. up to million features for the experiments in this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1091.txt | Citing Article:  D07-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both Liang, et al (2006), and Tillmann and Zhang (2006) report on effective machine translation (MT) models involving large numbers of features with discriminatively trained weights.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These features correspond to the use of a language model, but the weights for theses features are trained on the parallel training data only.</S><S sid = NA ssid = NA>The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1091.txt | Citing Article:  D08-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S><S sid = NA ssid = NA>2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S><S sid = NA ssid = NA>2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Tillmann and Zhang (2006) trained their feature set using an on line discriminative algorithm.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Using this feature representation and the loss function in Eq.</S><S sid = NA ssid = NA>Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Tillmann and Zhang (2006) avoided the problem by precomputing the oracle translations in advance.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the training data where target translations are given, a BLEU score can be calculated for each against the target translations.</S><S sid = NA ssid = NA>A block is a pair of phrases which are translations of each other.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S><S sid = NA ssid = NA>2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1091.txt | Citing Article:  W07-0716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For instance, some max-margin methods restrict their computations to a set of examples from a feasible set, where they are expected to be maximally discriminative (Tillmann and Zhang, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We refer to this formulation as ’costMargin’ (cost-sensitive margin) method: for each training sentence the ’costMargin’ between the ’true’ block sequence set and the ’alternative’ block sequence set is maximized.</S><S sid = NA ssid = NA>This block set is used to decode training sentence to obtain block orientation sequences that are used in the discriminative parameter training.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P06-1091.txt | Citing Article:  W07-0716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This might prove beneficial for various discriminative training methods (Tillmann and Zhang, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are able to achieve comparable performance to (Tillmann and Zhang, 2005).</S><S sid = NA ssid = NA>A Discriminative Global Training Algorithm For Statistical MT</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P06-1091.txt | Citing Article:  D10-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is the main motivation of (Tillmann and Zhang,2006), where the authors compute high BLEU hypotheses by running a conventional decoder so as to maximize a per-sentence approximation of BLEU-4, under a simple (local) reordering models.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Starting with a simple model, the training data is decoded multiple times: the weight vector is trained to discriminate block sequences with a high translation score against block sequences with a high BLEU score 2.</S><S sid = NA ssid = NA>The high BLEU scoring block sequences are obtained as follows: the regular phrase-based decoder is modified in a way that it uses the BLEU score as optimization criterion (independent of any translation model).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P06-1091.txt | Citing Article:  D09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Tillmann and Zhang (2006) present a procedure to directly optimize the global scoring function used by a phrase based decoder on the accuracy of the translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder.</S><S sid = NA ssid = NA>For the results with word-based features, the decoder still generates phrase-to-phrase translations, but all the scoring is done on the word level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P06-1091.txt | Citing Article:  W12-3160.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is referred to in past work as maxBLEU (Tillmann and Zhang, 2006) (MB).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are able to achieve comparable performance to (Tillmann and Zhang, 2005).</S><S sid = NA ssid = NA>The work in this paper substantially differs from previous work in SMT based on the noisy channel approach presented in (Brown et al., 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


