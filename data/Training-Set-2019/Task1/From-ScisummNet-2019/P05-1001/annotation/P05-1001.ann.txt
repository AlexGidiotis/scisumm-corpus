Citance Number: 1 | Reference Article:  P05-1001.txt | Citing Article:  H05-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ando and Zhang (2005) independently used this phrase, for a semi-supervised, cross-task learner that differs from our unsupervised, cross-instance learner.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We choose this task because the original intention of this shared task was to test the effectiveness of semi-supervised learning methods.</S><S sid = NA ssid = NA>In the first step, we train m predictors independently.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P05-1001.txt | Citing Article:  P14-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P05-1001.txt | Citing Article:  P10-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ando and Zhang (2005) utilized a multi task learner within their semi-supervised algorithm to learn feature representations which were useful across a large number of related tasks.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For semi-supervised learning, the idea is to create many auxiliary prediction problems (relevant to the task) from unlabeled data so that we can learn the shared structureO(useful for the task) using the ASO algorithm.</S><S sid = NA ssid = NA>Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For a more complete description, see (Ando and Zhang, 2005a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S><S sid = NA ssid = NA>The formal derivation can be found in (Ando and Zhang, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>An important observation in (Ando and Zhang, 2005a) is that the binary classification problems used to derive theta are not necessarily those problems we are aiming to solve.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>From a c-way classification problem, c!=(c — k)! binary prediction problems can be created.</S><S sid = NA ssid = NA>One binary classification problem can be created for each possible word value (e.g., “IBM”, “he”, “get”,••J.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Assuming there are k target problems and m auxiliary problems, it is shown in (Ando and Zhang, 2005a) that by performing one round of minimization, an approximate solution of theat can be obtained from (4) by the following algorithm:.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Hence, many auxiliary problems can be obtained using this idea.</S><S sid = NA ssid = NA>•Relevancy: auxiliary problems should be related to the target problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is a simplified version of the definition in (Ando and Zhang, 2005a), made possible because the same theta is used for all auxiliary problems.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Moreover, the auxiliary problems used in our experiments are merely possible examples.</S><S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P05-1001.txt | Citing Article:  P07-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P05-1001.txt | Citing Article:  W09-1119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the work was supported by ARDA under the NIMD program PNWD-SW-6059.</S><S sid = NA ssid = NA>Structural learning provides a framework for carrying out possible new ideas.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To avoid terminological confusion, we refer throughout the paper to a specific structural learning method, alternating structural optimization (ASO) (Ando and Zhang, 2005a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper presents a novel semi-supervised method that employs a learning framework called structural learning (Ando and Zhang, 2004), which seeks to discover shared predictive structures (i.e. what good classifiers for the task are like) through jointly learning multiple classification problems on unlabeled data.</S><S sid = NA ssid = NA>We presented a novel semi-supervised learning method that learns the most predictive lowdimensional feature projection from unlabeled data using the structural learning algorithm SVD-ASO.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Pivot features correspond to the auxiliary problems of Ando and Zhang (2005a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S><S sid = NA ssid = NA>The formal derivation can be found in (Ando and Zhang, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We follow Ando and Zhang (2005a) and use the modified Huber loss.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In all settings (including baseline methods), the loss function is a modification of the Huber’s robust loss for regression: L(p, y) = max (0,1 — py)2 if py > —1; and —4py otherwise; with square regularization (A=10-4).</S><S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For both computational and statistical reasons, though, we follow Ando and Zhang (2005a) and compute a low-dimensional linear approximation to the pivot predictor space.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The final classifier for the target task is in the form of (1), a linear predictor for structural learning.</S><S sid = NA ssid = NA>Specifically, we assume that there exists a low-dimensional predictive structure shared by multiple prediction problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ando and Zhang (2005a) describe several free paramters and extensions to ASO, and we briefly address our choices for these here.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Ex 3.2 Predict the top-k choices of the classifier.</S><S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P05-1001.txt | Citing Article:  W06-1615.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As in Ando and Zhang (2005a), we observed that setting h between 20 and 100 did not change results significantly, and a lower dimensionality translated to faster run-time.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>See (Ando and Zhang, 2004) for the precise formulation.</S><S sid = NA ssid = NA>The formal derivation can be found in (Ando and Zhang, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


