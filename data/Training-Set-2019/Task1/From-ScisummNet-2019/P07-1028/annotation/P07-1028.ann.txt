Citance Number: 1 | Reference Article:  P07-1028.txt | Citing Article:  D07-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We build on a recent selectional preference model (Erk, 2007) that bases its generalisations on word similarity in a vector space.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since the flexibility of similarity-based models extends to the vector space for computing similarities, one obvious remedy to the coverage problem would be the use of a less sparse vector space.</S><S sid = NA ssid = NA>The most probable reason for this is the sparsity of the underlying vector space.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1028.txt | Citing Article:  D07-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our model builds on the architecture of Erk (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the evaluation, the similarity-model shows lower error rates than both Resnik's WordNet-based model and the EM-based clustering model.</S><S sid = NA ssid = NA>In evaluations the similarity-based model shows lower error rates than both Resnik's WordNet-based model and the EM-based clustering model, but has coverage problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1028.txt | Citing Article:  D07-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Erk (2007) extracted the set of seen head words from corpora with semantic role annotation, and used only a single vector space representation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a set S = Seen(rp) of seen headwords for some role rp, each similarity metric produces a set like(S) of words that have nonzero similarity to S, that is, to at least one word in S. Line (a) shows the average frequency of words in like(S).</S><S sid = NA ssid = NA>Since the flexibility of similarity-based models extends to the vector space for computing similarities, one obvious remedy to the coverage problem would be the use of a less sparse vector space.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1028.txt | Citing Article:  D07-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In addition, we discuss in detail which properties of the vector space are crucial for the prediction of plausibility ratings, a much more fine-grained task than the pseudo-word disambiguation task presented in Erk (2007) that is more closely related to semantic role labelling.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Focusing on the task of semantic role labeling, we compute selectional preferences for semantic roles.</S><S sid = NA ssid = NA>In a pseudo-disambiguation task the similarity-based model showed error rates down to 0.16, far lower than both EM-based clustering and Resnik's WordNet model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1028.txt | Citing Article:  D07-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We have demonstrated that the successful evaluation of the model in Erk (2007) on the coarse-grained pseudo-word disambiguation task carries over to the prediction of human plausibility judgments which requires relatively fine-grained, relation-based distinctions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In a pseudo-disambiguation task the similarity-based model showed error rates down to 0.16, far lower than both EM-based clustering and Resnik's WordNet model.</S><S sid = NA ssid = NA>In the evaluation, the similarity-model shows lower error rates than both Resnik's WordNet-based model and the EM-based clustering model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1028.txt | Citing Article:  P14-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Such models have engendered improvements in diverse applications such as selectional preference modeling (Erk, 2007), word-sense discrimination (McCarthy and Carroll, 2003), automatic dictionary building (Curran, 2003), and information retrieval (Manning et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>They have been used for example for syntactic disambiguation (Hindle and Rooth, 1993), word sense disambiguation (WSD) (McCarthy and Carroll, 2003) and semantic role labeling (SRL) (Gildea and Jurafsky, 2002).</S><S sid = NA ssid = NA>Brockmann and Lapata (2003) perform a comparison of WordNet-based models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1028.txt | Citing Article:  E12-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Erk (2007) and Erk et al (2010) modeled the contexts of a word as the distribution of words that co-occur with it.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The argument positions for which we compute selectional preferences will be semantic roles in the FrameNet (Baker et al., 1998) paradigm, and the predicates we consider will be semantic classes of words rather than individual words (which means that different preferences will be learned for different senses of a predicate word).</S><S sid = NA ssid = NA>Rooth et al. (1999) generalize over seen headwords using EM-based clustering rather than WordNet.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1028.txt | Citing Article:  E12-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Acknowledgements Many thanks to Jason Baldridge, Razvan Bunescu, Stefan Evert, Ray Mooney, Ulrike and Sebastian Pad6, and Sabine Schulte im Walde for helpful discussions.</S><S sid = NA ssid = NA>This is especially relevant in view of the domain-dependence problem that SRL faces.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1028.txt | Citing Article:  C10-1142.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Selectional preferences are computed as in Erk (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Simple Similarity-based Model for Selectional Preferences</S><S sid = NA ssid = NA>The first five models are similarity-based, computed with uniform weights.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1028.txt | Citing Article:  P09-2019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In (Erk, 2007) a distributional similarity based model for selectional preferences is introduced, reminiscent of that of Pantel and Lin (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have introduced the similarity-based model for inducing selectional preferences.</S><S sid = NA ssid = NA>A Simple Similarity-based Model for Selectional Preferences</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1028.txt | Citing Article:  P10-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Bergsma et al. (2008) test pairs that fall below a mutual information threshold (might include some seen pairs), and Erk (2007) selects a subset of roles in FrameNet (Baker et al, 1998) to test and uses all labeled instances within this subset (unclear what portion of subset of data is seen).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use FrameNet (Baker et al., 1998), a semantic lexicon for English that groups words in semantic classes called frames and lists semantic roles for each frame.</S><S sid = NA ssid = NA>Rooth et al. (1999) generalize over seen headwords using EM-based clustering rather than WordNet.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1028.txt | Citing Article:  P10-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We implemented the current state-of-the-art smoothing model of Erk (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>While there have been no isolated comparisons of the two generalization paradigms that we are aware of, Gildea and Jurafsky's (2002) task-based evaluation has found clusteringbased approaches to have better coverage than WordNet generalization, that is, for a given role there are more words for which they can state a preference.</S><S sid = NA ssid = NA>In SRL, the two most pressing issues today are (1) the development of strong semantic features to complement the current mostly syntacticallybased systems, and (2) the problem of the domain dependence (Carreras and Marquez, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1028.txt | Citing Article:  P10-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The Train size is approximately the same size used in Erk (2007), although on a different corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Line (c) looks at the size of like(S).</S><S sid = NA ssid = NA>Since we are using a cutoff of 500 similar words computed per word in S, the size of like(S) can only vary if the same word is suggested as similar for several seen headwords in S. This way, the size of like(S) functions as an indicator of the degree of uniformity or similarity that a similarity metric “perceives” among the members of S. To facilitate comparison across frequency bands, line (c) normalizes by the size of S, showwe see that Cosine seems to “perceive” considerably less similarity among the seen headwords than any of the other metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1028.txt | Citing Article:  P10-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>These results appear consistent with Erk (2007) because that work used the BNC corpus (the same size as one year of our data) and Erk chose confounders randomly within a broad frequency range.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our generalization corpus is the BNC.</S><S sid = NA ssid = NA>In a test set of pairs (rp, w), each headword w is paired with a confounder w' chosen randomly from the BNC according to its frequency4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1028.txt | Citing Article:  S12-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similar to Erk (2007), we used an adapted version which we computed for semantic roles by means of the FN database rather than for verb argument positions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The argument positions for which we compute selectional preferences will be semantic roles in the FrameNet (Baker et al., 1998) paradigm, and the predicates we consider will be semantic classes of words rather than individual words (which means that different preferences will be learned for different senses of a predicate word).</S><S sid = NA ssid = NA>Our primary corpus will consist of manually semantically annotated data, and we will use semantic verb classes as predicates and semantic roles as arguments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1028.txt | Citing Article:  W11-0607.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Erk et al (2010) propose the Exemplar-Based Model of Selectional Preferences, in turn based on Erk (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Simple Similarity-based Model for Selectional Preferences</S><S sid = NA ssid = NA>We propose a new, simple model for the automatic induction of selectional preferences, using corpus-based semantic similarity metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1028.txt | Citing Article:  N10-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In (Erk, 2007) a number of SP models are tested in a pseudo-task related to SRL.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Besides the similarity metric itself, which we discuss below, parameters of the similarity-based models include the number of seen headwords, the weighting scheme, and the number of similar words for each headword.</S><S sid = NA ssid = NA>So similarity-based models seem not overly sensitive to the weighting scheme used, the number of seen headwords, or the number of similar words per seen headword.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1028.txt | Citing Article:  D09-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Acknowledgements Many thanks to Jason Baldridge, Razvan Bunescu, Stefan Evert, Ray Mooney, Ulrike and Sebastian Pad6, and Sabine Schulte im Walde for helpful discussions.</S><S sid = NA ssid = NA>This is especially relevant in view of the domain-dependence problem that SRL faces.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1028.txt | Citing Article:  E12-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Acknowledgements Many thanks to Jason Baldridge, Razvan Bunescu, Stefan Evert, Ray Mooney, Ulrike and Sebastian Pad6, and Sabine Schulte im Walde for helpful discussions.</S><S sid = NA ssid = NA>This is especially relevant in view of the domain-dependence problem that SRL faces.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1028.txt | Citing Article:  P10-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The notion of selectional preference is not restricted to surface-level predicates such as verbs and modifiers, but also extends to semantic frames (Erk, 2007) and inference rules (Pantel et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use FrameNet (Baker et al., 1998), a semantic lexicon for English that groups words in semantic classes called frames and lists semantic roles for each frame.</S><S sid = NA ssid = NA>Like Rooth et al. (1999) we evaluate selectional preference induction approaches in a pseudodisambiguation task.</S> | Discourse Facet:  NA | Annotator: Automatic


