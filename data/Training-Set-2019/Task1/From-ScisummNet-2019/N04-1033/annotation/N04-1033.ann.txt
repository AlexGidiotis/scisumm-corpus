Citance Number: 1 | Reference Article:  N04-1033.txt | Citing Article:  W05-0834.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use a phrase-based translation approach as described in (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We described a phrase-based translation approach.</S><S sid = NA ssid = NA>In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N04-1033.txt | Citing Article:  W05-0834.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Section 4, we will describe a monotone search algorithm.</S><S sid = NA ssid = NA>We described a highly efficient monotone search algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N04-1033.txt | Citing Article:  W12-3137.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We exchange the baseline lexical scoring with a noisy-or (Zens and Ney, 2004) lexical scoring variant.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Thus the lexical choice of words is of the same quality.</S><S sid = NA ssid = NA>Then, we will describe refinements of the baseline model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N04-1033.txt | Citing Article:  P09-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The core of our engine is the dynamic programming algorithm for monotone phrasal decoding (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The monotone search can be efficiently computed with dynamic programming.</S><S sid = NA ssid = NA>We obtain the following dynamic programming recursion.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N04-1033.txt | Citing Article:  P06-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There is, however, a large body of work using morphological analysis to define cluster-based translation models similar to ours but in a supervised manner (Zens and Ney, 2004), (Niessen and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The alignment template system (Och et al., 1999) is similar to the system described in this work.</S><S sid = NA ssid = NA>In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N04-1033.txt | Citing Article:  W06-3118.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our approach to phrase-table smoothing contrasts to previous work (Zens and Ney, 2004) in which smoothed phrase probabilities are constructed from word-pair probabilities and combined in a log-linear model with an unsmoothed phrase-table.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This will be used to smooth the phrase translation probabilities.</S><S sid = NA ssid = NA>Finally, we have to estimate the phrase translation probabilities p(˜f|˜e).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N04-1033.txt | Citing Article:  W10-1717.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Each includes relative frequency estimates and lexical estimates (based on Zens and Ney, 2004) of forward and backward conditional probabilities.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It should be pointed out that in practice the monotone search will perform better than what the preceding estimates indicate.</S><S sid = NA ssid = NA>We are using relative frequencies to estimate the phrase translation probabilities.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N04-1033.txt | Citing Article:  P06-2061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work has been partially funded by the EU project TransType 2, IST-2001-32091.</S><S sid = NA ssid = NA>Q(J + 1, $) is the probability of the optimum translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N04-1033.txt | Citing Article:  P08-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to complete the conversion from a pipeline approach to a joint approach, we fold our input segmentation step into the exact search framework by replacing a separate segmentation module (#2) with a monotone phrasal decoder (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We described a phrase-based translation approach.</S><S sid = NA ssid = NA>As a decision rule, we obtain: This approach is a generalization of the source-channel approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N04-1033.txt | Citing Article:  P08-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the joint approach (Figure 1c), we perform segmentation and L2P prediction simultaneously by applying the monotone search algorithm developed for statistical machine translation (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Improvements In Phrase-Based Statistical Machine Translation</S><S sid = NA ssid = NA>In Section 4, we will describe a monotone search algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N04-1033.txt | Citing Article:  E09-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Logic MONOTONE) This is the algorithm of Zens and Ney (2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In Section 4, we will describe a monotone search algorithm.</S><S sid = NA ssid = NA>We described a highly efficient monotone search algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N04-1033.txt | Citing Article:  E09-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The First d Uncovered Words strategy (FdUW) is described by Tillman and Ney (2003) and Zens and Ney (2004), who call it the IBM Constraint.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For details, see (Tillmann and Ney, 2003).</S><S sid = NA ssid = NA>Therefore, there is no constraint on the reordering within the phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N04-1033.txt | Citing Article:  W09-0439.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In (Zens and Ney, 2004) the downhill simplex method is used to estimate the weights; around 200 iterations are required for convergence to occur.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the experiments, the Downhill Simplex algorithm converged after about 200 iterations.</S><S sid = NA ssid = NA>We use the Downhill Simplex algorithm from (Press et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N04-1033.txt | Citing Article:  W07-0717.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work has been partially funded by the EU project TransType 2, IST-2001-32091.</S><S sid = NA ssid = NA>Q(J + 1, $) is the probability of the optimum translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N04-1033.txt | Citing Article:  W07-0717.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For tractability, we followed standard practice with this technique and considered only monotonic alignments when decoding (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We take the union ofboth alignments to obtain a symmetrized word alignment matrix.</S><S sid = NA ssid = NA>It means that two phrases are considered to be translations of each other, if the words are aligned only within the phrase pair and not to words outside.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N04-1033.txt | Citing Article:  P12-1048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>combination method (Zens and Ney, 2004) which has shown good performance in calculating similarities between bags-of-words in different languages.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The translation results of the different systems are shown in Table 6.</S><S sid = NA ssid = NA>The unigram method hurts performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N04-1033.txt | Citing Article:  P12-1048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This finding fails to echo the promising results in the previous study (Zens and Ney,2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The translation results for the Xerox and Canadian Hansards task are very promising.</S><S sid = NA ssid = NA>We start with the Verbmobil results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N04-1033.txt | Citing Article:  P08-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The source text, annotated with name translations, is then passed to a statistical, phrase-based MT system (Zens and Ney, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Improvements In Phrase-Based Statistical Machine Translation</S><S sid = NA ssid = NA>So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N04-1033.txt | Citing Article:  W09-0438.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The following methods were investigated: (Monotone) Phrase-based MT on character level: A state-of-the-art phrase-based SMT system (Zens and Ney, 2004) was used for name transliteration, i.e. translation of characters instead of words.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The described search is monotone at the phrase level.</S><S sid = NA ssid = NA>Obviously, the monotone phrase-based system outperforms the monotone single-word based system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N04-1033.txt | Citing Article:  W09-1704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use the RWTH Aachen Chinese-to-English statistical phrase-based machine translation system (Zens and Ney, 2004) for these purposes.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Improvements In Phrase-Based Statistical Machine Translation</S><S sid = NA ssid = NA>In statistical machine translation, the currently best performing systems are based in some way on phrases or word groups.</S> | Discourse Facet:  NA | Annotator: Automatic


