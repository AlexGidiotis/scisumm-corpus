Citance Number: 1 | Reference Article:  P94-1002.txt | Citing Article:  C96-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our salience factors mirror those used by (Lappin and Leass, 1994), with the exception of Poss-s, discussed below, and CNTX-S, which is sensitive to the context in which a discourse referent appears, where a context is a topically coherent segment of text, as determined by a text-segmentation algorithm which follows (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Many researchers have studied the patterns of occurrence of characters, setting, time, and the other thematic factors that Chafe mentions, usually in the context of narrative.</S><S sid = NA ssid = NA>This could very well be due to problems with the algorithm used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P94-1002.txt | Citing Article:  N12-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>TextTiling (TT) (Hearst, 1994) relies on the simplest coherence relation word repetition and computes similarities between textual units based on the similarities of word space vectors.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Skorochod'ko (1972) suggests discovering a text's structure by dividing it up into sentences and seeing how much word overlap appears among the sentences.</S><S sid = NA ssid = NA>Influenced by Halliday & Hasan's (1976) theory of lexical coherence, Morris developed an algorithm that finds chains of related terms via a comprehensive thesaurus (Roget's Fourth Edition).3 For example, the 2Interestingly, Chafe arrived at the Flow Model after working extensively with, and then becoming dissatisfied with, a hierarchical model of paragraph structure like that of Longacre (1979). words residential and apartment both index the same thesaural category and can thus be considered to be in a coherence relation with one another.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P94-1002.txt | Citing Article:  W04-2906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Text-based segmentation approaches have utilized term-based similarity measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A cutoff based on a particular valley depth is similarly problematic.</S><S sid = NA ssid = NA>This paper has described algorithms for the segmentation of expository texts into discourse units that reflect the subtopic structure of expository text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P94-1002.txt | Citing Article:  P05-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Messages are partitioned into multi-paragraph segments using TextTiling, which reportedly has an overall precision of 83% and recall of 78% (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>When the block similarity algorithm is allowed to be off by one paragraph, there is dramatic improvement in the scores for the texts that lower part of Table 2, yielding an overall precision of 83% and recall of 78%.</S><S sid = NA ssid = NA>Multi-Paragraph Segmentation Of Expository Text</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P94-1002.txt | Citing Article:  P07-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This part of the Discourse Analysis field has received a constant interest since the initial work in this domain such as (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Most discourse segmentation work is done at a finer granularity than that suggested here.</S><S sid = NA ssid = NA>Closed-class and other very frequent words are eliminated from the analysis.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P94-1002.txt | Citing Article:  P07-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As TextTiling, the topic segmentation method of Hearst (Hearst, 1994), the topic segmenter we propose, called F06, first evaluates the lexical cohesion of texts and then finds their topic shifts by identifying breaks in this cohesion.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>From a computational viewpoint, deducing textual topic structure from lexical connectivity alone is appealing, both because it is easy to compute, and also because discourse cues are sometimes misleading with respect to the topic structure (Brown & Yule 1983)(ยง3).</S><S sid = NA ssid = NA>The structure of expository texts can be characterized as a sequence of subtopical discussions that occur in the context of a few main topic discussions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P94-1002.txt | Citing Article:  W03-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Texts without adequate paragraph marking could be segmented using tools such as TextTiling (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper describes TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts.</S><S sid = NA ssid = NA>I have used the results of TextTiling in a new paradigm for information access on fulltext documents (Hearst 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P94-1002.txt | Citing Article:  P07-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The first task can be addressed by using the hierarchical structure readily available in the text (e.g., chapters, sections and subsections) or by employing existing topic segmentation algorithms (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One way to evaluate these segmentation algorithms is to compare against judgments made by human readers, another is to compare the algorithms against texts premarked by authors, and a third way is to see how well the results improve a computational task.</S><S sid = NA ssid = NA>This paper has described algorithms for the segmentation of expository texts into discourse units that reflect the subtopic structure of expository text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P94-1002.txt | Citing Article:  P07-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This division can either be automatically computed using one of the many available text segmentation algorithms (Hearst, 1994), or it can be based on demarcations already present in the input (e.g., paragraph markers).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The core algorithm has three main parts: Tokenization refers to the division of the input text into individual lexical units.</S><S sid = NA ssid = NA>Multi-Paragraph Segmentation Of Expository Text</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P94-1002.txt | Citing Article:  P08-2068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, the TextTiling algorithm, introduced by (Hearst, 1994), assumes that the local minima of the word similarity curve are the points of low lexical cohesion and thus the natural boundary candidates.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Thus it displays low similarity both to itself and to its neighbors.</S><S sid = NA ssid = NA>... At points where all of these change in a maximal way, an episode boundary is strongly present.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P94-1002.txt | Citing Article:  W04-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Text-based segmentation approaches have utilized term-based similarity measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A cutoff based on a particular valley depth is similarly problematic.</S><S sid = NA ssid = NA>This paper has described algorithms for the segmentation of expository texts into discourse units that reflect the subtopic structure of expository text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P94-1002.txt | Citing Article:  P10-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Discourse segmentation of the documents composed of parallel parts is a novel and challenging problem, as previous research has mostly focused on the linear segmentation of isolated texts (e.g., (Hearst, 1994)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Most discourse segmentation work is done at a finer granularity than that suggested here.</S><S sid = NA ssid = NA>I have used the results of TextTiling in a new paradigm for information access on fulltext documents (Hearst 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P94-1002.txt | Citing Article:  D07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Fordocuments where hierarchical information is not explicitly provided, such as automatic speech transcripts, we can use automatic segmentation methods to induce such a structure (Hearst, 1994).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Many discourse models assume a hierarchical segmentation model, e.g., attentional/intentional structure (Grosz & Sidner 1986) and Rhetorical Structure Theory (Mann & Thompson 1987).</S><S sid = NA ssid = NA>I have used the results of TextTiling in a new paradigm for information access on fulltext documents (Hearst 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this study we apply the methods of Foltz et al (1998), Hearst (1994, 1997), and a new technique utilizing an orthonormal basis to topic segmentation of tutorial dialogue.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>I have used the results of TextTiling in a new paradigm for information access on fulltext documents (Hearst 1994).</S><S sid = NA ssid = NA>Since readers often disagree about where to draw a boundary marking for a topic shift, one can only use the general trends as a basis from which to compare different algorithms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both Hearst (1994, 1997) and Foltz et al (1998) use vector space methods discussed below to represent and compare units of text.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following the advice of Gale et al. (1992a), I compare the algorithm against both upper and lower bounds.</S><S sid = NA ssid = NA>Another possibility would be to use semantic similarity information as computed in Schiitze (1993), Resnik (1993), or Dagan et al. (1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, Hearst (1994, 1997) and Foltz et al (1998) differ on how text units are defined and on how to interpret the results of a comparison.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Figure 4 shows a plot of the results of applying the block comparison algorithm to the Stargazer text.</S><S sid = NA ssid = NA>These scores appear in Table 1 (results at 33% are also shown for comparison purposes).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The text unit's definition in Hearst (1994, 1997) and Foltz et al (1998) is generally task dependent, depending on what size gives the best results.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This section compares the algorithm against reader judgments, since author markups are fallible and are usually applied to text types that this algorithm is not designed for, and Hearst (1994) shows how to use TextTiles in a task (although it does not show whether or not the results of the algorithms used here are better than some other algorithm with similar goals).</S><S sid = NA ssid = NA>Salton et at.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hearst likewise chooses a large unit, 6 token-sequences of 20 tokens (Hearst, 1994), but varies these parameters dependent on the characteristics of the text to be segmented, e.g. paragraph size.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This value, labeled k, varies slightly from text to text; as a heuristic it is the average paragraph length (in token-sequences).</S><S sid = NA ssid = NA>In practice, setting w to 20 tokens per token-sequence works best for many texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hearst (1994, 1997) in contrast uses a relative comparison of cohesion, by recasting vector comparisons as depth scores.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These new scores, called depth scores, corresponding to how sharp a change occurs on both sides of the tokensequence gap, are then sorted.</S><S sid = NA ssid = NA>The relative height of the peak to the right of i is added to the relative height of the peak to the left.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P94-1002.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hearst (1994, 1997) was replicated using the JTextTile (Choi, 1999) Java soft ware.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>I have used the results of TextTiling in a new paradigm for information access on fulltext documents (Hearst 1994).</S><S sid = NA ssid = NA>This section describes two algorithms for discovering subtopic structure using term repetition as a lexical cohesion indicator.</S> | Discourse Facet:  NA | Annotator: Automatic


