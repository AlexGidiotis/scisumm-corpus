Citance Number: 1 | Reference Article:  P05-1057.txt | Citing Article:  H05-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>These approaches include an enhanced HMM alignment model that uses part-of speech tags (Toutanova et al, 2002), a log-linear combination of IBM translation models and HMM models (Och and Ney, 2003), techniques that rely on dependency relations (Cherry and Lin, 2003), and a log-linear combination of IBM Model 3 alignment probabilities, POS tags, and bilingual dictionary coverage (Liu et al, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Och and Ney (2003) proposed Model 6, a log-linear combination of IBM translation models and HMM model.</S><S sid = NA ssid = NA>We use IBM Model 3 alignment probabilities, POS correspondence, and bilingual dictionary coverage as features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P05-1057.txt | Citing Article:  P06-2014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Liu et al., 2005) uses a log-linear model with a greedy search.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use a greedy search algorithm to search the alignment with highest probability in the space of all possible alignments.</S><S sid = NA ssid = NA>The greedy search algorithm for general loglinear models is formally described as follows: Input: e, f, eT, fT, and D Output: a The above search algorithm, however, is not efficient for our log-linear models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P05-1057.txt | Citing Article:  P06-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We will retrain the Chinese parser on Penn Chinese Treebank version 5.0 and try to improve word alignment quality using log-linear models as suggested in (Liu et al, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Log-Linear Models For Word Alignment</S><S sid = NA ssid = NA>The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P05-1057.txt | Citing Article:  D07-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Liu et al, 2005) presented a log-linear model combining IBM Model 3 trained in both directions with heuristic features which resulted in a 1-to-1 alignment.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have presented a framework for word alignment based on log-linear models between parallel texts.</S><S sid = NA ssid = NA>The relationship between the translation model and the alignment model is given by: Although IBM models are considered more coherent than heuristic models, they have two drawbacks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P05-1057.txt | Citing Article:  D09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The F-measures for Chinese-English and Arabic-English are usually around 80% (Liu et al, 2005) and 70% (Fraser and Marcu, 2007), respectively.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present in this section results of experiments on a parallel corpus of Chinese-English texts.</S><S sid = NA ssid = NA>The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P05-1057.txt | Citing Article:  P06-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Liu et al (2005) used a conditional log-linear model with similar features to those we have employed.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Log-Linear Models For Word Alignment</S><S sid = NA ssid = NA>For log-linear models, POS information and an additional dictionary are used, which is not the case for GIZA++/IBM models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P05-1057.txt | Citing Article:  W10-2917.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>2004AA114010).</S><S sid = NA ssid = NA>Treated as feature functions, syntactic dependencies can be easily incorporated into log-linear models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P05-1057.txt | Citing Article:  W10-2917.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Liu et al (2005) propose a log-linear model for the alignment between two sentences, in which different features can be used to describe the alignment quality.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Log-Linear Models For Word Alignment</S><S sid = NA ssid = NA>The use of POS information for improving statistical alignment quality of the HMM-based model is described 1If there is a target word which is assigned to more than one source words, h(a, e, f) = 0. in (Toutanova et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P05-1057.txt | Citing Article:  N06-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Analternative ME approach models alignment directly as a log-linear combination of feature functions (Liu et al., 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Log-Linear Models For Word Alignment</S><S sid = NA ssid = NA>Treated as feature functions, syntactic dependencies can be easily incorporated into log-linear models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P05-1057.txt | Citing Article:  P06-2122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To make more confident conclusions, we also did tests on a larger hand-aligned data set used in Liu et al (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Statistical approaches, which depend on a set of unknown parameters that are learned from training data, try to describe the relationship between a bilingual sentence pair (Brown et al., 1993; Vogel and Ney, 1996).</S><S sid = NA ssid = NA>However, the search algorithm we proposed is supervised, relying on a hand-aligned bilingual corpus, while the baseline approach of IBM alignments is unsupervised.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P05-1057.txt | Citing Article:  W07-0405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>2004AA114010).</S><S sid = NA ssid = NA>Treated as feature functions, syntactic dependencies can be easily incorporated into log-linear models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P05-1057.txt | Citing Article:  H05-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Liu et al (2005) also develop a log-linear model, based on IBM Model 3.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Och and Ney (2003) proposed Model 6, a log-linear combination of IBM translation models and HMM model.</S><S sid = NA ssid = NA>Table 2 compares the results of our log-linear models with IBM Model 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P05-1057.txt | Citing Article:  D11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A straightforward approach to the alignment matrix is to build a log linear model (Liu et al, 2005) for the probability of the alignment A.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Log-Linear Models For Word Alignment</S><S sid = NA ssid = NA>An alignment a is defined as a subset of the Cartesian product of the word positions: We define the alignment problem as finding the alignment a that maximizes Pr(a  |e, f) given e and f. We directly model the probability Pr(a  |e, f).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P05-1057.txt | Citing Article:  D11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, the sum over all alignments may be restricted to a sum over the n-best list from other aligners (Liu et al, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>4 requires a sum over a large number of possible alignments.</S><S sid = NA ssid = NA>The set of considered alignments are also called n-best list of alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P05-1057.txt | Citing Article:  D11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is a key difference between our model and (Liu et al, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Brown et al. (1993) proposed a series of statistical models of the translation process.</S><S sid = NA ssid = NA>An especially well-founded framework is maximum entropy (Berger et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


