Citance Number: 1 | Reference Article:  W07-2216.txt | Citing Article:  D07-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Koo et al (2007) and McDonald and Satta (2007) both describe how the Matrix Tree Theorem can be applied to computing the sum of scores of edge factored dependency trees and the edge marginals.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Independently of this work, Koo et al. (2007) and Smith and Smith (2007) showed that the MatrixTree Theorem can be used to train edge-factored log-linear models of dependency parsing.</S><S sid = NA ssid = NA>Following the work of Koo et al. (2007) and Smith and Smith (2007), it is possible to compute all expectations in O(n3 + |L|n2) through matrix inversion.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-2216.txt | Citing Article:  P13-2109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The main obstacle is that non-projective parsing is NP-hard beyond arc-factored models (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S><S sid = NA ssid = NA>However, for the non-projective case, moving beyond edge-factored models will almost certainly lead to intractable parsing problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-2216.txt | Citing Article:  P09-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The marginal p (yi=k|x;theta) can be computed by dividing this score by Zx (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Using these values, each expectation is computed in O(1).</S><S sid = NA ssid = NA>A dth order factorization is one in which the score factors only over the d nearest edges in the neighbourhoods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-2216.txt | Citing Article:  P09-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Because these features consider multiple edges, including them in the CRF model would make exact inference intractable (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Consider a first-order vertical Markovization in which the score for a dependency graph factors over pairs of vertically adjacent edges2, where k hiwk0 ij is the weight of including both edges (h, i)k and (i, j)k0 in the dependency graph.</S><S sid = NA ssid = NA>This suggests that it is unlikely that exact non-projective dependency parsing is tractable for any model richer than the edge-factored model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-2216.txt | Citing Article:  D08-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Exact algorithms for dependency parsing (Eisner and Satta, 1999; McDonald et al., 2005b) are tractable only when the model makes very strong, linguistically unsupportable independence assumptions, such as "arc factorization" for nonprojective dependency parsing (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (Paskin, 2001; McDonald et al., 2005a; McDonald et al., 2005b).</S><S sid = NA ssid = NA>A consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-2216.txt | Citing Article:  D08-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A projective dependency parse (top), and a non-projective dependency parse (bottom) for two English sentences; examples from McDonald and Satta (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For many languages, a significant portion of sentences require a non-projective dependency analysis (Buchholz et al., 2006).</S><S sid = NA ssid = NA>On the Complexity of Non-Projective Data-Driven Dependency Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-2216.txt | Citing Article:  D08-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the projective case, the arc-factored assumption can be weakened in certain ways while maintaining polynomial parser runtime (Eisner and Satta, 1999), but not in the non-projective case (McDonald and Satta, 2007), where finding the highest-scoring tree becomes NP-hard.McDonald and Pereira (2006) adopted an approximation based on O (n3) projective parsing followed by rearrangement to permit crossing arcs, achieving higher performance.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S><S sid = NA ssid = NA>The complexity results given here suggest that polynomial chart-parsing algorithms do not exist for the non-projective case.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-2216.txt | Citing Article:  D08-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Exact parsing under such model, with arbitrary second-order features, is intractable (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>2McDonald and Pereira (2006) define this as a second-order Markov assumption.</S><S sid = NA ssid = NA>This suggests that it is unlikely that exact non-projective dependency parsing is tractable for any model richer than the edge-factored model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-2216.txt | Citing Article:  P09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A projective dependency parse (top), and a non-projective dependency parse (bottom) for two English sentences; examples from McDonald and Satta (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For many languages, a significant portion of sentences require a non-projective dependency analysis (Buchholz et al., 2006).</S><S sid = NA ssid = NA>On the Complexity of Non-Projective Data-Driven Dependency Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-2216.txt | Citing Article:  P09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While in the projective case, the arc-factored assumption can be weakened in certain ways while maintaining polynomial parser runtime (Eisner and Satta,1999), the same does not happen in the nonprojective case, where finding the highest-scoring tree becomes NP-hard (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The projective case has been investigated in Paskin (2001).</S><S sid = NA ssid = NA>The complexity results given here suggest that polynomial chart-parsing algorithms do not exist for the non-projective case.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-2216.txt | Citing Article:  P09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While, as pointed out by McDonald and Satta (2007), the inclusion of these features makes inference NP hard, by relaxing the integer constraints we obtain approximate algorithms that are very efficient and competitive with state-of-the-art methods.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (McDonald and Pereira, 2006) and exact methods through integer linear programming (Riedel and Clarke, 2006) or branch-and-bound algorithms (Hirakawa, 2006).</S><S sid = NA ssid = NA>Syntactic dependency parsing has seen a number of new learning and inference algorithms which have raised state-of-the-art parsing accuracies for many languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-2216.txt | Citing Article:  E09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>the problem is intractable in the absence of this assumption (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For systems that model arity constraints we give a reduction from the Hamiltonian graph problem suggesting that the parsing problem is intractable in this case.</S><S sid = NA ssid = NA>The primary problem in treating each dependency as independent is that it is not a realistic assumption.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-2216.txt | Citing Article:  E09-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Exhaustive non projective dependency parsing with more powerful models is intractable (McDonald and Satta, 2007), and one has to resort to approximation algorithms (McDonald and Pereira, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S><S sid = NA ssid = NA>Recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (McDonald and Pereira, 2006) and exact methods through integer linear programming (Riedel and Clarke, 2006) or branch-and-bound algorithms (Hirakawa, 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-2216.txt | Citing Article:  C10-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unfortunately, global inference and learning for graph-based dependency parsing is typically NP-hard (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Many learning paradigms can be defined as inference-based learning.</S><S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-2216.txt | Citing Article:  D10-1125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unfortunately, the non-projective parsing problem is known to be NP-hard for all but the simplest models (McDonald and Satta, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S><S sid = NA ssid = NA>On the Complexity of Non-Projective Data-Driven Dependency Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-2216.txt | Citing Article:  D10-1125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>McDonald and Pereira (2006) and McDonald and Satta (2007) describe complexity results for non projective parsing, showing that parsing for a variety of models is NP-hard.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In McDonald and Pereira (2006), it was shown that non-projective dependency parsing with horizontal Markovization is FNP-hard.</S><S sid = NA ssid = NA>On the Complexity of Non-Projective Data-Driven Dependency Parsing</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-2216.txt | Citing Article:  D07-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Second, McDonald and Satta (2007) propose an O (n5) algorithm for computing the marginals, as opposed to the O (n3) matrix-inversion approach used by Smith and Smith (2007) and ourselves.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following the work of Koo et al. (2007) and Smith and Smith (2007), it is possible to compute all expectations in O(n3 + |L|n2) through matrix inversion.</S><S sid = NA ssid = NA>Independently of this work, Koo et al. (2007) and Smith and Smith (2007) showed that the MatrixTree Theorem can be used to train edge-factored log-linear models of dependency parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-2216.txt | Citing Article:  D07-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, both papers propose minimum-risk decoding, and McDonald and Satta (2007) discuss unsupervised learning and language modeling, while Smith and Smith (2007) define hidden variable models based on spanning trees.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following the work of Koo et al. (2007) and Smith and Smith (2007), it is possible to compute all expectations in O(n3 + |L|n2) through matrix inversion.</S><S sid = NA ssid = NA>Independently of this work, Koo et al. (2007) and Smith and Smith (2007) showed that the MatrixTree Theorem can be used to train edge-factored log-linear models of dependency parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


