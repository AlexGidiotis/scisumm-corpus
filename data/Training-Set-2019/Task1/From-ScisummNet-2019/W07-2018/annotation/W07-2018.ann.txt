Citance Number: 1 | Reference Article:  W07-2018.txt | Citing Article:  D08-1048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Therefore, there is nowadays a pressing need to adopt learning approaches to extend the coverage of the FrameNet lexicon by automatically acquiring new LUs, a task we call LU induction, as recently proposed at SemEval-2007 (Baker et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>systems labeled three new texts automatically.</S><S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-2018.txt | Citing Article:  D08-1048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We also tested our models on a realistic gold-standard set of 24 unknown LUs extracted from the SemEval-2007 corpus (Baker et al., 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>For frame nodes, the partici pants got full credit if the frame of the node matched the gold standard.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-2018.txt | Citing Article:  P14-1136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Johansson and Nugues (2007) presented the best performing system at SemEval 2007 (Baker et al, 2007), and Das et al (2010) improved performance, and later set the current state of the art on this task (Das et al,2014).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>(Scheffczyk et al., 2006; Frank and Semecky, 2004; Sinha and Narayanan, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-2018.txt | Citing Article:  S10-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous shared tasks have shown that frame-semantic SRL of running text is a hard problem (Baker et al, 2007), partly due to the fact that running text is bound to contain many frames for which no or little annotated training data are available.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>text in the training data was somewhat similar.</S><S sid = NA ssid = NA>3.1 Training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-2018.txt | Citing Article:  W10-2802.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It is one of the main reason for the performance drop of supervised SRL systems inout-of-domain scenarios (Baker et al, 2007) (Johansson and Nugues, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>systems labeled three new texts automatically.</S><S sid = NA ssid = NA>The systems submitted by the teams differed in their sensitivity to differences in the texts: UTD-SRL?s system varied by around 10% across texts, while LTH?s varied by 15%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-2018.txt | Citing Article:  W10-2802.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>LU induction has been integrated at SemEval-2007 as part of the Frame Semantic Structure Extraction shared task (Baker et al, 2007), where systems are requested to assign the correct frame to a given LU, even when the LU is not yet present in FrameNet.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>In principle, the deci sion as to what frame to add a new LU to should be helped by the same criteria that are used to assign polysemous lemmas to existing frames.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-2018.txt | Citing Article:  S12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In our experiments, we use FrameNet 1.5, which contains a lexicon of 877 frames and 1,068 role labels, and 78 documents with multiple predicate argument annotations (a superset of the SemEval shared task dataset; Baker et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>After training on FN annotations, the participants?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-2018.txt | Citing Article:  E09-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We will also use our measures in applications, to check their effectiveness in supporting various tasks, e.g. in mapping frames across Text and Hypothesis in RTE, in linking related frames in discourse, or in inducing frames for LU which are not in FrameNet (Baker et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>5.1 Partial credit for related frames.</S><S sid = NA ssid = NA>The evaluation measured precision and recall for frames and frame elements, with partial credit for incorrect but closely related frames.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-2018.txt | Citing Article:  W09-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>They used the mapping in the Semeval-2007 task on frame-semantic structure extraction (Baker et al, 2007) in order to find target words in open text and assign frames. Crespo and Buitelaar (2008) carried out an automatic mapping of medical-oriented frames to WordNet synsets applying a Statistical Hypothesis Testing to select synsets attached to a lexical unit that were statistically significant using a given reference corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>In principle, the deci sion as to what frame to add a new LU to should be helped by the same criteria that are used to assign polysemous lemmas to existing frames.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-2018.txt | Citing Article:  N10-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our parser achieves the best published results to date on the SemEval 07 FrameNet task (Baker et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>The major part of the training data for the task con sisted of the current data release from FrameNet(Release 1.3), described in Sec.2 This was supple mented by additional training data made availablethrough SemEval to participants in this task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-2018.txt | Citing Article:  N10-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>More details can be found in Baker et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Please consult the separate system papers for details about the features used.</S><S sid = NA ssid = NA>(Scheffczyk et al., 2006; Frank and Semecky, 2004; Sinha and Narayanan, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-2018.txt | Citing Article:  N10-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recent work on frame-semantic parsing in which sentences may contain multiple frames to be recognized along with their arguments has used the SemEval 07 data (Baker et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>The train ing data was FN annotated sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-2018.txt | Citing Article:  W09-1321.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Domain-oriented semantic structures are valuable assets because their representation suits information needs in the domain; however, the extraction of such structures is difficult due to the large gap between the text and these structures. On the other hand, the extraction of linguistically oriented semantics from text has long been studied in computational linguistics, and has recently been formalized as Semantic Role Labeling (Gildea and Jurafsky, 2002), and semantic structure extraction (Baker et al, 2007) (Surdeanu et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>The other NTI text, ?Work Advances?, while in the same domain, was shorter and closer to newspaper style than the rest of the NTI texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-2018.txt | Citing Article:  D09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A variety of methods have been developed for semantic role labeling with reasonably good performance (F 1 measures in the low 80s on standard test collections for English; we refer the interested reader to the proceedings of the SemEval-2007 shared task (Baker et al, 2007) for an overview of the state-of-the-art).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>The task of labeling frame-evoking words with ap propriate frames is similar to WSD, while the task of assigning frame elements is called Semantic Role Labeling (SRL), and has been the subject of several shared tasks at ACL and CoNLL.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-2018.txt | Citing Article:  D09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Considering how the performance of supervised systems degrades on out-of-domain data (Bakeret al, 2007), not to mention unseen events, semi supervised or unsupervised methods seem to offer the primary near-term hope for broad coverage semantic role labeling.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The task of labeling frame-evoking words with ap propriate frames is similar to WSD, while the task of assigning frame elements is called Semantic Role Labeling (SRL), and has been the subject of several shared tasks at ACL and CoNLL.</S><S sid = NA ssid = NA>This task is a more advanced and realistic version of the Automatic Semantic Role Labeling task of Senseval-3 (Litkowski, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-2018.txt | Citing Article:  D09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We extracted features from dependency parses corresponding to those routinely used in the semantic role labeling literature (see Baker et al (2007) for an overview).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Please consult the separate system papers for details about the features used.</S><S sid = NA ssid = NA>2.2 Semantic dependency graphs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-2018.txt | Citing Article:  D11-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A variety of other systems have focused on FrameNet-based (1998) SRL instead, including those that participated in the SemEval-2007 Task 19 (Baker et al, 2007) and work by Das et al (2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>The Berkeley FrameNet project (hereafter FN) (Fillmore et al, 2003) is creating a computer- and human-readable lexical resource for English, based on the theory of frame semantics and supported by corpus evidence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-2018.txt | Citing Article:  E09-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The approaches are too numerous to list; we refer the interested reader to the proceedings of the SemEval-2007 shared task (Baker et al, 2007) for an overview of the state of-the-art.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>SemEval-2007 Task 19: Frame Semantic Structure Extraction</S><S sid = NA ssid = NA>by any interested party.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W07-2018.txt | Citing Article:  E09-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We extracted features from dependency parses corresponding to those routinely used in the semantic role labeling literature (see Baker et al (2007) for an overview). SVM classifiers were trained to identify the arguments and label them with appropriate roles.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The LTH system used only SVM classifiers, while the UTD-SRL system used a combination of SVM and ME classifiers, determined experimentally.</S><S sid = NA ssid = NA>Please consult the separate system papers for details about the features used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W07-2018.txt | Citing Article:  P11-1144.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recently, since the release of full-text annotations in SemEval 07 (Baker et al, 2007), there has been work on identifying multiple frames and their corresponding sets of arguments in a sentence.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The remainder are from full-text annotation in which each sentence isannotated for all predicators; 1,700 sentences are annotated in the full-text portion of the database, ac counting for roughly 11,700 annotation sets, or 6.8 predicators (=annotation sets) per sentence.</S><S sid = NA ssid = NA>After training on FN annotations, the participants?</S> | Discourse Facet:  NA | Annotator: Automatic


