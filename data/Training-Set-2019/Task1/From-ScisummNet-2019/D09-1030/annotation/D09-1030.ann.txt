Citance Number: 1 | Reference Article:  D09-1030.txt | Citing Article:  N10-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It is possible that the length of stay of an annotator in the pool is not independent of her diligence; for example, Callison-Burch (2009) found in his AMT experiments with tasks related to machine translation that lazy annotators tended to stay longer and do more annotations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>We provided these instructions: Edit Machine Translation Your task is to edit the machine translation making as few changes as possible so that it matches the meaning of the human translation and is good English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D09-1030.txt | Citing Article:  P10-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We will perform a semi-automatic validation of BabelNet, e.g. by exploiting Amazon's Mechanical Turk (Callison-Burch, 2009) or designing a collaborative game (von Ahn, 2006) to validate low-ranking mappings and translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluated the feasibility of using Mechanical Turk to perform HTER.</S><S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D09-1030.txt | Citing Article:  W10-0705.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, Callison-Burch (2009) used MTurk to evaluate machine translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>Following Callison-Burch et al. (2008), we assigned a score to each of the 11 MT systems based on how often its translations were judged to be better than or equal to any other system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D09-1030.txt | Citing Article:  W10-0731.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Callison-Burch, 2009) uses MTurk workers for manual evaluation of automatic translation quality and experiments with weighed voting to combine multiple annotations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>Although it is not common for manual evaluation results to be reported in conference papers, several large-scale manual evaluations of machine translation quality take place annually.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D09-1030.txt | Citing Article:  W12-3153.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The use of crowd sourcing to evaluate machine translation and to build development sets was pioneered by Callison-Burch (2009) and Zaidan and Callison-Burch (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>The cost of using Mechanical Turk is low enough that we might consider attempting quixotic things like human-in-the-loop minimum error rate training (Zaidan and Callison-Burch, 2009), or doubling the amount of training data available for Urdu.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D09-1030.txt | Citing Article:  W10-0709.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Callison-Burch (2009), we treat evaluation as a weighted voting problem where each annotator's contribution is weighted by agreement with either a gold standard or with other annotators.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The contribution of each component system is weighted by the expectation that it will produce good output.</S><S sid = NA ssid = NA>To avoid letting careless annotators drag down results, we experimented with weighted voting.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D09-1030.txt | Citing Article:  C10-2109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It has also been used in MT evaluation (Callison-Burch, 2009), though that evaluation used reference translations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>If none of the five edits was deemed to be acceptable, then we used the edit distance between the MT and the reference.</S><S sid = NA ssid = NA>The Turkers were shown a source sentence, a reference translation, and translations from five MT systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D09-1030.txt | Citing Article:  W10-0734.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As an example, among the collected material several translations in languages other than English revealed a massive and defective use of on-line translation tools by untrusted workers, as also observed by (Callison-Burch, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We had bilingual graduate students translate the first 50 English sentences of that corpus into French, German and Spanish, so that we could re-use the multiple English reference translations.</S><S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D09-1030.txt | Citing Article:  W10-0710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We do not select German, French and other language pairs as they have already been explored by Callison-Burch (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>Turkers are free to select whichever HITs interest them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D09-1030.txt | Citing Article:  W10-0714.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Furthermore, previous research shows the effectiveness of crowd sourcing as a method of accomplishing labor intensive natural language processing tasks (Callison-Burch, 2009) and the effectiveness of using MTurk for a variety of natural language automation tasks (Snow, Jurafsy, & O'Connor, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Snow et al. (2008) examined the accuracy of labels created using Mechanical Turk for a variety of natural language processing tasks.</S><S sid = NA ssid = NA>The advantage of this type of evaluation is that the results have a natural interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D09-1030.txt | Citing Article:  D10-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The value of this upper bound is quite consistent with the bound computed similarly by Callison-Burch (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This gives an upper bound on the expected quality.</S><S sid = NA ssid = NA>An upper bound is indicated by the expert-expert bar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D09-1030.txt | Citing Article:  N10-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>; at an Arizona clinic These answers were judged to be incorrect: Locklear was retired in Arizona; Arizona; Arizona; in Arizona; Ms.Locklaer were laid off after a treatment out of the clinic in Arizona.</S><S sid = NA ssid = NA>Moreover, by weighting the votes of five Turkers, non-expert judgments perform at the upper bound of expert-expert correlation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D09-1030.txt | Citing Article:  W10-0701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>; at an Arizona clinic These answers were judged to be incorrect: Locklear was retired in Arizona; Arizona; Arizona; in Arizona; Ms.Locklaer were laid off after a treatment out of the clinic in Arizona.</S><S sid = NA ssid = NA>Moreover, by weighting the votes of five Turkers, non-expert judgments perform at the upper bound of expert-expert correlation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D09-1030.txt | Citing Article:  N10-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Callison-Burch (2009) showed similar results for machine translation evaluation, and further showed that Turkers could accomplish complex tasks like translating Urdu or creating reading comprehension tests.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We showed how a reading comprehension test could be created, administered, and graded, with only very minimal intervention.</S><S sid = NA ssid = NA>We report on experiments evaluating translation quality with HTER and with reading comprehension tests.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D09-1030.txt | Citing Article:  W10-0703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>; at an Arizona clinic These answers were judged to be incorrect: Locklear was retired in Arizona; Arizona; Arizona; in Arizona; Ms.Locklaer were laid off after a treatment out of the clinic in Arizona.</S><S sid = NA ssid = NA>Moreover, by weighting the votes of five Turkers, non-expert judgments perform at the upper bound of expert-expert correlation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D09-1030.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recently, AMT has been shown to be an effective tool for annotation and evalatuation in NLP tasks ranging from word similarity detection and emotion detection (Snow et al, 2008) to Machine Translation quality evaluation (Callison-Burch, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>These tasks included word sense disambiguation, word similarity, textual entailment, and temporal ordering of events, but not machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D09-1030.txt | Citing Article:  P11-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Callison-Burch (2009) proposed several ways to evaluate MT output on MTurk.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>Therefore, having people evaluate translation output would be preferable, if it were more practical.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D09-1030.txt | Citing Article:  W11-0409.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Over the last several of years, Mechanical Turk, introduced by Amazon as "artificial artificial intelligence", has been used successfully for a number of NLP tasks, including robust evaluation of machine translation systems by reading comprehension (Callison-Burch, 2009), and other tasks explored in the recent NAACL workshop (Callison-Burch and Dredze, 2010b).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Amazon describes its Mechanical Turk web service1 as artificial artificial intelligence.</S><S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D09-1030.txt | Citing Article:  W10-0704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Snow et al. (2008) examined the accuracy of labels created using Mechanical Turk for a variety of natural language processing tasks.</S><S sid = NA ssid = NA>The advantage of this type of evaluation is that the results have a natural interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D09-1030.txt | Citing Article:  W10-1701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>On another way, an application can combine active learning (Arora et al, 2009) and crowd sourcing, asking non-expertise such as workers of Amazon Mechanical Turk to label crucial alignment links that can improve the system with low cost, which is now a promising methodology in NLP areas (Callison-Burch, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These systems were selected from WMT09 (Callison-Burch et al., 2009).</S><S sid = NA ssid = NA>The low cost of the non-expert labor found on Mechanical Turk is cheap enough to collect redundant annotations, which can be utilized to ensure translation quality.</S> | Discourse Facet:  NA | Annotator: Automatic


