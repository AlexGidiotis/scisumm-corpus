Citance Number: 1 | Reference Article:  W06-1670.txt | Citing Article:  W07-2051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Supersense tagging A WordNet-based supersense tagger (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We take a sequence labeling approach to learning a model for supersense tagging.</S><S sid = NA ssid = NA>We define a tagset based on Wordnet’s lexicographers classes, or supersenses (Ciaramita and Johnson, 2003), cf.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-1670.txt | Citing Article:  P14-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>For each observed word xi in the data � extracts the following features: described below.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-1670.txt | Citing Article:  W08-2121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Columns 1 - 3 were predicted using the tagger of Ciaramita and Altun (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The first sense feature (2) is the label predicted for xi by the baseline model, cf.</S><S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-1670.txt | Citing Article:  W07-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>grained distinctions of WN (Hearst and Schutze,1993) (Peters et al, 1998) (Mihalcea and Moldovan, 2001) (Agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997) (Ciaramita and Johnson, 2003) (Villarejo et al, 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al., 2000; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-1670.txt | Citing Article:  S10-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997), (Ciaramita and Johnson, 2003), (Villarejo et al, 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>80s (Carreras et al., 2002; Florian et al., 2003), while Bio-NER accuracy ranges between the low 70s and 80s, depending on the data-set used for training/evaluation (Dingare et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-1670.txt | Citing Article:  P08-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Wherever applicable, we explore different syntactic and semantic representations of the textual content, e.g., extracting the dependency-based representation of the text or generalizing words to their WordNet supersenses (WNSS) (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We define a tagset based on Wordnet’s lexicographers classes, or supersenses (Ciaramita and Johnson, 2003), cf.</S><S sid = NA ssid = NA>We defined a tagset based on Wordnet supersenses, a much simpler and general semantic model than Wordnet which, however, preserves significant polysemy information and includes standard named entity recognition categories.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-1670.txt | Citing Article:  P08-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Sentences were annotated with WNSS categories, using the tagger of Ciaramita and Altun (2006), which annotates text with a 46-label tag set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Named entities of the categories “person”, “location” and “group” are also annotated.</S><S sid = NA ssid = NA>On this four tags the tagger achieves an average 82.46% F-score, not too far from NER results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-1670.txt | Citing Article:  W10-2601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the implementation available from http: //sourceforge.net/projects/supersensetag, more details on this tagger can be found in (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The tagger described in this paper is free software and can be downloaded from http://www.loa-cnr.it/ciaramita.html.</S><S sid = NA ssid = NA>The system based on the HMM tagger (Molina et al., 2004), 6Scoring was performed with a re-implementation of the “conlleval” script. achieved an F-score of 60.9%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-1670.txt | Citing Article:  W07-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This result is particularly interesting as a supersense tagger can easily provide a satisfactory accuracy (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Another interesting issue is the granularity of the tagset.</S><S sid = NA ssid = NA>The lower portion of Table 5 summarizes the results on the five most frequent noun and verb supersense labels on the Senseval-3 data, providing more specific evidence for the supersense tagger’s disambiguation accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-1670.txt | Citing Article:  P13-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This annotation was performed automatically using the SuperSense Tagger (Ciaramita and Altun, 2006) and includes 1183 named-entities and WordNet Super-Senses.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The original annotation with Wordnet 1.6 synset IDs has been converted to the most recent version 2.0 of Wordnet.</S><S sid = NA ssid = NA>Named entities of the categories “person”, “location” and “group” are also annotated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-1670.txt | Citing Article:  P13-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We recommend mate-tools (Bjorkelund et al, 2009) and SuperSenseTagger (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al., 2000; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-1670.txt | Citing Article:  P09-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used Ciaramita and Altun's Su per Sense Tagger (Ciaramita and Altun, 2006) to tag the supersenses.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>Since each lexicographer category groups together many synsets they have been also called supersenses (Ciaramita and Johnson, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-1670.txt | Citing Article:  S12-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is the coarse lexicographic category label, elsewhere denoted supersense (Ciaramita and Altun, 2006), which is the terminology we use.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since each lexicographer category groups together many synsets they have been also called supersenses (Ciaramita and Johnson, 2003).</S><S sid = NA ssid = NA>For this reason, in all obvious cases, we substituted the “noun.Tops” label with the more specific supersense label for the noun4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-1670.txt | Citing Article:  S12-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>we use the out puts of SuperSense Tagger (Ciaramita and Altun,2006), which is optimised for assigning the super senses described above, and can outperform a WNF style baseline on at least some datasets.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The supersense tagger was trained on the Semcor datasets SEM and SEMv.</S><S sid = NA ssid = NA>These features are described in detail in Section 4.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-1670.txt | Citing Article:  P11-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use SuperSenseTagger (Ciaramita and Altun,2006) as our NER tagger.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use the perceptron algorithm for sequence tagging (Collins, 2002).</S><S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-1670.txt | Citing Article:  W07-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>SUPERSENSE LEARNER brings together under one system the features previously used in the SENSELEARNER (Mihalcea and Csomai, 2005) and the SUPERSENSE (Ciaramita and Altun, 2006) all-words word sense disambiguation systems.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>Word sense disambiguation (WSD) is the task of deciding the intended sense for ambiguous words in context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-1670.txt | Citing Article:  W07-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A detailed description of the features used and the tagger can be foundin (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We used the following combination of spelling/morphological and contextual features.</S><S sid = NA ssid = NA>These features are described in detail in Section 4.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-1670.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997), (Ciaramita and Johnson, 2003), (Villarejo et al, 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>80s (Carreras et al., 2002; Florian et al., 2003), while Bio-NER accuracy ranges between the low 70s and 80s, depending on the data-set used for training/evaluation (Dingare et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-1670.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>WSD are those reported by (Ciaramita and Altun, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Ciaramita et al., 2005)).</S><S sid = NA ssid = NA>This indicates that sense granularity is only one of the problems in WSD.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-1670.txt | Citing Article:  P13-2083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Relations and POS tags are obtained using a dependency parser Tratz and Hovy (2011), supersense tags using sstlight Ciaramita and Altun (2006), and lemmas us 468.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>POS features of the form pos;[0] extract the first character from the POS label, thus providing a simplified representation of the POS tag.</S><S sid = NA ssid = NA>On this four tags the tagger achieves an average 82.46% F-score, not too far from NER results.</S> | Discourse Facet:  NA | Annotator: Automatic


