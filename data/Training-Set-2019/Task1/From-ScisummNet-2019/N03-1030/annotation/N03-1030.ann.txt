Citance Number: 1 | Reference Article:  N03-1030.txt | Citing Article:  W04-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>SEE allowed the judges to step through predefined units of the model summary (elementary discourse units/EDUs) (Soricut and Marcu, 2003) and for each unit of that summary, mark the sentences in the peer summary that expressed [all (4), most (3), some (2), hardly any (1) or none (0)] of the content in the current model summary unit.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The discourse segmenter proposed here takes as input a sentence and outputs its elementary discourse unit boundaries.</S><S sid = NA ssid = NA>In this section, we present a discourse segmentation algorithm that deals with segmenting sentences into elementary discourse units.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N03-1030.txt | Citing Article:  P14-2085.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This mapping leads to the notion of a dominance set over a discourse segmented lexicalized syntactic tree.</S><S sid = NA ssid = NA>In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N03-1030.txt | Citing Article:  N07-3006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our model was trained and tested on RST-DT (2002) and achieves a performance of up to 86.12% F-Score, which is comparable to Soricut and Marcu (2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The (RST-DT, 2002) corpus uses 110 different rhetorical relations.</S><S sid = NA ssid = NA>This is even more remarkable given that the discourse corpus (RST-DT, 2002) was built with no syntactic theory in mind.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N03-1030.txt | Citing Article:  W10-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentence Level Discourse Parsing Using Syntactic And Lexical Information</S><S sid = NA ssid = NA>Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N03-1030.txt | Citing Article:  P09-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Since segmentation is the first stage of discourse parsing, quality discourse segments are critical to building quality discourse representations (Soricut and Marcu, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We break down the problem of building sentence-level discourse trees into two sub-problems: discourse segmentation and discourse parsing.</S><S sid = NA ssid = NA>The discourse parsing model uses syntactic trees produced by Charniak’s parser (2000) and discourse segments produced by the algorithm described in Section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N03-1030.txt | Citing Article:  P09-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soricut and Marcu (2003) construct a statistical discourse segmenter as part of their sentence-level discourse parser (SPADE), the only implementation available for our comparison.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our statistical approach to sentence segmentation uses two components: a statistical model which assigns a probability to the insertion of a discourse boundary after each word in a sentence, and a segmenter, which uses the probabilities computed by the model for inserting discourse boundaries.</S><S sid = NA ssid = NA>The metric we use to evaluate the discourse segmenter records the accuracy of the discourse segmenter with respect to its ability to insert inside-sentence discourse boundaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N03-1030.txt | Citing Article:  N07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soricut and Marcu (2003) use syntactic features to identify sentence-internal RST structure.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The models use syntactic and lexical features.</S><S sid = NA ssid = NA>We denote such node , and the features we use are node , its parent , and the siblings of .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N03-1030.txt | Citing Article:  D09-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The test set includes only sentences for which our English parser (Soricut and Marcu, 2003) could produce a parse tree, which effectively excluded a few very long sentences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For this evaluation, we re-trained Charniak’s parser (2000) such that the test sentences from the discourse corpus were not seen by the syntactic parser during training.</S><S sid = NA ssid = NA>The remaining 5% of the sentences cannot be used in our approach, as no well-formed discourse tree can be associated with these sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N03-1030.txt | Citing Article:  W05-0613.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>One exception is Marcu's work (Marcu, 1997, 1999) (see also Soricut and Marcu (2003) for constructing discourse structures for individual sentences).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In our experiments we used as discourse structures only the discourse sub-trees spanning over individual sentences.</S><S sid = NA ssid = NA>Yet, they built discourse structures at sentence level that are not only consistent with the syntactic structures of sentences, but also derivable from them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N03-1030.txt | Citing Article:  W06-1317.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Within Rhetorical Structure Theory (RST), Soricut and Marcu (2003) have developed two probabilistic models for identifying clausal elementary discourse units and generating discourse trees at the sentence level.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S><S sid = NA ssid = NA>In this paper, we introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N03-1030.txt | Citing Article:  N06-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentence Level Discourse Parsing Using Syntactic And Lexical Information</S><S sid = NA ssid = NA>Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N03-1030.txt | Citing Article:  P07-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>their relation edges are obtained from the Spade system described in Soricut and Marcu (2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also compute the agreement between human annotators on the discourse segmentation task ( ), using the doubly-annotated discourse corpus mentioned in Section 2. described in this paper ( ) using syntactic trees produced by Charniak’s parser (2000), in comparison with the results obtained by the algorithm described in (Marcu, 2000) ( ), and baseline algorithms and , on the same test set.</S><S sid = NA ssid = NA>Tuple ENABLEMENT-NS[2,2,3] has a score of 0.40, obtained ATTRIBUTION-SN[1,1,3] has a score of 0.37 for the structure, and a score of 0.009 for the relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N03-1030.txt | Citing Article:  W04-2322.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soricut and Marcu (2003) also build up RST sentential trees to use in discourse parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.</S><S sid = NA ssid = NA>We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N03-1030.txt | Citing Article:  D07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and other text-structuring tasks.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Once we have the segmenting probabilities given by the statistical model, a straightforward algorithm is used to implement the segmenter.</S><S sid = NA ssid = NA>The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N03-1030.txt | Citing Article:  P12-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Soricut and Marcu, 2003) and (Polanyi et al., 2004) implement models to perform discourse parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we describe probabilistic models and algorithms that exploit the discourseannotated corpus produced by Carlson et al. (2003).</S><S sid = NA ssid = NA>(See (Carlson et al., 2003) for details concerning the corpus and the annotation process.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A discourse tree (Soricut and Marcu, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>An example of a discourse structure is the tree given in Figure 1.</S><S sid = NA ssid = NA>The overall probability of a discourse tree is obtained multiplying the structural probabilities and the relational probabilities for all the tuples in the discourse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soricut and Marcu (2003) introduce a statistical discourse segmenter, which is trained on RST DT to label words with boundary or no-boundary labels.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our statistical model assigns a segmenting probability for each word , where boundary, no-boundary .</S><S sid = NA ssid = NA>Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Like Soricut and Marcu (2003), they formulate the discourse segmentation task as a binary classification problem of deciding whether a word is the boundary or no-boundary of EDUs.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S><S sid = NA ssid = NA>Given a syntactic tree , the algorithm inserts a boundary after each word for which boundary .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soricut and Marcu (2003) and Subba and Di Eugenio (2007) use boundary labels, which are assigned to words at the end of EDUs.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As mentioned in Section 2, we use both 18 labels and 110 labels for the discourse relations.</S><S sid = NA ssid = NA>Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>SPADE is the work of Soricut and Marcu (2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).</S><S sid = NA ssid = NA>Recent work on Tree Adjoining Grammar-based lexicalized models of discourse (Forbes et al., 2001) has already shown how to exploit within a single framework lexical, syntactic, and discourse cues.</S> | Discourse Facet:  NA | Annotator: Automatic


