Citance Number: 1 | Reference Article:  W06-2933.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The pseudo-projective approach (Nivre and Nilsson, 2005): Transform non-projective training trees to projective ones but encode the information necessary to make the inverse transformation in the DEPREL, so that this inverse transformation can also be carried out on the test trees (Nivre et al, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Non-projective dependencies are captured indirectly by projectivizing the training data for the classifiers and applying an inverse transformation to the output of the parser.</S><S sid = NA ssid = NA>To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-2933.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S><S sid = NA ssid = NA>Table 2 shows final test results for each language and for the twelve required languages together.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-2933.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S><S sid = NA ssid = NA>By contrast, Turkish (Oflazer et al., 2003; Atalay et al., 2003) exhibits high root accuracy but consistently low attachment scores (about 88% for length 1 and 68% for length 2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-2933.txt | Citing Article:  P14-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Firstto Third-Order Features The feature templates of first to third-order features are mainly drawn from previous work on graph based parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al, 2006) and dual decomposition-based parsing (Martins et al, 2011).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Features of the type DEPREL have a special status in that they are extracted during parsing from the partially built dependency graph and may therefore contain errors, whereas all the other features have gold standard values during both training and parsing.2 Based on previous research, we defined a base model to be used as a starting point for languagespecific feature selection.</S><S sid = NA ssid = NA>The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-2933.txt | Citing Article:  P14-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>includes the most accurate parsers among Nivre et al (2006), McDonald et al (2006), Martins et al (2010), Martins et al (2011), Martins et al (2013), Koo et al (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al (2013).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S><S sid = NA ssid = NA>Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003), Chinese (Chen et al., 2003), Danish (Kromann, 2003), and Swedish (Nilsson et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-2933.txt | Citing Article:  C10-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both methods are sometimes combined (Nivre et al, 2006b).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S><S sid = NA ssid = NA>Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003), Chinese (Chen et al., 2003), Danish (Kromann, 2003), and Swedish (Nilsson et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-2933.txt | Citing Article:  C10-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We represented features with a parameter format partly inspired by MaltParser (Nivre et al, 2006a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our methodology for performing this task is based on four essential components: All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1</S><S sid = NA ssid = NA>Since the projective parsing algorithm and graph transformation techniques are the same for all data sets, our optimization efforts have been focused on feature selection, using a combination of backward and forward selection starting from the base model described in section 2.2, and parameter optimization for the SVM learner, using grid search for an optimal combination of the kernel parameters -y and r, the penalty parameter C and the termination criterion c, as well as the splitting feature s and the frequency threshold t. Feature selection and parameter optimization have to some extent been interleaved, but the amount of work done varies between languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-2933.txt | Citing Article:  C10-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>These parameters are identical to Nivre et al (2006b) to enable a comparison of the scores. We evaluated the feature candidates on a development set using the labeled and unlabeled attachment scores (LAS and UAS) that we computed with the eval.pl script from CoNLL-X.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>By contrast, Turkish (Oflazer et al., 2003; Atalay et al., 2003) exhibits high root accuracy but consistently low attachment scores (about 88% for length 1 and 68% for length 2).</S><S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-2933.txt | Citing Article:  D07-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following (Nivre et al, 2006), the encoding scheme called Head in (Nivre and Nilsson, 2005) was used to encode the original non-projective dependencies in the labels of the projectivized dependency tree.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label rTh, where r is the original label and h is the label of the original head in the nonprojective dependency graph.</S><S sid = NA ssid = NA>To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-2933.txt | Citing Article:  D07-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the base feature model defined in (Nivre et al, 2006) for all the languages but Arabic, Chinese, Czech, and Turkish.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The base model contains twenty features, but note that the fields LEMMA, CPOS and FEATS are not available for all languages.</S><S sid = NA ssid = NA>Features of the type DEPREL have a special status in that they are extracted during parsing from the partially built dependency graph and may therefore contain errors, whereas all the other features have gold standard values during both training and parsing.2 Based on previous research, we defined a base model to be used as a starting point for languagespecific feature selection.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-2933.txt | Citing Article:  D07-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For Arabic, Chinese, and Czech, we used the same feature models used in the CoNLL-X 948 shared task by (Nivre et al, 2006), and for Turkish we used again the base feature model but extended it with a single feature: the part-of-speech tag of the token preceding the current top of the stack.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The number of features in the optimized models varies from 16 (Turkish) to 30 (Spanish), but the models use all fields available for a given language, except that FORM is not used for Turkish (only LEMMA).</S><S sid = NA ssid = NA>The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-2933.txt | Citing Article:  W08-2104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Talbanken05 is a Swedish tree bank converted to dependency format, containing both written and spoken language (Nivre et al, 2006a). For each token, Talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).</S><S sid = NA ssid = NA>The number of features in the optimized models varies from 16 (Turkish) to 30 (Spanish), but the models use all fields available for a given language, except that FORM is not used for Turkish (only LEMMA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-2933.txt | Citing Article:  W08-2104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Nivre et al,2006b), where this parser was the best performing parser for Swedish.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We have the best reported score for Japanese, Swedish and Turkish, and the score for Arabic, Danish, Dutch, Portuguese, Spanish, and overall does not differ significantly from the best one.</S><S sid = NA ssid = NA>The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-2933.txt | Citing Article:  C10-2129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>MaltParser (Nivre et al, 2006) is a language independent system for data-driven dependency parsing which is freely available. It is based on a deterministic parsing strategy in combination with tree bank-induced classifiers for predicting parsing actions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).</S><S sid = NA ssid = NA>The evaluation shows that labeled pseudo-projective dependency parsing, using a deterministic parsing algorithm and SVM classifiers, gives competitive parsing accuracy for all languages involved in the 7Given that the average IG count of a word is 1.26 in the treebank, this means that they are normally adjacent to the head word. shared task, although the level of accuracy varies considerably between languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-2933.txt | Citing Article:  C10-2129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the training of the Malt parser model that we use in the stacking experiments, we use learner and parser settings identical to the ones optimized for German in the CoNLL-X shared task (Nivre et al, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data.</S><S sid = NA ssid = NA>Our methodology for performing this task is based on four essential components: All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-2933.txt | Citing Article:  W07-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use Nivre et al, (2006)'s dependency parser.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).</S><S sid = NA ssid = NA>This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-2933.txt | Citing Article:  P11-2033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unigram label information has been used in MaltParser (Nivre et al, 2006a; Nivre, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our methodology for performing this task is based on four essential components: All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1</S><S sid = NA ssid = NA>We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label rTh, where r is the original label and h is the label of the original head in the nonprojective dependency graph.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-2933.txt | Citing Article:  D12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In principle, it is restricted to projective dependency forests, but it can be used in conjunction with the pseudo-projective transformation (Nivre et al2006) in order to capture a restricted subset of non projective forests.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.</S><S sid = NA ssid = NA>Labeled Pseudo-Projective Dependency Parsing With Support Vector Machines</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-2933.txt | Citing Article:  D12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Table 4: Comparison of the parsing accuracy (LAS and UAS, excluding punctuation) of Nivre's arc-eager parser with projective buffer transitions (NE+LBA/RBA) and the parser with the pseudo-projective transformation (Nivre et al2006) decide between both with the restricted feature in formation available for buffer nodes.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.</S><S sid = NA ssid = NA>Non-projective dependencies can be recovered by applying an inverse transformation to the output of the parser, using a left-to-right, top-down, breadthfirst search, guided by the extended arc labels rTh assigned by the parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-2933.txt | Citing Article:  D12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To further put the obtained results into context, Table 4 compares the performance of the arc-eager parser with the projective buffer transition most suitable for each dataset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al2006) in the CoNLL-X shared task, one of the top two performing systems in that event.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.</S><S sid = NA ssid = NA>Non-projective dependencies can be recovered by applying an inverse transformation to the output of the parser, using a left-to-right, top-down, breadthfirst search, guided by the extended arc labels rTh assigned by the parser.</S> | Discourse Facet:  NA | Annotator: Automatic


