Citance Number: 1 | Reference Article:  P05-1020.txt | Citing Article:  W06-1633.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.</S><S sid = NA ssid = NA>Ranking candidate partitions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P05-1020.txt | Citing Article:  W06-1633.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our approach.</S><S sid = NA ssid = NA>Our approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P05-1020.txt | Citing Article:  W12-4508.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There are many different training example generation algorithms, e.g., McCarthy and Lehnert's method, Soon et als method, Ng and Cardies method (Ng, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In an attempt to reduce the training time, Soon et al.’s method creates a smaller number of training instances than McCarthy and Lehnert’s.</S><S sid = NA ssid = NA>Negative instances are generated as in Soon et al.’s method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P05-1020.txt | Citing Article:  P07-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S><S sid = NA ssid = NA>Specifically, a classifier is first trained to determine whether two NPs in a document are co-referring or not.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In particular, the best result for BNEWS is achieved using only method-based features, whereas the best result for NPAPER is obtained using only partitionbased features.</S><S sid = NA ssid = NA>To our knowledge, our work is the first attempt to optimize a ranker for clustering-level accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In particular, the best result for BNEWS is achieved using only method-based features, whereas the best result for NPAPER is obtained using only partitionbased features.</S><S sid = NA ssid = NA>Ng and Cardie’s system, on the other hand, employs RIPPER to train a coreference classifier on instances created by N&C’s method and represented by N&C’s feature set, inducing a partition on the given NPs via best-first clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So, we apply a perfect ranking model, which uses an oracle to choose the best candidate partition for each test text.</S><S sid = NA ssid = NA>Ng and Cardie’s system, on the other hand, employs RIPPER to train a coreference classifier on instances created by N&C’s method and represented by N&C’s feature set, inducing a partition on the given NPs via best-first clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This could be incorporated in a ranking scheme, as in Ng (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Ranking candidate partitions.</S><S sid = NA ssid = NA>Random ranking.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P05-1020.txt | Citing Article:  P07-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The baseline results are shown in rows 1 and 2 of Table 3, where performance is reported in terms of recall, precision, and F-measure.</S><S sid = NA ssid = NA>Recall that our approach uses labeled data to train both the coreference classifiers and the ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We thank the three anonymous reviewers for their valuable comments on an earlier draft of the paper.</S><S sid = NA ssid = NA>We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We thank the three anonymous reviewers for their valuable comments on an earlier draft of the paper.</S><S sid = NA ssid = NA>We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>MUC and B3 metrics (Ng, 2005a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate our approach on three standard coreference data sets using two different scoring metrics.</S><S sid = NA ssid = NA>In our experiments, our approach compares favorably to two state-of-the-art coreference systems adopting the standard machine learning approach, outperforming them by as much as 4–7% on the three data sets for one of the performance metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P05-1020.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(2004)).</S><S sid = NA ssid = NA>McCallum and Wellner (2003) and Zelenko et al. (2004) have employed graph-based partitioning algorithms such as correlation clustering (Bansal et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P05-1020.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.</S><S sid = NA ssid = NA>Machine Learning For Coreference Resolution: From Local Classification To Global Ranking</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P05-1020.txt | Citing Article:  P08-2012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>McCallum and Wellner (2003) and Zelenko et al. (2004) have employed graph-based partitioning algorithms such as correlation clustering (Bansal et al., 2002).</S><S sid = NA ssid = NA>(2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P05-1020.txt | Citing Article:  D12-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a test text, we use our coreference systems to create candidate partitions as in training, and select the highest-ranked partition according to the ranking model to be the final partition.3 The rest of this section describes how we select these learning-based coreference systems and acquire the ranking model.</S><S sid = NA ssid = NA>So, we apply a perfect ranking model, which uses an oracle to choose the best candidate partition for each test text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P05-1020.txt | Citing Article:  P08-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The baseline results are shown in rows 1 and 2 of Table 3, where performance is reported in terms of recall, precision, and F-measure.</S><S sid = NA ssid = NA>Recall that our approach uses labeled data to train both the coreference classifiers and the ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P05-1020.txt | Citing Article:  S10-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>According to Ng (2005), most learning based coreference systems can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S><S sid = NA ssid = NA>Specifically, Soon et al.’s system employs a decision tree learner to train a coreference classifier on instances created by Soon’s method and represented by Soon’s feature set, coordinating the classification decisions via closest-first clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P05-1020.txt | Citing Article:  S10-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This strategy has been described as best-first clustering by Ng (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We employ three clustering algorithms, as described below.</S><S sid = NA ssid = NA>We employ two feature sets for representing an instance, as described below.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P05-1020.txt | Citing Article:  C10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>See Ng and Cardie (2002b) for details.</S><S sid = NA ssid = NA>We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


