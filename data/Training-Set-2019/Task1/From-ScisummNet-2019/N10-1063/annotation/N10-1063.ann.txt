Citance Number: 1 | Reference Article:  N10-1063.txt | Citing Article:  W11-1207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>More recently, (Smith et al, 2010) reported significant improvements mining parallel Wikipedia articles using more sophisticated indicators of sentence parallelism, incorporating a richer set of features and cross-sentence dependencies within a Conditional Random Fields (CRFs) model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our model is a first order linear chain Conditional Random Field (CRF) (Lafferty et al., 2001).</S><S sid = NA ssid = NA>Wikipedia’s markup contains other useful indicators for parallel sentence extraction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N10-1063.txt | Citing Article:  W11-1208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A recent study by Smith et al (2010) extracted parallel sentences from comparable corpora to extend the existing resources.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment</S><S sid = NA ssid = NA>We were pleasantly surprised at the amount of parallel sentences extracted from such a varied comparable corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N10-1063.txt | Citing Article:  P13-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This methodology is similar to that of Smith et al (2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This data is used to train a word alignment model, such as IBM Model 1 (Brown et al., 1993) or HMM-based word alignment (Vogel et al., 1996).</S><S sid = NA ssid = NA>A similar source of information has been used to create seed lexicons in (Koehn and Knight, 2002) and as part of the feature space in (Haghighi et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N10-1063.txt | Citing Article:  P13-1135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Many websites are available in multiple languages, and unlike other potential sources — such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010) — it is common to find document pairs that are direct translations of one another.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Section 2 describes the multilingual resources available in Wikipedia.</S><S sid = NA ssid = NA>The related problem of automatic document alignment in news and web corpora has been explored by a number of researchers, including Resnik and Smith (2003), Munteanu and Marcu (2005), Tillmann and Xu (2009), and Tillmann (2009).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N10-1063.txt | Citing Article:  P13-1135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For these experiments, we also include training data mined from Wikipedia using a simplified version of the sentence aligner described by Smith et al (2010), in order to determine how the effect of such data compares with the effect of web mined data.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The “Large” data condition includes all the medium data, and also includes using a broad range of available sources such as data scraped from the web (Resnik and Smith, 2003), data from the United Nations, phrase books, software documentation, and more.</S><S sid = NA ssid = NA>Furthermore, adding the Wikipedia data to the large data condition still made substantial improvements.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N10-1063.txt | Citing Article:  P13-1135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unfortunately, it is difficult to obtain meaningful results on some open domain test sets such as the Wikipedia dataset used by Smith et al (2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Therefore, we experimented with two broad domain test sets.</S><S sid = NA ssid = NA>The extracted Wikipedia data is likely to make the greatest impact on broad domain test sets – indeed, initial experimentation showed little BLEU gain on in-domain test sets such as Europarl, where out-of-domain training data is unlikely to provide appropriate phrasal translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N10-1063.txt | Citing Article:  P13-1135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, Smith et al (2010) mine parallel sentences from comparable documents in Wikipedia, demonstrating substantial gains on open domain translation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this section, we will focus on methods for extracting parallel sentences from aligned, comparable documents.</S><S sid = NA ssid = NA>A noisy parallel corpus has documents which contain many parallel sentences in roughly the same order.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N10-1063.txt | Citing Article:  N12-1079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As this is computationally intensive, most studies fall back to heuristics, e.g., comparing news articles close in time (Munteanu and Marcu, 2005), exploiting "inter-wiki" links in Wikipedia (Smith et al., 2010), or bootstrapping off an existing search engine (Resnik and Smith, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In recent years, there have been several approaches developed for obtaining parallel sentences from non-parallel, or comparable data, such as news articles published within the same time period (Munteanu and Marcu, 2005), or web pages with a similar structure (Resnik and Smith, 2003).</S><S sid = NA ssid = NA>The related problem of automatic document alignment in news and web corpora has been explored by a number of researchers, including Resnik and Smith (2003), Munteanu and Marcu (2005), Tillmann and Xu (2009), and Tillmann (2009).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N10-1063.txt | Citing Article:  W11-1212.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While several recent works on dealing with large bilingual collections of texts, e.g. (Smith et al., 2010), seek for extracting parallel sentences from comparable corpora, we present PARADOCS, a system designed to recognize pairs of parallel documents in a (large) bilingual collection of texts.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment</S><S sid = NA ssid = NA>In this section, we will focus on methods for extracting parallel sentences from aligned, comparable documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N10-1063.txt | Citing Article:  W11-1212.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Smith et al (2010) extended these previous lines of work in several directions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This feature corresponds more closely to context similarity measures used in previous work on lexicon induction.</S><S sid = NA ssid = NA>This data is used to train a word alignment model, such as IBM Model 1 (Brown et al., 1993) or HMM-based word alignment (Vogel et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N10-1063.txt | Citing Article:  P12-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To create our dataset, we followed Smith et al (2010) to find parallel-foreign sentences using comparable documents linked by inter-wiki links.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment</S><S sid = NA ssid = NA>In this section, we will focus on methods for extracting parallel sentences from aligned, comparable documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N10-1063.txt | Citing Article:  W11-1209.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Wikipedia has become an attractive source of comparable documents in more recent work (Smith et al, 2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Comparable corpora contain topic aligned documents which are not translations of each other.</S><S sid = NA ssid = NA>In this section, we will focus on methods for extracting parallel sentences from aligned, comparable documents.</S> | Discourse Facet:  NA | Annotator: Automatic


