Citance Number: 1 | Reference Article:  W01-0514.txt | Citing Article:  P03-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Thanks are due to the anonymous reviewers for their invaluable comments; Masao Utiyama and Hitoshi Isahara for providing the U00 algorithm and detailed results; Marti Hearst for guidance on the evaluation problem; Mary McGee Wood for support and HCRC for making this work possible.</S><S sid = NA ssid = NA>The basic keyword search approach retrieves all documents which contain some or all of the query terms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W01-0514.txt | Citing Article:  P13-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>PLSA is the probabilistic variant of latent semantic analysis (LSA) (Choi et al, 2001), and offers a more solid statistical foundation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Latent Semantic Analysis For Text Segmentation</S><S sid = NA ssid = NA>Inter-sentence similarity is estimated by latent semantic analysis (LSA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi at al. used LSA for segmentation (Choi et al., 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>C99 (Choi, 2000a) was used as the test bench.</S><S sid = NA ssid = NA>Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Choi et al, 2001) used all vocabulary words to compute low-dimensional document vectors.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In other words, the first k columns of U, or Ak, is the best approximation of BBT in k—dimensional space.</S><S sid = NA ssid = NA>Ak is the k—dimensional LSA space for A.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Choi et al, 2001) used clustering to predict boundaries whereas we used the average similarity scores.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>C99 (Choi, 2000a) was used as the test bench.</S><S sid = NA ssid = NA>Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W01-0514.txt | Citing Article:  H05-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It is a very powerful technique already used for NLP applications such as information retrieval (Berry et al, 1995) and text segmentation (Choi et al, 2001) and, more recently, multi and single-document summarization.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S><S sid = NA ssid = NA>Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W01-0514.txt | Citing Article:  P07-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In CWM (Choi et al, 2001), a variant of C99, each word of a sentence is replaced by its representation in a Latent Semantic Analysis (LSA) space.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Inter-sentence similarity is estimated by latent semantic analysis (LSA).</S><S sid = NA ssid = NA>Latent Semantic Analysis For Text Segmentation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W01-0514.txt | Citing Article:  P08-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Thanks are due to the anonymous reviewers for their invaluable comments; Masao Utiyama and Hitoshi Isahara for providing the U00 algorithm and detailed results; Marti Hearst for guidance on the evaluation problem; Mary McGee Wood for support and HCRC for making this work possible.</S><S sid = NA ssid = NA>The basic keyword search approach retrieves all documents which contain some or all of the query terms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W01-0514.txt | Citing Article:  D10-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While extensive research has been conducted in topic segmentation for monologues (e.g., (Malioutov and Barzilay, 2006), (Choi et al, 2001)) and synchronous dialogs (e.g., (Galley et al, 2003), (Hsueh et al, 2006)), none has studied the problem of segmenting asynchronous multi-party conversations (e.g., email).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S><S sid = NA ssid = NA>Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The CWM algorithm (Choi et al, 2001) applies the same procedure to a similarity matrix of LSI vectors.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The input matrix X can either be the similarity matrix M or the rank matrix R, depending on whether ranking is applied to M. Topic boundaries are identified by the divisive clustering procedure in C99.</S><S sid = NA ssid = NA>Our new algorithm, CWM, was used in this experiment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As a preliminary test of the error measure, I evaluated two algorithms from Choi et al (2001) on the standard segmentation data set that Choi (2000) compiled.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Test results show LSA is a more accurate similarity measure than the</S><S sid = NA ssid = NA>C99 and C99b are the algorithms described in (Choi, 2000a).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The C99 (Choi, 2000) and CWM (Choi et al, 2001) algorithms were evaluated.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>C99 and C99b are the algorithms described in (Choi, 2000a).</S><S sid = NA ssid = NA>C99 (Choi, 2000a) was used as the test bench.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Because of these differences, the implementation of HCWM reported here differs somewhat from the implementation of CWM reported by Choi et al (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This implementation of C99 has three parameters.</S><S sid = NA ssid = NA>For implementation details and optimisations, see (Choi, 2000a).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(12.5%) matches what Choi et al (2001) reported (12%), while the error for HCWM (12.1%) is higher than that reported for the version with a paragraph-based 500-dimension LSI space (9%) but appears comparable to their sentence-based 400-dimension LSI space.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The values {100, 200, 300, 400, 500} represent the dimensionality of the trained space.</S><S sid = NA ssid = NA>For instance, &quot;p, 400&quot; is a 400-dimensional space that was trained on paragraphs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>And the result for NONE (46.1%) agrees with Choi et al (2001)'s results for their NONE (46%) base line.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The significance of our results has been confirmed by both t-test and KS-test (Press et al., 1992).</S><S sid = NA ssid = NA>Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W01-0514.txt | Citing Article:  N04-4025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In addition, LSA has been applied to a number of NLP tasks, such as text segmentation (Choi et al, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example).</S><S sid = NA ssid = NA>B? serves as the baseline for methods that determines the optimal segmentation, i.e. the number of topic segments in a text.</S> | Discourse Facet:  NA | Annotator: Automatic


