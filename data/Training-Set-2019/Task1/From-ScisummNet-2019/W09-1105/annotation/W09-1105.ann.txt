Citance Number: 1 | Reference Article:  W09-1105.txt | Citing Article:  W09-1408.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our goal was to investigate the performance of a memory-based approach to the event extraction task, using only the information available in the training corpus and modelling the task applying an approach similar to the one that has been applied to tasks like semantic role labeling (Morante et al, 2008) or negation scope detection (Morante and Daelemans, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The approach to the treatment of negation in NLP presented in this paper was introduced in Morante et al. (2008).</S><S sid = NA ssid = NA>The system has been developed using the BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008)1, a freely available resource that consists of medical and biological texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W09-1105.txt | Citing Article:  W10-3110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In keeping with the evaluation presented by Morante and Daelemans (2009), the number of perfectly identified negation scopes is measured separately as the percentage of correct scopes (PCS).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Additionally, we evaluate the percentage of correct scopes (PCS).</S><S sid = NA ssid = NA>This system achieved a 50.05 percentage of correct scopes but had a number of important shortcomings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W09-1105.txt | Citing Article:  W10-3110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The best reported performance to date on the BioScope full papers corpus was presented by Morante and Daelemans (2009), who achieved an F1 score of 70.9 with predicted negation signals, and an F1 score of 84.7 by feeding the manually annotated negation cues to their scope finding system.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 7 also shows that, except for can not, all negation signals score a lower PCS on the papers subcorpus.</S><S sid = NA ssid = NA>In the corpus, every sentence is annotated with information about negation and speculation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W09-1105.txt | Citing Article:  S12-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Morante and Daelemans describe a method for improving resolution of the scope of negation by combining IGTREE, CRF, and Support Vector Machines (SVM) (Morante and Daelemans, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The fourth classifier, a metalearner, is also a CRF as implemented in CRF++.</S><S sid = NA ssid = NA>We use IGTREE as implemented in TiMBL (version 6.1.2) (Daelemans et al., 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W09-1105.txt | Citing Article:  W10-2919.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The effect of negation has been broadly studied in NLP (Morante and Daelemans, 2009) and sentiment analysis (Jia et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The approach to the treatment of negation in NLP presented in this paper was introduced in Morante et al. (2008).</S><S sid = NA ssid = NA>We use IGTREE as implemented in TiMBL (version 6.1.2) (Daelemans et al., 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W09-1105.txt | Citing Article:  W10-3113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Still, Morante and Daelemans (2009), for example, used various classifiers (Memory-based Learners, Support Vector Machines, and Conditional Random Fields) to detect negation cues and their scope.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Feature selection experiments were carried out with the memory-based learning classifier.</S><S sid = NA ssid = NA>Typical example sentences with this negation signal are shown in (4).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W09-1105.txt | Citing Article:  P11-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similarly, Morante and Daelemans (2009b) developed a machine learning system for identifying hedging cues and their scopes.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The two classification tasks (identifying negation signals and finding the scope) are implemented using supervised machine learning methods trained on part of the annotated corpus.</S><S sid = NA ssid = NA>Machine learning techniques have been used in some cases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Compared with negation scope finding, negation signal finding is much simpler and has been well resolved in the literature, e.g. with the accuracy of 95.8% -98.7% on the three sub corpora of the Bioscope corpus (Morante and Daelemans, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the negation finding task, a negation token is correctly classified if it has been classified as being at the beginning or inside the negation signal.</S><S sid = NA ssid = NA>Finding the scope of a negation signal means determining at sentence level the sequence of words in the sentence that is affected by the negation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Morante et al (2008) and Morante and Daelemans (2009) pioneered the research on negation scope finding by formulating it as a chunking problem, which classifies the words of a sentence as being inside or outside the scope of a negation signal.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finding the scope of a negation signal means determining at sentence level the sequence of words in the sentence that is affected by the negation.</S><S sid = NA ssid = NA>In the scope finding task, a token is correctly classified if it has been correctly classified as being inside or outside of the scope of all the negation signals that there are in the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, given golden negation signals on the Bioscope corpus, Morante and Daelemans (2009) only got the performance of 50.26% in PCS (percentage of correct scope) measure on the full papers sub corpus (22.8 words per sentence on average), compared to 87.27% in PCS measure on the clinical reports subcorpus (6.6 words per sentence on average).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This difference can not be caused by the sentence length, since the average sentence length in the abstracts subcorpus (26.43 tokens) is similar to the average sentence length in the papers subcorpus (26.24).</S><S sid = NA ssid = NA>An alternative to the PCS-2 measure would be to mark in the corpus the relevant negated content words and evaluate if they are under the scope.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Morante and Daelemans (2009) further improved the performance by combing several classifiers.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The architecture of the system is new for this problem, with three classifiers and a metalearner that takes as input the output of the first classifiers.</S><S sid = NA ssid = NA>However, the classifiers only predict the first and last element of the scope.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For detailed statistics about the three subcorpora, please see Morante and Daelemans (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 1 shows statistics about the corpora.</S><S sid = NA ssid = NA>We take the scope to the right for the baseline because it is much more frequent than the scope to the left, as is shown by the statistics contained in Table 1 of Section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following the experimental setting in Morante and Daelemans (2009), the abstracts sub corpus is randomly divided into 10 folds so as to perform 10-fold cross validation, while the performance on both the papers and clinical reports subcorpora is evaluated using the system trained on the whole abstracts subcorpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The results provided for the abstracts part of the corpus have been obtained by performing 10-fold cross validation experiments, whereas the results provided for papers and clinical reports have been obtained by training on the full abstracts subcorpus and testing on the papers and clinical reports subcorpus.</S><S sid = NA ssid = NA>One factor is the length of sentences: 75.85 % of the sentences in the clinical reports have 10 or less words, whereas this rate is 3.17 % for abstracts and 11.27 % for papers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W09-1105.txt | Citing Article:  C10-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although Morante and Daelemans (2009) reported the performance of 95.8%-98.7% on negation signal finding, it lowers the performance of negation scope finding by about 7.29%-16.52% in PCS measure.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the negation finding task, a negation token is correctly classified if it has been classified as being at the beginning or inside the negation signal.</S><S sid = NA ssid = NA>Finding the scope of a negation signal means determining at sentence level the sequence of words in the sentence that is affected by the negation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are grateful to four anonymous reviewers for their valuable comments and suggestions.</S><S sid = NA ssid = NA>Golding and Chapman (2003) experiment with Naive Bayes and Decision Trees to distinguish whether a medical observation is negated by the word not in a corpus of hospital reports.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, given golden negation cues on the Bioscope corpus, Morante and Daelemans (2009a) only got the performance of 50.26% in PCS on the full papers sub corpus (22.8 words per sentence on average), compared to 87.27% in PCS on the clinical reports sub corpus (6.6 words per sentence on average).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The average length of a sentence for clinical reports is 7.73 tokens, whereas for abstracts it is 26.43 and for papers 26.24.</S><S sid = NA ssid = NA>This difference can not be caused by the sentence length, since the average sentence length in the abstracts subcorpus (26.43 tokens) is similar to the average sentence length in the papers subcorpus (26.24).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Speculation Scope Learning Similar to Morante and Daelemans (2009a), Morante and Daelemans (2009b) formulated speculation scope identification as a chunking problem which predicts whether a word in the sentence is inside or outside of the speculation scope, with proper post-processing to ensure consecutiveness of the speculation scope.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the corpus, every sentence is annotated with information about negation and speculation.</S><S sid = NA ssid = NA>In the scope finding task, a token is correctly classified if it has been correctly classified as being inside or outside of the scope of all the negation signals that there are in the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are grateful to four anonymous reviewers for their valuable comments and suggestions.</S><S sid = NA ssid = NA>Golding and Chapman (2003) experiment with Naive Bayes and Decision Trees to distinguish whether a medical observation is negated by the word not in a corpus of hospital reports.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are grateful to four anonymous reviewers for their valuable comments and suggestions.</S><S sid = NA ssid = NA>Golding and Chapman (2003) experiment with Naive Bayes and Decision Trees to distinguish whether a medical observation is negated by the word not in a corpus of hospital reports.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W09-1105.txt | Citing Article:  D10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We are grateful to four anonymous reviewers for their valuable comments and suggestions.</S><S sid = NA ssid = NA>Golding and Chapman (2003) experiment with Naive Bayes and Decision Trees to distinguish whether a medical observation is negated by the word not in a corpus of hospital reports.</S> | Discourse Facet:  NA | Annotator: Automatic


