Citance Number: 1 | Reference Article:  D09-1101.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported in part by NSF Grant IIS-0812261.</S><S sid = NA ssid = NA>These features have largely been employed by state-of-the-art learning-based coreference systems (e.g., Soon et al. (2001), Ng and Cardie (2002b), Bengtson and Roth (2008)), and are computed automatically.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D09-1101.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported in part by NSF Grant IIS-0812261.</S><S sid = NA ssid = NA>These features have largely been employed by state-of-the-art learning-based coreference systems (e.g., Soon et al. (2001), Ng and Cardie (2002b), Bengtson and Roth (2008)), and are computed automatically.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D09-1101.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For comparison purposes, the B3None variant used on A05RA is calculated slightly differently than other B3None results; see Rahman and Ng (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For illustrative purposes, we will use the text segment shown in Figure 1.</S><S sid = NA ssid = NA>However, this is not the case when system mentions are used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D09-1101.txt | Citing Article:  N10-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Luo et al. (2004) represent one of the earliest attempts to investigate learning-based entity-mention models.</S><S sid = NA ssid = NA>Our cluster-ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D09-1101.txt | Citing Article:  W12-4509.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The set of features that we use, listed in Table 5, is an extension of the set by Rahman and Ng (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Specifically, for each feature X shown in the last two blocks in Table 1, we first convert X into an equivalent set of binary-valued features if it is multi-valued.</S><S sid = NA ssid = NA>The feature set used to represent the instance is primarily composed of features that describe the relationship between mj and mk, as well as a few cluster-level features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our system is based on a cluster-ranking model proposed by Rahman and Ng (2009), with novel semantic features based on recent re search on narrative event schema (Chambers and Jurafsky, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Heuristic-based cluster ranking.</S><S sid = NA ssid = NA>Our cluster-ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We created a baseline system based on the cluster-ranking model proposed by Rahman and Ng (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>The mention-ranking baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Rahman and Ng (2009) in particular propose the cluster-ranking model which we used in our baseline.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>The mention-ranking baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In each query we include a null-cluster instance, to allow joint learning of discourse-new detection, following (Rahman and Ng, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Discourse-new detection.</S><S sid = NA ssid = NA>Also, our joint-learning approach to discourse-new detection and coreference resolution consistently yields cluster rankers that outperform those adopting the pipeline architecture.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We follow Rahman and Ng (2009) in jointly learning to detect anaphoric mentions along with resolving coreference relations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The discourse-new classifier used in the resolution step is trained with 26 of the 37 features2 described in Ng and Cardie (2002a) that are deemed useful for distinguishing between anaphoric and non-anaphoric mentions.</S><S sid = NA ssid = NA>Also, we retain twinless system mentions that are nonsingletons, as the resolver should be penalized for identifying spurious coreference relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D09-1101.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We follow the procedure described in (Rahman and Ng, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(2004), as described below.</S><S sid = NA ssid = NA>Given an active mention mk, we follow Denis and Baldridge (2008) and use an independently-trained classifier to determine whether mk is discourse-new.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D09-1101.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use the ACE 2005 coreference corpus as released by the LDC, which consists of the 599 training documents used in the official ACE evaluation.3 To ensure diversity, the corpus was created by selecting documents from six different sources: Broadcast News (bn), Broadcast Conversations (bc), Newswire (nw), Webblog (wb), Usenet (un), and conversational telephone speech (cts).</S><S sid = NA ssid = NA>To train a ranker, we use the SVM ranker-learning algorithm from the SVMlZght package.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D09-1101.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported in part by NSF Grant IIS-0812261.</S><S sid = NA ssid = NA>These features have largely been employed by state-of-the-art learning-based coreference systems (e.g., Soon et al. (2001), Ng and Cardie (2002b), Bengtson and Roth (2008)), and are computed automatically.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D09-1101.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Also, the B3 variant used by Rahman and Ng (2009) is slightly different from other systems (they remove all and only the singleton twinless system mentions, so it is neither B3All nor B3None).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We propose a simple solution to this problem: we remove all and only those twinless system mentions that are singletons before applying B3 and CEAF.</S><S sid = NA ssid = NA>Note that we only remove twinless (as opposed to all) system mentions that are singletons: this allows us to reward a resolver for successful identification of singleton mentions that have twins, thus overcoming a major weakness of and common criticism against the MUC scorer.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D09-1101.txt | Citing Article:  P12-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The other systems we compare to and outperform are the perceptron-based Reconcile system of Stoyanov et al (2009), the strong deterministic system of Haghighi and Klein (2009), and the cluster-ranking model of Rahman and Ng (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>We believe that our proposal addresses Stoyanov et al.’s (2009) problem of having very low precision when applying the CEAF scorer to score partitions of system mentions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D09-1101.txt | Citing Article:  P11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To extract NPs from the ACE-annotated documents, we train a mention extractor on the training texts (see Section 5.1 of Rahman and Ng (2009) for details), which recalls 83.6% of the NPs in the test set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To extract system mentions from a test text, we trained a mention extractor on the training texts.</S><S sid = NA ssid = NA>Mention extractor.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D09-1101.txt | Citing Article:  P11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Since space limitations preclude a description of these features, we refer the reader to Rahman and Ng (2009) for details.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The features for an instance can be divided into two types: (1) features that describe mk (i.e, those shown in the second block of Table 1), and (2) cluster-level features, which describe the relationship between cj and mk.</S><S sid = NA ssid = NA>Noun phrase (NP) coreference resolution is the task of identifying which NPs (or mentions) refer to the same real-world entity or concept.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D09-1101.txt | Citing Article:  P11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Details of the CR model can be found in Rahman and Ng (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>In this section, we describe three coreference models that will serve as our baselines: the mentionpair model, the entity-mention model, and the mention-ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D09-1101.txt | Citing Article:  P11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Also, the results show that the CR model is stronger than the MP model, corroborating previous empirical findings (Rahman and Ng, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>In this section, we describe three coreference models that will serve as our baselines: the mentionpair model, the entity-mention model, and the mention-ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D09-1101.txt | Citing Article:  S12-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our cluster-ranking model.</S><S sid = NA ssid = NA>After training, the resulting cluster ranker processes the mentions in a test text in a left-to-right manner.</S> | Discourse Facet:  NA | Annotator: Automatic


