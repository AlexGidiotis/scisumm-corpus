Citance Number: 1 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The work of Aone and Bennett (1995), McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996) employed decision tree learning.</S><S sid = NA ssid = NA>The RESOLVE system is presented in McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The RESOLVE system is presented in McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).</S><S sid = NA ssid = NA>The RESOLVE system is described in three papers: McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soon et al (2001) use twelve features (see Table 1).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 3 and Table 4 show the results of the experiment.</S><S sid = NA ssid = NA>RESOLVE makes use of 39 features, considerably more than our system's 12 features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soon et al (2001) include all noun phrases returned by their NP identifier and report an F-measure of 62.6% for MUC-6 data and 60.4% for MUC-7 data.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since these features are highly informative, we were curious to see how much they contribute to our MUC-6 and MUC-7 results of 62.6% and 60.4%, respectively.</S><S sid = NA ssid = NA>We evaluated our approach on common data sets, namely, the MUC-6 and MUC-7 coreference corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One factor that affects the performance of a machine learning approach is the set of features used.</S><S sid = NA ssid = NA>The features used were slightly changed for this domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J01-4004.txt | Citing Article:  P02-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For MUC-7, there is no drop in F-measure; for MUC-6, the F-measure dropped slightly.</S><S sid = NA ssid = NA>However, its F-measure is comparable to that of STR_MATCH.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J01-4004.txt | Citing Article:  P14-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Fisher et al. (1995) adapted RESOLVE to work in MUC-6.</S><S sid = NA ssid = NA>C5 is a commonly used decision tree learning algorithm and thus it may be considered as a baseline method against which other learning algorithms can be compared.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J01-4004.txt | Citing Article:  P14-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For each j, the algorithm considers every markable i before j as a potential antecedent.</S><S sid = NA ssid = NA>A coreferring antecedent is found if the classifier returns true.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J01-4004.txt | Citing Article:  P11-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Fisher et al. (1995) adapted RESOLVE to work in MUC-6.</S><S sid = NA ssid = NA>Our result is encouraging since it indicates that a learning approach using relatively shallow features can achieve scores comparable to those of systems built using nonlearning approaches.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J01-4004.txt | Citing Article:  N06-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Instances are created following Soon et al (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The following two subsections describe the errors in more detail.</S><S sid = NA ssid = NA>Fisher et al. (1995) adapted RESOLVE to work in MUC-6.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J01-4004.txt | Citing Article:  N06-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Other baseline systems that are used are ONE_CHAIN, ONE_WRD, and HD_WRD (Cardie and Wagstaff 1999).</S><S sid = NA ssid = NA>The following two subsections describe the errors in more detail.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J01-4004.txt | Citing Article:  N06-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In terms of absolute Fmeasure, the difference between using these three features and using all features is 2.3% for MUC-6 and 1% for MUC-7; in other words, the other nine features contribute just 2.3% and 1% more for each of the MUC years.</S><S sid = NA ssid = NA>The distance feature has different effects on different noun phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J01-4004.txt | Citing Article:  S10-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>On the other hand, the markables extracted by our system include nested noun phrases, MUC-style named entity types (money, percent, date, etc.</S><S sid = NA ssid = NA>We also implemented a module that recognizes MUC-style named entities, that is, organization, person, location, date, time, money, and percent.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J01-4004.txt | Citing Article:  S10-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>RESOLVE's feature set includes the two highly informative features, ALIAS and STR_MATCH.</S><S sid = NA ssid = NA>Fisher et al. (1995) adapted RESOLVE to work in MUC-6.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J01-4004.txt | Citing Article:  P11-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>PAIRWISE: as in the work by Soon et al (2001), antecedent identification and anaphoricity determination are simultaneously executed by a single classifier.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Fisher et al. (1995) adapted RESOLVE to work in MUC-6.</S><S sid = NA ssid = NA>A coreferring antecedent is found if the classifier returns true.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J01-4004.txt | Citing Article:  C10-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We adopt a corpus-based, machine learning approach to noun phrase coreference resolution.</S><S sid = NA ssid = NA>A Machine Learning Approach To Coreference Resolution Of Noun Phrases</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J01-4004.txt | Citing Article:  D08-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A Machine Learning Approach To Coreference Resolution Of Noun Phrases</S><S sid = NA ssid = NA>Such knowledge sources are commonly used for the task of determining coreference.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J01-4004.txt | Citing Article:  D08-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Soon et al (2001) use the Closest-Link method: They select as an antecedent the closest preceding mention that is predicted coreferential by a pairwise coreference module; this is equivalent to choosing the closest mention whose pc value is above a threshold.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We use the same method to generate coreference chains for both MUC-6 and MUC7, except for the following.</S><S sid = NA ssid = NA>Since WordNet orders the senses of a noun by their frequency, this is equivalent to choosing the most frequent sense as the semantic class for each noun.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J01-4004.txt | Citing Article:  D08-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One important factor is the distance between the two markables.</S><S sid = NA ssid = NA>We include the distance feature so that the learning algorithm can best decide the distribution for different classes of noun phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J01-4004.txt | Citing Article:  P10-1120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Systems ALIAS_STR and ALIAS_STR_APPOS in Table 3 and Table 4 show the results of the experiment.</S><S sid = NA ssid = NA>Table 3 and Table 4 show the results of the experiment.</S> | Discourse Facet:  NA | Annotator: Automatic


